{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/images/logo.jpg","path":"images/logo.jpg","modified":1,"renderable":0},{"_id":"source/images/wechat.jpg","path":"images/wechat.jpg","modified":1,"renderable":0},{"_id":"source/images/2020-12-02/1.jpg","path":"images/2020-12-02/1.jpg","modified":1,"renderable":0},{"_id":"source/images/2020-12-02/2.jpg","path":"images/2020-12-02/2.jpg","modified":1,"renderable":0},{"_id":"themes/hexo-theme-xoxo/source/css/common.less","path":"css/common.less","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/core.less","path":"css/core.less","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/highlight.less","path":"css/highlight.less","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/mixin.less","path":"css/mixin.less","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/normalize.css","path":"css/normalize.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/variables.less","path":"css/variables.less","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/xoxo.css","path":"css/xoxo.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/xoxo.css.map","path":"css/xoxo.css.map","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/xoxo.less","path":"css/xoxo.less","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/xxoo.css","path":"css/xxoo.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/css/xxoo.css.map","path":"css/xxoo.css.map","modified":1,"renderable":1},{"_id":"themes/hexo-theme-xoxo/source/js/xoxo.js","path":"js/xoxo.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/_posts/.kubernetes的python-client体验.md.swp","hash":"8433bce7c682735e7fc37f7000897d19c80cae1f","modified":1606802751084},{"_id":"source/_posts/EMQ-X-Kuiper与EdgeX-Foundry集成实践.md","hash":"1e8db499d3cb83e7521ea4d7beda07c1fcc5815b","modified":1606790205542},{"_id":"source/_posts/kind快速部署Kubernetes环境.md","hash":"2e24af11e13eac90591b14923b6242b1afaa3ef8","modified":1606704145604},{"_id":"source/_posts/kubernetes_install_on_ubuntu.md","hash":"1c36901478e12b5c254ee79893eae44b0326f27a","modified":1606380061137},{"_id":"source/_posts/kubernetes的python-client体验.md","hash":"389088a8aaa0354f9968f2685f9e516ee19746cf","modified":1606805307289},{"_id":"source/_posts/kubernetes部署httpd服务.md","hash":"04cc2bb6d45c8de035b54f41bd5f638c05e1f4fe","modified":1606894521898},{"_id":"source/_posts/如何使用github作为Helm的chart仓库.md","hash":"98e54f1d38658374dc764ec5967ac3f722e71a32","modified":1606786755943},{"_id":"source/_posts/如何配置kubernetes的pod从私有仓库拉取镜像.md","hash":"63b1b08813c6bcb4906332e8b9c630dece32e76d","modified":1606810678431},{"_id":"source/about/index.md","hash":"55121cce114f21bacfa03f9de1653e4bef71fb4b","modified":1606701512669},{"_id":"source/categories/index.md","hash":"da0e4464fda0a9ea677650f2cf552258bd1cd054","modified":1606362387598},{"_id":"source/images/logo.jpg","hash":"e958bc3141570f28db728b779192341f8dbefa1e","modified":1606374855259},{"_id":"source/tags/index.md","hash":"a4a0df27d5cb071364a00b3d09ddbb135792c378","modified":1606362355518},{"_id":"source/search/index.md","hash":"562ec480a408a6dea9b88754f43c6d40a92d5d2a","modified":1606369135673},{"_id":"source/images/2020-12-02/1.jpg","hash":"4edbd970d895e86d49363fe5b35a3fab4c4dc6a2","modified":1606893733466},{"_id":"source/images/2020-12-02/2.jpg","hash":"7911a1c7570a007e29fb7c489f91dba9bdd6b1f3","modified":1606893526355},{"_id":"themes/hexo-theme-xoxo/source/js/xoxo.js","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606358880941},{"_id":"source/images/wechat.jpg","hash":"508d3ef3f991341c44862d17edd3b69a0879f8ad","modified":1606379002282},{"_id":"themes/hexo-theme-xoxo/.gitignore","hash":"e355699544358cef7ed34a09c15264e851c9b562","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/README.md","hash":"a1f59810e70ef45fb1b918aa1bfea649bdbeed9e","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/_config.yml","hash":"6b66c45635ceaa74be0f116c51fdde1d67da7cd2","modified":1606375795579},{"_id":"themes/hexo-theme-xoxo/gulpfile.js","hash":"d5f9cc74e2ea4a5d6de8b7931bf90e6a04a02dc9","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/package.json","hash":"203f579a057fb68bf79182b1da74bc7f52d09a0b","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/index.ejs","hash":"bc4c04e523b9152cb7e5f2b2c689e7a718f6bdd2","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/archive.ejs","hash":"bd98c4a500422340d829b918b86963f810607205","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/page.ejs","hash":"7651d7af258b87772f833d7debc01f7445187109","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/layout.ejs","hash":"620c5a3e7c58037cc9822ef781657e84b44f47a8","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/tag.ejs","hash":"f35efdf7de89401ab24cc7b1712ca7702a8591ff","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/post.ejs","hash":"2c04ffba37f7a3df7ebc2081f7d6fe131f32c090","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/languages/default.yml","hash":"e44dfd1305ccc06b94f04de434ada89697e03e55","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/languages/en.yml","hash":"75b950e8e515b782a189c29210a9322e9af414f6","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/languages/zh-CN.yml","hash":"9d165da5991434fa1d82d090e1323b75ca5f86b6","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/languages/zh-TW.yml","hash":"12e322c9f08dd2370785581b990baa43e9b9153f","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/analytics.ejs","hash":"df9871e7d66f1b703c5b757df94fd0f3fd5ea1b6","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/archive.ejs","hash":"b5c154d8e0f1930e4261ec63d3a0952ff03fd075","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/archive-post.ejs","hash":"464086c3fd545aa2e059acade02e8382985e22e8","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/disqus.ejs","hash":"efdd456a2ee49d2a2eb8ada28cee68a637121e50","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/copyright.ejs","hash":"80791921ca6d72f32368275aa88fb56ea99b0ef6","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/footer.ejs","hash":"b656ac3f0b2ddff5cd0e9011b966cad744df03aa","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/head.ejs","hash":"403678c7e8108f4fd53390b83bf13045cadee1ea","modified":1606375578054},{"_id":"themes/hexo-theme-xoxo/layout/partials/js.ejs","hash":"281e2504e687db6dc65c0fa6a2e6ff747efbc324","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/nav.ejs","hash":"6d0032f1b1e54bf09cae36138c7275e2cd59b7c3","modified":1606376117651},{"_id":"themes/hexo-theme-xoxo/layout/partials/prenext.ejs","hash":"8ca2261a9fc465b1f1921569ac59b9aa4c83a8c1","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/recent-posts.ejs","hash":"1e743751f0480b3b65f8365199bdd228ac5494bc","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/scripts.ejs","hash":"edc7c81143cd624719a43d2b3edb325fd3cd8019","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/search.ejs","hash":"1a03040e44ab0b91064c3d22a5a8d7cb70a379ca","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/layout/partials/share.ejs","hash":"7f50f5214e1f6db00ef14124ccbda471fe5f0454","modified":1606378937839},{"_id":"themes/hexo-theme-xoxo/layout/partials/toc.ejs","hash":"be02b5e03ecf4cac8d0fe22854a4c7632d36a6a5","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/scripts/tags/lazy-image.js","hash":"451f6faf1ce5600774b81d8a7ca5826165333b12","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/source/css/common.less","hash":"5d3b78c83e36faec5ae5cf77b8f05ee90a310910","modified":1606358880937},{"_id":"themes/hexo-theme-xoxo/source/css/core.less","hash":"cc7bd8065e0d45bdec12a98d33c3c8d770c81fa0","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/highlight.less","hash":"a7ae4e53c04249f69a2b878fe5e56bf1d23a8b9d","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/mixin.less","hash":"e7336eca0285aa1189ad47bf6dc7f59fde60e67c","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/normalize.css","hash":"ebe0759bf259b6caeadee6137973481046ac5636","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/variables.less","hash":"52aafe1e3a907a85b69b2cf02f14e5e9973b8388","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/xoxo.css","hash":"e3255fc18e04cf9a6f07be45ac1b34cfa0ea2b48","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/xoxo.less","hash":"43d9ab1c0fa6d73faeb64910b3e1e07cae63d489","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/xoxo.css.map","hash":"9e43c4ab3dede729c344ad4e6c1bbf9ad0bee6a9","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/xxoo.css","hash":"c3d0d559499adea9e89892b5d714f4ab00e0ffa9","modified":1606358880941},{"_id":"themes/hexo-theme-xoxo/source/css/xxoo.css.map","hash":"d07fe1cc9edd53ca13b3e43ada5ac9788da609a9","modified":1606358880941},{"_id":"public/atom.xml","hash":"96a25702a22ecd16146261bd265c7a1d0c498f91","modified":1606894527735},{"_id":"public/search.xml","hash":"2fab41a1825da2995bc0dc71f8d1444ba5bc5e0e","modified":1606894527735},{"_id":"public/about/index.html","hash":"fbe9731a7246d4e5d2577f4f778ab6fbfa53dd8f","modified":1606894527735},{"_id":"public/categories/index.html","hash":"d78400cdbeb0ccdf3580e6d361176b7bf319ee27","modified":1606894527735},{"_id":"public/tags/index.html","hash":"43c248474a29269cad07c7b2d19eb2f32df011ae","modified":1606894527735},{"_id":"public/search/index.html","hash":"5b138b68e0074530f0bc7ef3d7a7cb85bfd19303","modified":1606894527735},{"_id":"public/archives/index.html","hash":"df2c3b54df58b96505082ddf611a7d89f92c9595","modified":1606894527735},{"_id":"public/archives/2020/index.html","hash":"5df286cb5c22488d458f3e63c3239b968296fecc","modified":1606894527735},{"_id":"public/archives/2020/11/index.html","hash":"ea22378e47c5900d99a3e8170308662c863291c1","modified":1606894527735},{"_id":"public/archives/2020/12/index.html","hash":"b91a13d0bd87ef30edba65558ccb0e1241b072f3","modified":1606894527735},{"_id":"public/categories/kuiper/index.html","hash":"15c8b26a0509d67b481ee7b2dccc2aabb64b8456","modified":1606894527735},{"_id":"public/categories/kubernetes/index.html","hash":"0af85ae822b4d4a3a88bab40f99aefe066a2c2de","modified":1606894527735},{"_id":"public/categories/python/index.html","hash":"e4c77aef63d22fa5cdace3b75716e88804f6bc49","modified":1606894527735},{"_id":"public/categories/kuiper/edgex/index.html","hash":"fa8833e98b65e3be3295ea9530cc8a90d24c4aff","modified":1606894527735},{"_id":"public/categories/helm/index.html","hash":"a8d6b133c05fec1093bd992f331c88af87495018","modified":1606894527735},{"_id":"public/categories/registry/index.html","hash":"9b7732e9871adc2092d4c6a3189559d3c9a1abe5","modified":1606894527735},{"_id":"public/categories/python/kubernetes/index.html","hash":"dd3da6417e22ca5aad09b2db2ee0b3c6fa8d696c","modified":1606894527735},{"_id":"public/categories/registry/docker/index.html","hash":"9572e0077cb9762cd30c1acb30e8eda9c157794a","modified":1606894527735},{"_id":"public/categories/registry/docker/kubernetes/index.html","hash":"9531c0a9b8b378bcd0977990362edbf81ae87e26","modified":1606894527735},{"_id":"public/categories/云原生/index.html","hash":"b1f9a6e718bc9418765450ad64d0e0fd9e2afab3","modified":1606894527735},{"_id":"public/tags/kuiper/index.html","hash":"a844f8a6db8115b5501f4247689985afe8f49113","modified":1606894527735},{"_id":"public/tags/edgex/index.html","hash":"74cd60865355a60e2c0ca907252d17bd64d3f48a","modified":1606894527735},{"_id":"public/tags/云计算/index.html","hash":"0cf0c87fd478052892c649cf4cb9736354ba7d00","modified":1606894527735},{"_id":"public/tags/边缘计算/index.html","hash":"19c5ee15a954ec134c2d9e54a3430f2d92ca0d26","modified":1606894527735},{"_id":"public/tags/kubernetes/index.html","hash":"c845a1390f503559fb5b41134c8cbfe3d07231b5","modified":1606894527735},{"_id":"public/tags/python/index.html","hash":"167991a38918e3a35e708196a25cb666182a8440","modified":1606894527735},{"_id":"public/tags/GitHub/index.html","hash":"6b6096eb3a0a6ea43c22fcd0a598d6c6c8508b3e","modified":1606894527735},{"_id":"public/tags/helm/index.html","hash":"24aadbf0b7cc871fe0929f58560e32e4fd0991cd","modified":1606894527735},{"_id":"public/tags/docker/index.html","hash":"f5127e1015ad4fec7c6156e860bb04c486a6b6a3","modified":1606894527735},{"_id":"public/tags/云原生/index.html","hash":"acf0c9880f04fac89d799312c4eb626381129a42","modified":1606894527735},{"_id":"public/2020/12/02/kubernetes部署httpd服务/index.html","hash":"86c6199105530a7f8c2b878910b227b23260a01d","modified":1606894527735},{"_id":"public/2020/12/01/如何配置kubernetes的pod从私有仓库拉取镜像/index.html","hash":"25f005a77dadd77069a20ee6ba52eff0f2ecf6f8","modified":1606894527735},{"_id":"public/2020/12/01/kubernetes的python-client体验/index.html","hash":"d10ed576a6f8246fc45f669da3bf9eafebbe2f05","modified":1606894527735},{"_id":"public/2020/12/01/EMQ-X-Kuiper与EdgeX-Foundry集成实践/index.html","hash":"d66a432f006fb3da0fd82cc8141d985da892c27c","modified":1606894527735},{"_id":"public/2020/12/01/如何使用github作为Helm的chart仓库/index.html","hash":"9612cdb1b9efadc1a07034488b4ee1f246e740dc","modified":1606894527735},{"_id":"public/2020/11/26/kind快速部署Kubernetes环境/index.html","hash":"202ca0bd8929d6787200558fce0269784c0f491a","modified":1606894527735},{"_id":"public/2020/11/26/kubernetes_install_on_ubuntu/index.html","hash":"c859e8d1c2a1f5dd30e2fe3dba176e95fbe3d026","modified":1606894527735},{"_id":"public/index.html","hash":"f85b0e874a69ff71ec669e1013b8097c18094abf","modified":1606894527735},{"_id":"public/images/2020-12-02/1.jpg","hash":"4edbd970d895e86d49363fe5b35a3fab4c4dc6a2","modified":1606894527735},{"_id":"public/images/2020-12-02/2.jpg","hash":"7911a1c7570a007e29fb7c489f91dba9bdd6b1f3","modified":1606894527735},{"_id":"public/css/common.less","hash":"5d3b78c83e36faec5ae5cf77b8f05ee90a310910","modified":1606894527735},{"_id":"public/css/core.less","hash":"cc7bd8065e0d45bdec12a98d33c3c8d770c81fa0","modified":1606894527735},{"_id":"public/css/highlight.less","hash":"a7ae4e53c04249f69a2b878fe5e56bf1d23a8b9d","modified":1606894527735},{"_id":"public/css/mixin.less","hash":"e7336eca0285aa1189ad47bf6dc7f59fde60e67c","modified":1606894527735},{"_id":"public/css/variables.less","hash":"52aafe1e3a907a85b69b2cf02f14e5e9973b8388","modified":1606894527735},{"_id":"public/css/xoxo.less","hash":"43d9ab1c0fa6d73faeb64910b3e1e07cae63d489","modified":1606894527735},{"_id":"public/css/xoxo.css.map","hash":"9e43c4ab3dede729c344ad4e6c1bbf9ad0bee6a9","modified":1606894527735},{"_id":"public/css/xxoo.css.map","hash":"d07fe1cc9edd53ca13b3e43ada5ac9788da609a9","modified":1606894527735},{"_id":"public/images/logo.jpg","hash":"e958bc3141570f28db728b779192341f8dbefa1e","modified":1606894527735},{"_id":"public/js/xoxo.js","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606894527735},{"_id":"public/css/normalize.css","hash":"ebe0759bf259b6caeadee6137973481046ac5636","modified":1606894527735},{"_id":"public/images/wechat.jpg","hash":"508d3ef3f991341c44862d17edd3b69a0879f8ad","modified":1606894527735},{"_id":"public/css/xoxo.css","hash":"e3255fc18e04cf9a6f07be45ac1b34cfa0ea2b48","modified":1606894527735},{"_id":"public/css/xxoo.css","hash":"c3d0d559499adea9e89892b5d714f4ab00e0ffa9","modified":1606894527735}],"Category":[{"name":"kuiper","_id":"cki73ih170004h0l7hvq65ktb"},{"name":"kubernetes","_id":"cki73ih1a000bh0l7gruyeb9u"},{"name":"python","_id":"cki73ih1c000eh0l7g55h81tq"},{"name":"edgex","parent":"cki73ih170004h0l7hvq65ktb","_id":"cki73ih1e000lh0l77mu9gmy0"},{"name":"helm","_id":"cki73ih1e000oh0l73lja1egf"},{"name":"registry","_id":"cki73ih1f000th0l70w86gx76"},{"name":"kubernetes","parent":"cki73ih1c000eh0l7g55h81tq","_id":"cki73ih1g000yh0l71rgb0mqm"},{"name":"docker","parent":"cki73ih1f000th0l70w86gx76","_id":"cki73ih1h0013h0l7f9fk76uu"},{"name":"kubernetes","parent":"cki73ih1h0013h0l7f9fk76uu","_id":"cki73ih1h0018h0l75h6i4mdp"},{"name":"云原生","_id":"cki73ih1k001jh0l71oza1pu1"}],"Data":[],"Page":[{"title":"about","date":"2020-11-26T03:18:21.000Z","type":"about","_content":"## 关于我\n\n教育：硕士一枚\n\n技能：关注云计算、边缘计算、大数据等领域; 擅长Docker、Kubernetes、EdgeX Foundry、KubeEdge等云原生领域知识，最近在持续关注华为的昇腾生态产品：Ascend（华为自研AI芯片）、MindSpore（华为自研AI框架，类似于Tensorflow、Pytorch）\n\n联系方式：\n     1. GitHub: https://github.com/yushanjin\n     2. Gitee: https://gitee.com/yushanjin\n     3. 简书：https://www.jianshu.com/u/aa3d5c41012b\n     4. 微信公众号：云技术实践者\n\n希望大家相互多多交流！\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2020-11-26 11:18:21\ntype: about\n---\n## 关于我\n\n教育：硕士一枚\n\n技能：关注云计算、边缘计算、大数据等领域; 擅长Docker、Kubernetes、EdgeX Foundry、KubeEdge等云原生领域知识，最近在持续关注华为的昇腾生态产品：Ascend（华为自研AI芯片）、MindSpore（华为自研AI框架，类似于Tensorflow、Pytorch）\n\n联系方式：\n     1. GitHub: https://github.com/yushanjin\n     2. Gitee: https://gitee.com/yushanjin\n     3. 简书：https://www.jianshu.com/u/aa3d5c41012b\n     4. 微信公众号：云技术实践者\n\n希望大家相互多多交流！\n","updated":"2020-11-30T01:58:32.669Z","path":"about/index.html","comments":1,"layout":"page","_id":"cki73ih110000h0l72jkacstf","content":"<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>教育：硕士一枚</p>\n<p>技能：关注云计算、边缘计算、大数据等领域; 擅长Docker、Kubernetes、EdgeX Foundry、KubeEdge等云原生领域知识，最近在持续关注华为的昇腾生态产品：Ascend（华为自研AI芯片）、MindSpore（华为自研AI框架，类似于Tensorflow、Pytorch）</p>\n<p>联系方式：<br>     1. GitHub: <a href=\"https://github.com/yushanjin\">https://github.com/yushanjin</a><br>     2. Gitee: <a href=\"https://gitee.com/yushanjin\">https://gitee.com/yushanjin</a><br>     3. 简书：<a href=\"https://www.jianshu.com/u/aa3d5c41012b\">https://www.jianshu.com/u/aa3d5c41012b</a><br>     4. 微信公众号：云技术实践者</p>\n<p>希望大家相互多多交流！</p>\n","site":{"data":{}},"excerpt":"关于我\n教育：硕士一枚\n\n技能：关注云计算、边缘计算、大数据等领域; 擅长Docker、Kubernetes、EdgeX Foundry、KubeEdge等云原生领域知识，最近在持续关注华为的昇腾生态产品：Ascend（华为自研AI芯片）、MindSpore（华为自研AI框架，类似于Tensorflow、Pytorch）\n\n联系方式：\n1. GitHub: https://github.com/yushanjin\n2. Gitee: https://gitee.com/yushanjin\n3. 简书：https://www.jianshu.com/u/aa3d5c41012b\n4. 微信公众号","more":"<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>教育：硕士一枚</p>\n<p>技能：关注云计算、边缘计算、大数据等领域; 擅长Docker、Kubernetes、EdgeX Foundry、KubeEdge等云原生领域知识，最近在持续关注华为的昇腾生态产品：Ascend（华为自研AI芯片）、MindSpore（华为自研AI框架，类似于Tensorflow、Pytorch）</p>\n<p>联系方式：<br>     1. GitHub: <a href=\"https://github.com/yushanjin\">https://github.com/yushanjin</a><br>     2. Gitee: <a href=\"https://gitee.com/yushanjin\">https://gitee.com/yushanjin</a><br>     3. 简书：<a href=\"https://www.jianshu.com/u/aa3d5c41012b\">https://www.jianshu.com/u/aa3d5c41012b</a><br>     4. 微信公众号：云技术实践者</p>\n<p>希望大家相互多多交流！</p>\n"},{"title":"categories","date":"2020-11-26T03:20:56.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2020-11-26 11:20:56\ntype: categories\n---\n","updated":"2020-11-26T03:46:27.598Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cki73ih150002h0l7dx56d9hk","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2020-11-26T03:20:29.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2020-11-26 11:20:29\ntype: tags\n---\n","updated":"2020-11-26T03:45:55.518Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cki73ih180006h0l7b05pgjpl","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"search","date":"2020-11-26T05:38:20.000Z","type":"search","_content":"","source":"search/index.md","raw":"---\ntitle: search\ndate: 2020-11-26 13:38:20\ntype: \"search\"\n---\n","updated":"2020-11-26T05:38:55.673Z","path":"search/index.html","comments":1,"layout":"page","_id":"cki73ih190008h0l70m1od3m0","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"EMQ X Kuiper与EdgeX Foundry集成实践","date":"2020-12-01T02:34:44.000Z","_content":"\nKuiper是什么? EdgeX Foundry又是什么？\n\n# Kuiper\nEMQ X Kuiper 是 Golang 实现的轻量级物联网边缘分析、流式处理开源软件，可以运行在各类**资源受限的边缘设备**上。Kuiper 设计的一个主要目标就是将在云端运行的实时流式计算框架（比如 [Apache Spark](https://spark.apache.org/)，[Apache Storm](https://storm.apache.org/) 和 [Apache Flink](https://flink.apache.org/) 等）迁移到边缘端。Kuiper 参考了上述云端流式处理项目的架构与实现，结合边缘流式数据处理的特点，采用了编写**基于`源 (Source)`，`SQL (业务逻辑处理)`, `目标 (Sink)` 的规则引擎来实现边缘端的流式数据处理**。\n其架构如下：\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-82b09a3d6c9e5c33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n- 源 (Sources) ：内置支持 MQTT 数据的接入，扩展支持与EdgeX Foundry集成\n- SQL：流式数据逻辑处理，具备完整的数据分析处理能力\n   - 支持丰富的数据类型\n   - 支持4种时间窗口（滚动窗口、跳跃窗口、滑动窗口、会话窗口）\n   - 内置60+处理函数\n   - 提供类SQL语句对数据进行抽取、过滤、转换\n- 目标(Sinks)：内置支持 MQTT、HTTP等\n\nEMQ公司的相关产品，可以登陆其官网查询了解\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-b1643f3d02bea968.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n# EdgeX Foundry\nEdgeX Foundry是一个Linux 基金会运营的开源的，基于与硬件和操作系统完全无关的边缘计算物联网软件框架项目。其是一系列松耦合、开源的微服务集合，位于网络的边缘，可以与设备、传感器、执行器和其他物联网对象的物理世界进行交互。EdgeX Foundry 旨在创造一个互操作性、即插即用、模块化的物联网边缘计算的生态系统。\n其架构如下：\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-fd06dab15f5598af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n从架构图可以看出：\n**南侧（SouthBound）**:在物理领域内的所有物联网对象，以及与这些设备、传感器、执行器和其他物联网对象直接通信并从中收集数据的网络边缘，统称为“南侧”。\n**北侧（NorthBound）**:将数据收集、存储、聚合、分析并转换为信息的云(或企业系统)，以及与云通信的网络部分称为网络的“北侧”。\n因此，EdgeX使数据可以向北移动到云，也可以横向移动到其他网关，或返回到设备、传感器和执行器。\nEdgeX的重要服务层及微服务：\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-d0e4c5a219ab700d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n## 1、安装edgex\n参照官网文档：[https://fuji-docs.edgexfoundry.org/Ch-GettingStartedUsers.html](https://fuji-docs.edgexfoundry.org/Ch-GettingStartedUsers.html)\ndocker-compose启动\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-f5a8d9ed341b66b4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n相关服务正常\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-8ab54653eca76cc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n## 2、安装并启动kuiper\nsudo docker run -d --name kuiper --restart always -e EDGEX_SERVER=10.0.105.143 -e EDGEX_PORT=5563 -e EDGEX_SERVICE_SERVER=http://10.0.105.143:48080 emqx/kuiper:0.2.1\n\n环境变量具体参考：[https://hub.docker.com/r/emqx/kuiper](https://hub.docker.com/r/emqx/kuiper) 中的说明\nEDGEX_SERVER：edgex中zeromq的地址（zeromq集成到core data服务中了，可以看到core data服务暴露了两个端口一个5563，一个48080）\nEDGEX_PORT：edgex中zeromq的端口\nEDGEX_SERVICE_SERVER：edgex中core data的地址及端口\n这里我使用的kuiper镜像为 emqx/kuiper:0.2.1，为目前最新版本\n\n## 3、进入kuiper容器\nsudo docker exec -it kuiper /bin/sh\n\n## 4、查看日志\n/kuiper # cat log/stream.log\n\n## 5、创建流，订阅来自edgex的消息流\n/kuiper # bin/cli create stream demo'() WITH (FORMAT=\"JSON\", TYPE=\"edgex\")'\n\n## 6、创建规则文件，内容如下\n/kuiper # cat rule.txt\n```\n{\n  \"sql\": \"SELECT * from demo GROUP BY TUMBLINGWINDOW(ss, 10)\",\n  \"actions\": [\n    {\n      \"mqtt\": {\n        \"server\": \"tcp://broker.emqx.io:1883\",\n        \"topic\": \"result\",\n        \"clientId\": \"demo_001\"\n      }\n}\n  ]\n}\n```\n上述规则：Kuiper将接受edgex的数据，执行select操作（每10s钟），然后将处理后的数据发布到tcp://broker.emqx.io:1883（也可以换成其他的，比如broker.hivemq.com或者自己搭建的EMQ X edge）\n**注意：**Kuiper SQL相关的参考，见https://docs.emqx.io/kuiper/latest/cn/sqls/overview.html\n\n## 7、创建规则，命名为rule1\n/kuiper # bin/cli create rule rule1 -f rule.txt\n\n## 8、查看日志，可以看到已经连通edgex，相关的规则也已经创建\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-4f07b16e3735e2dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n## 9、查看规则状态\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-1349f6fd6210e627.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n## 10、使用mosquitto订阅broker.emqx.io中主题为result的消息\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-4fdbca2eb0e7af64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n分析结果，发布到文件（[https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/file.md](https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/file.md)）\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n   {\n      \"file\": {\n        \"path\": \"/tmp/result.txt\",\n        \"interval\": 5000\n      }\n   }\n  ]\n}\n```\n分析结果，发布到zmq（[https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/zmq.md](https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/zmq.md)）\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n  {\n    \"zmq\": {\n       \"server\": \"tcp://127.0.0.1:5563\",\n       \"topic\": \"temp\"\n      }\n   }\n  ]\n}\n```\n分析结果，通过调用rest（[https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/rest.md](https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/rest.md)）\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n  {\n    \"rest\": {\n      \"url\": \"http://127.0.0.1:48082/api/v1/device/cc622d99-f835-4e94-b5cb-b1eff8699dc4/command/51fce08a-ae19-4bce-b431-b9f363bba705\",       \n      \"method\": \"post\",\n      \"dataTemplate\": \"\\\"newKey\\\":\\\"{{.key}}\\\"\",\n      \"sendSingle\": true\n      }\n    }\n  ]\n}\n```\n**这个类似于EdgeX中core services中的command服务**\n\n分析结果，发布到edgex（[https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/edgex.md](https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/edgex.md)）\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n    {\n      \"edgex\": {\n        \"protocol\": \"tcp\",\n        \"host\": \"*\",\n        \"port\": 5571,\n        \"topic\": \"application\",\n        \"deviceName\": \"kuiper\",\n        \"contentType\": \"application/json\"\n      }\n    }\n  ]\n}\n```\n分析结果，发布到日志文件，默认在log/stream.log\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n    {\n      \"log\": {}\n    }\n  ]\n}\n```\n经验证，有些插件不完整\n\n```\n/kuiper # ./bin/cli getstatus rule rule1\nConnecting to 127.0.0.1:20498... \nStopped: cannot open /kuiper/plugins/sinks/File.so: plugin.Open(\"/kuiper/plugins/sinks/File.so\"): Error relocating /kuiper/plugins/sinks/File.so: __fprintf_chk: symbol not found.\n```\n\n\n参考：\n\n1、kuiper官方文档及github地址\n\n[https://docs.emqx.io/kuiper/latest/cn/](https://docs.emqx.io/kuiper/latest/cn/)\n\n[https://github.com/emqx/kuiper](https://github.com/emqx/kuiper)\n\n2、kuiper集成edgex文档[https://github.com/emqx/kuiper/blob/master/docs/en_US/edgex/edgex_rule_engine_tutorial.md](https://github.com/emqx/kuiper/blob/master/docs/en_US/edgex/edgex_rule_engine_tutorial.md)\n","source":"_posts/EMQ-X-Kuiper与EdgeX-Foundry集成实践.md","raw":"---\ntitle: EMQ X Kuiper与EdgeX Foundry集成实践\ndate: 2020-12-01 10:34:44\ntags:\n- kuiper\n- edgex\ncategories:\n- kuiper\n- edgex\n---\n\nKuiper是什么? EdgeX Foundry又是什么？\n\n# Kuiper\nEMQ X Kuiper 是 Golang 实现的轻量级物联网边缘分析、流式处理开源软件，可以运行在各类**资源受限的边缘设备**上。Kuiper 设计的一个主要目标就是将在云端运行的实时流式计算框架（比如 [Apache Spark](https://spark.apache.org/)，[Apache Storm](https://storm.apache.org/) 和 [Apache Flink](https://flink.apache.org/) 等）迁移到边缘端。Kuiper 参考了上述云端流式处理项目的架构与实现，结合边缘流式数据处理的特点，采用了编写**基于`源 (Source)`，`SQL (业务逻辑处理)`, `目标 (Sink)` 的规则引擎来实现边缘端的流式数据处理**。\n其架构如下：\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-82b09a3d6c9e5c33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n- 源 (Sources) ：内置支持 MQTT 数据的接入，扩展支持与EdgeX Foundry集成\n- SQL：流式数据逻辑处理，具备完整的数据分析处理能力\n   - 支持丰富的数据类型\n   - 支持4种时间窗口（滚动窗口、跳跃窗口、滑动窗口、会话窗口）\n   - 内置60+处理函数\n   - 提供类SQL语句对数据进行抽取、过滤、转换\n- 目标(Sinks)：内置支持 MQTT、HTTP等\n\nEMQ公司的相关产品，可以登陆其官网查询了解\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-b1643f3d02bea968.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n# EdgeX Foundry\nEdgeX Foundry是一个Linux 基金会运营的开源的，基于与硬件和操作系统完全无关的边缘计算物联网软件框架项目。其是一系列松耦合、开源的微服务集合，位于网络的边缘，可以与设备、传感器、执行器和其他物联网对象的物理世界进行交互。EdgeX Foundry 旨在创造一个互操作性、即插即用、模块化的物联网边缘计算的生态系统。\n其架构如下：\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-fd06dab15f5598af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n从架构图可以看出：\n**南侧（SouthBound）**:在物理领域内的所有物联网对象，以及与这些设备、传感器、执行器和其他物联网对象直接通信并从中收集数据的网络边缘，统称为“南侧”。\n**北侧（NorthBound）**:将数据收集、存储、聚合、分析并转换为信息的云(或企业系统)，以及与云通信的网络部分称为网络的“北侧”。\n因此，EdgeX使数据可以向北移动到云，也可以横向移动到其他网关，或返回到设备、传感器和执行器。\nEdgeX的重要服务层及微服务：\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-d0e4c5a219ab700d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n## 1、安装edgex\n参照官网文档：[https://fuji-docs.edgexfoundry.org/Ch-GettingStartedUsers.html](https://fuji-docs.edgexfoundry.org/Ch-GettingStartedUsers.html)\ndocker-compose启动\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-f5a8d9ed341b66b4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n相关服务正常\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-8ab54653eca76cc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n## 2、安装并启动kuiper\nsudo docker run -d --name kuiper --restart always -e EDGEX_SERVER=10.0.105.143 -e EDGEX_PORT=5563 -e EDGEX_SERVICE_SERVER=http://10.0.105.143:48080 emqx/kuiper:0.2.1\n\n环境变量具体参考：[https://hub.docker.com/r/emqx/kuiper](https://hub.docker.com/r/emqx/kuiper) 中的说明\nEDGEX_SERVER：edgex中zeromq的地址（zeromq集成到core data服务中了，可以看到core data服务暴露了两个端口一个5563，一个48080）\nEDGEX_PORT：edgex中zeromq的端口\nEDGEX_SERVICE_SERVER：edgex中core data的地址及端口\n这里我使用的kuiper镜像为 emqx/kuiper:0.2.1，为目前最新版本\n\n## 3、进入kuiper容器\nsudo docker exec -it kuiper /bin/sh\n\n## 4、查看日志\n/kuiper # cat log/stream.log\n\n## 5、创建流，订阅来自edgex的消息流\n/kuiper # bin/cli create stream demo'() WITH (FORMAT=\"JSON\", TYPE=\"edgex\")'\n\n## 6、创建规则文件，内容如下\n/kuiper # cat rule.txt\n```\n{\n  \"sql\": \"SELECT * from demo GROUP BY TUMBLINGWINDOW(ss, 10)\",\n  \"actions\": [\n    {\n      \"mqtt\": {\n        \"server\": \"tcp://broker.emqx.io:1883\",\n        \"topic\": \"result\",\n        \"clientId\": \"demo_001\"\n      }\n}\n  ]\n}\n```\n上述规则：Kuiper将接受edgex的数据，执行select操作（每10s钟），然后将处理后的数据发布到tcp://broker.emqx.io:1883（也可以换成其他的，比如broker.hivemq.com或者自己搭建的EMQ X edge）\n**注意：**Kuiper SQL相关的参考，见https://docs.emqx.io/kuiper/latest/cn/sqls/overview.html\n\n## 7、创建规则，命名为rule1\n/kuiper # bin/cli create rule rule1 -f rule.txt\n\n## 8、查看日志，可以看到已经连通edgex，相关的规则也已经创建\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-4f07b16e3735e2dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n## 9、查看规则状态\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-1349f6fd6210e627.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n## 10、使用mosquitto订阅broker.emqx.io中主题为result的消息\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-4fdbca2eb0e7af64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n分析结果，发布到文件（[https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/file.md](https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/file.md)）\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n   {\n      \"file\": {\n        \"path\": \"/tmp/result.txt\",\n        \"interval\": 5000\n      }\n   }\n  ]\n}\n```\n分析结果，发布到zmq（[https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/zmq.md](https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/zmq.md)）\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n  {\n    \"zmq\": {\n       \"server\": \"tcp://127.0.0.1:5563\",\n       \"topic\": \"temp\"\n      }\n   }\n  ]\n}\n```\n分析结果，通过调用rest（[https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/rest.md](https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/rest.md)）\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n  {\n    \"rest\": {\n      \"url\": \"http://127.0.0.1:48082/api/v1/device/cc622d99-f835-4e94-b5cb-b1eff8699dc4/command/51fce08a-ae19-4bce-b431-b9f363bba705\",       \n      \"method\": \"post\",\n      \"dataTemplate\": \"\\\"newKey\\\":\\\"{{.key}}\\\"\",\n      \"sendSingle\": true\n      }\n    }\n  ]\n}\n```\n**这个类似于EdgeX中core services中的command服务**\n\n分析结果，发布到edgex（[https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/edgex.md](https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/edgex.md)）\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n    {\n      \"edgex\": {\n        \"protocol\": \"tcp\",\n        \"host\": \"*\",\n        \"port\": 5571,\n        \"topic\": \"application\",\n        \"deviceName\": \"kuiper\",\n        \"contentType\": \"application/json\"\n      }\n    }\n  ]\n}\n```\n分析结果，发布到日志文件，默认在log/stream.log\n```\n{\n  \"sql\": \"SELECT * from demo\",\n  \"actions\": [\n    {\n      \"log\": {}\n    }\n  ]\n}\n```\n经验证，有些插件不完整\n\n```\n/kuiper # ./bin/cli getstatus rule rule1\nConnecting to 127.0.0.1:20498... \nStopped: cannot open /kuiper/plugins/sinks/File.so: plugin.Open(\"/kuiper/plugins/sinks/File.so\"): Error relocating /kuiper/plugins/sinks/File.so: __fprintf_chk: symbol not found.\n```\n\n\n参考：\n\n1、kuiper官方文档及github地址\n\n[https://docs.emqx.io/kuiper/latest/cn/](https://docs.emqx.io/kuiper/latest/cn/)\n\n[https://github.com/emqx/kuiper](https://github.com/emqx/kuiper)\n\n2、kuiper集成edgex文档[https://github.com/emqx/kuiper/blob/master/docs/en_US/edgex/edgex_rule_engine_tutorial.md](https://github.com/emqx/kuiper/blob/master/docs/en_US/edgex/edgex_rule_engine_tutorial.md)\n","slug":"EMQ-X-Kuiper与EdgeX-Foundry集成实践","published":1,"updated":"2020-12-01T02:36:45.542Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cki73ih130001h0l70tl2f2pn","content":"<p>Kuiper是什么? EdgeX Foundry又是什么？</p>\n<h1 id=\"Kuiper\"><a href=\"#Kuiper\" class=\"headerlink\" title=\"Kuiper\"></a>Kuiper</h1><p>EMQ X Kuiper 是 Golang 实现的轻量级物联网边缘分析、流式处理开源软件，可以运行在各类<strong>资源受限的边缘设备</strong>上。Kuiper 设计的一个主要目标就是将在云端运行的实时流式计算框架（比如 <a href=\"https://spark.apache.org/\">Apache Spark</a>，<a href=\"https://storm.apache.org/\">Apache Storm</a> 和 <a href=\"https://flink.apache.org/\">Apache Flink</a> 等）迁移到边缘端。Kuiper 参考了上述云端流式处理项目的架构与实现，结合边缘流式数据处理的特点，采用了编写<strong>基于<code>源 (Source)</code>，<code>SQL (业务逻辑处理)</code>, <code>目标 (Sink)</code> 的规则引擎来实现边缘端的流式数据处理</strong>。<br>其架构如下：<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-82b09a3d6c9e5c33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<ul>\n<li>源 (Sources) ：内置支持 MQTT 数据的接入，扩展支持与EdgeX Foundry集成</li>\n<li>SQL：流式数据逻辑处理，具备完整的数据分析处理能力<ul>\n<li>支持丰富的数据类型</li>\n<li>支持4种时间窗口（滚动窗口、跳跃窗口、滑动窗口、会话窗口）</li>\n<li>内置60+处理函数</li>\n<li>提供类SQL语句对数据进行抽取、过滤、转换</li>\n</ul>\n</li>\n<li>目标(Sinks)：内置支持 MQTT、HTTP等</li>\n</ul>\n<p>EMQ公司的相关产品，可以登陆其官网查询了解<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-b1643f3d02bea968.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h1 id=\"EdgeX-Foundry\"><a href=\"#EdgeX-Foundry\" class=\"headerlink\" title=\"EdgeX Foundry\"></a>EdgeX Foundry</h1><p>EdgeX Foundry是一个Linux 基金会运营的开源的，基于与硬件和操作系统完全无关的边缘计算物联网软件框架项目。其是一系列松耦合、开源的微服务集合，位于网络的边缘，可以与设备、传感器、执行器和其他物联网对象的物理世界进行交互。EdgeX Foundry 旨在创造一个互操作性、即插即用、模块化的物联网边缘计算的生态系统。<br>其架构如下：<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-fd06dab15f5598af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"><br>从架构图可以看出：<br><strong>南侧（SouthBound）</strong>:在物理领域内的所有物联网对象，以及与这些设备、传感器、执行器和其他物联网对象直接通信并从中收集数据的网络边缘，统称为“南侧”。<br><strong>北侧（NorthBound）</strong>:将数据收集、存储、聚合、分析并转换为信息的云(或企业系统)，以及与云通信的网络部分称为网络的“北侧”。<br>因此，EdgeX使数据可以向北移动到云，也可以横向移动到其他网关，或返回到设备、传感器和执行器。<br>EdgeX的重要服务层及微服务：<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-d0e4c5a219ab700d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h2 id=\"1、安装edgex\"><a href=\"#1、安装edgex\" class=\"headerlink\" title=\"1、安装edgex\"></a>1、安装edgex</h2><p>参照官网文档：<a href=\"https://fuji-docs.edgexfoundry.org/Ch-GettingStartedUsers.html\">https://fuji-docs.edgexfoundry.org/Ch-GettingStartedUsers.html</a><br>docker-compose启动<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-f5a8d9ed341b66b4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"><br>相关服务正常<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-8ab54653eca76cc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h2 id=\"2、安装并启动kuiper\"><a href=\"#2、安装并启动kuiper\" class=\"headerlink\" title=\"2、安装并启动kuiper\"></a>2、安装并启动kuiper</h2><p>sudo docker run -d –name kuiper –restart always -e EDGEX_SERVER=10.0.105.143 -e EDGEX_PORT=5563 -e EDGEX_SERVICE_SERVER=<a href=\"http://10.0.105.143:48080/\">http://10.0.105.143:48080</a> emqx/kuiper:0.2.1</p>\n<p>环境变量具体参考：<a href=\"https://hub.docker.com/r/emqx/kuiper\">https://hub.docker.com/r/emqx/kuiper</a> 中的说明<br>EDGEX_SERVER：edgex中zeromq的地址（zeromq集成到core data服务中了，可以看到core data服务暴露了两个端口一个5563，一个48080）<br>EDGEX_PORT：edgex中zeromq的端口<br>EDGEX_SERVICE_SERVER：edgex中core data的地址及端口<br>这里我使用的kuiper镜像为 emqx/kuiper:0.2.1，为目前最新版本</p>\n<h2 id=\"3、进入kuiper容器\"><a href=\"#3、进入kuiper容器\" class=\"headerlink\" title=\"3、进入kuiper容器\"></a>3、进入kuiper容器</h2><p>sudo docker exec -it kuiper /bin/sh</p>\n<h2 id=\"4、查看日志\"><a href=\"#4、查看日志\" class=\"headerlink\" title=\"4、查看日志\"></a>4、查看日志</h2><p>/kuiper # cat log/stream.log</p>\n<h2 id=\"5、创建流，订阅来自edgex的消息流\"><a href=\"#5、创建流，订阅来自edgex的消息流\" class=\"headerlink\" title=\"5、创建流，订阅来自edgex的消息流\"></a>5、创建流，订阅来自edgex的消息流</h2><p>/kuiper # bin/cli create stream demo’() WITH (FORMAT=”JSON”, TYPE=”edgex”)’</p>\n<h2 id=\"6、创建规则文件，内容如下\"><a href=\"#6、创建规则文件，内容如下\" class=\"headerlink\" title=\"6、创建规则文件，内容如下\"></a>6、创建规则文件，内容如下</h2><p>/kuiper # cat rule.txt</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo GROUP BY TUMBLINGWINDOW(ss, 10)&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;mqtt&quot;: &#123;</span><br><span class=\"line\">        &quot;server&quot;: &quot;tcp:&#x2F;&#x2F;broker.emqx.io:1883&quot;,</span><br><span class=\"line\">        &quot;topic&quot;: &quot;result&quot;,</span><br><span class=\"line\">        &quot;clientId&quot;: &quot;demo_001&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上述规则：Kuiper将接受edgex的数据，执行select操作（每10s钟），然后将处理后的数据发布到tcp://broker.emqx.io:1883（也可以换成其他的，比如broker.hivemq.com或者自己搭建的EMQ X edge）<br><strong>注意：</strong>Kuiper SQL相关的参考，见<a href=\"https://docs.emqx.io/kuiper/latest/cn/sqls/overview.html\">https://docs.emqx.io/kuiper/latest/cn/sqls/overview.html</a></p>\n<h2 id=\"7、创建规则，命名为rule1\"><a href=\"#7、创建规则，命名为rule1\" class=\"headerlink\" title=\"7、创建规则，命名为rule1\"></a>7、创建规则，命名为rule1</h2><p>/kuiper # bin/cli create rule rule1 -f rule.txt</p>\n<h2 id=\"8、查看日志，可以看到已经连通edgex，相关的规则也已经创建\"><a href=\"#8、查看日志，可以看到已经连通edgex，相关的规则也已经创建\" class=\"headerlink\" title=\"8、查看日志，可以看到已经连通edgex，相关的规则也已经创建\"></a>8、查看日志，可以看到已经连通edgex，相关的规则也已经创建</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-4f07b16e3735e2dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h2 id=\"9、查看规则状态\"><a href=\"#9、查看规则状态\" class=\"headerlink\" title=\"9、查看规则状态\"></a>9、查看规则状态</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-1349f6fd6210e627.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h2 id=\"10、使用mosquitto订阅broker-emqx-io中主题为result的消息\"><a href=\"#10、使用mosquitto订阅broker-emqx-io中主题为result的消息\" class=\"headerlink\" title=\"10、使用mosquitto订阅broker.emqx.io中主题为result的消息\"></a>10、使用mosquitto订阅broker.emqx.io中主题为result的消息</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-4fdbca2eb0e7af64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p>分析结果，发布到文件（<a href=\"https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/file.md\">https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/file.md</a>）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">   &#123;</span><br><span class=\"line\">      &quot;file&quot;: &#123;</span><br><span class=\"line\">        &quot;path&quot;: &quot;&#x2F;tmp&#x2F;result.txt&quot;,</span><br><span class=\"line\">        &quot;interval&quot;: 5000</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>分析结果，发布到zmq（<a href=\"https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/zmq.md\">https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/zmq.md</a>）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;zmq&quot;: &#123;</span><br><span class=\"line\">       &quot;server&quot;: &quot;tcp:&#x2F;&#x2F;127.0.0.1:5563&quot;,</span><br><span class=\"line\">       &quot;topic&quot;: &quot;temp&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>分析结果，通过调用rest（<a href=\"https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/rest.md\">https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/rest.md</a>）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;rest&quot;: &#123;</span><br><span class=\"line\">      &quot;url&quot;: &quot;http:&#x2F;&#x2F;127.0.0.1:48082&#x2F;api&#x2F;v1&#x2F;device&#x2F;cc622d99-f835-4e94-b5cb-b1eff8699dc4&#x2F;command&#x2F;51fce08a-ae19-4bce-b431-b9f363bba705&quot;,       </span><br><span class=\"line\">      &quot;method&quot;: &quot;post&quot;,</span><br><span class=\"line\">      &quot;dataTemplate&quot;: &quot;\\&quot;newKey\\&quot;:\\&quot;&#123;&#123;.key&#125;&#125;\\&quot;&quot;,</span><br><span class=\"line\">      &quot;sendSingle&quot;: true</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>这个类似于EdgeX中core services中的command服务</strong></p>\n<p>分析结果，发布到edgex（<a href=\"https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/edgex.md\">https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/edgex.md</a>）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;edgex&quot;: &#123;</span><br><span class=\"line\">        &quot;protocol&quot;: &quot;tcp&quot;,</span><br><span class=\"line\">        &quot;host&quot;: &quot;*&quot;,</span><br><span class=\"line\">        &quot;port&quot;: 5571,</span><br><span class=\"line\">        &quot;topic&quot;: &quot;application&quot;,</span><br><span class=\"line\">        &quot;deviceName&quot;: &quot;kuiper&quot;,</span><br><span class=\"line\">        &quot;contentType&quot;: &quot;application&#x2F;json&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>分析结果，发布到日志文件，默认在log/stream.log</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;log&quot;: &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>经验证，有些插件不完整</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;kuiper # .&#x2F;bin&#x2F;cli getstatus rule rule1</span><br><span class=\"line\">Connecting to 127.0.0.1:20498... </span><br><span class=\"line\">Stopped: cannot open &#x2F;kuiper&#x2F;plugins&#x2F;sinks&#x2F;File.so: plugin.Open(&quot;&#x2F;kuiper&#x2F;plugins&#x2F;sinks&#x2F;File.so&quot;): Error relocating &#x2F;kuiper&#x2F;plugins&#x2F;sinks&#x2F;File.so: __fprintf_chk: symbol not found.</span><br></pre></td></tr></table></figure>\n\n\n<p>参考：</p>\n<p>1、kuiper官方文档及github地址</p>\n<p><a href=\"https://docs.emqx.io/kuiper/latest/cn/\">https://docs.emqx.io/kuiper/latest/cn/</a></p>\n<p><a href=\"https://github.com/emqx/kuiper\">https://github.com/emqx/kuiper</a></p>\n<p>2、kuiper集成edgex文档<a href=\"https://github.com/emqx/kuiper/blob/master/docs/en_US/edgex/edgex_rule_engine_tutorial.md\">https://github.com/emqx/kuiper/blob/master/docs/en_US/edgex/edgex_rule_engine_tutorial.md</a></p>\n","site":{"data":{}},"excerpt":"Kuiper是什么? EdgeX Foundry又是什么？\n\nKuiper\nEMQ X Kuiper 是 Golang 实现的轻量级物联网边缘分析、流式处理开源软件，可以运行在各类资源受限的边缘设备上。Kuiper 设计的一个主要目标就是将在云端运行的实时流式计算框架（比如Apache Spark，Apache Storm和Apache Flink等）迁移到边缘端。Kuiper 参考了上述云端流式处理项目的架构与实现，结合边缘流式数据处理的特点，采用了编写基于源 (Source)，SQL (业务逻辑处理),目标 (Sink)的规则引擎来实现边缘端的流式数据处理。\n其架构如下：\n\n\n * 源 (","more":"<p>Kuiper是什么? EdgeX Foundry又是什么？</p>\n<h1 id=\"Kuiper\"><a href=\"#Kuiper\" class=\"headerlink\" title=\"Kuiper\"></a>Kuiper</h1><p>EMQ X Kuiper 是 Golang 实现的轻量级物联网边缘分析、流式处理开源软件，可以运行在各类<strong>资源受限的边缘设备</strong>上。Kuiper 设计的一个主要目标就是将在云端运行的实时流式计算框架（比如 <a href=\"https://spark.apache.org/\">Apache Spark</a>，<a href=\"https://storm.apache.org/\">Apache Storm</a> 和 <a href=\"https://flink.apache.org/\">Apache Flink</a> 等）迁移到边缘端。Kuiper 参考了上述云端流式处理项目的架构与实现，结合边缘流式数据处理的特点，采用了编写<strong>基于<code>源 (Source)</code>，<code>SQL (业务逻辑处理)</code>, <code>目标 (Sink)</code> 的规则引擎来实现边缘端的流式数据处理</strong>。<br>其架构如下：<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-82b09a3d6c9e5c33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<ul>\n<li>源 (Sources) ：内置支持 MQTT 数据的接入，扩展支持与EdgeX Foundry集成</li>\n<li>SQL：流式数据逻辑处理，具备完整的数据分析处理能力<ul>\n<li>支持丰富的数据类型</li>\n<li>支持4种时间窗口（滚动窗口、跳跃窗口、滑动窗口、会话窗口）</li>\n<li>内置60+处理函数</li>\n<li>提供类SQL语句对数据进行抽取、过滤、转换</li>\n</ul>\n</li>\n<li>目标(Sinks)：内置支持 MQTT、HTTP等</li>\n</ul>\n<p>EMQ公司的相关产品，可以登陆其官网查询了解<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-b1643f3d02bea968.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h1 id=\"EdgeX-Foundry\"><a href=\"#EdgeX-Foundry\" class=\"headerlink\" title=\"EdgeX Foundry\"></a>EdgeX Foundry</h1><p>EdgeX Foundry是一个Linux 基金会运营的开源的，基于与硬件和操作系统完全无关的边缘计算物联网软件框架项目。其是一系列松耦合、开源的微服务集合，位于网络的边缘，可以与设备、传感器、执行器和其他物联网对象的物理世界进行交互。EdgeX Foundry 旨在创造一个互操作性、即插即用、模块化的物联网边缘计算的生态系统。<br>其架构如下：<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-fd06dab15f5598af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"><br>从架构图可以看出：<br><strong>南侧（SouthBound）</strong>:在物理领域内的所有物联网对象，以及与这些设备、传感器、执行器和其他物联网对象直接通信并从中收集数据的网络边缘，统称为“南侧”。<br><strong>北侧（NorthBound）</strong>:将数据收集、存储、聚合、分析并转换为信息的云(或企业系统)，以及与云通信的网络部分称为网络的“北侧”。<br>因此，EdgeX使数据可以向北移动到云，也可以横向移动到其他网关，或返回到设备、传感器和执行器。<br>EdgeX的重要服务层及微服务：<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-d0e4c5a219ab700d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h2 id=\"1、安装edgex\"><a href=\"#1、安装edgex\" class=\"headerlink\" title=\"1、安装edgex\"></a>1、安装edgex</h2><p>参照官网文档：<a href=\"https://fuji-docs.edgexfoundry.org/Ch-GettingStartedUsers.html\">https://fuji-docs.edgexfoundry.org/Ch-GettingStartedUsers.html</a><br>docker-compose启动<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-f5a8d9ed341b66b4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"><br>相关服务正常<br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-8ab54653eca76cc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h2 id=\"2、安装并启动kuiper\"><a href=\"#2、安装并启动kuiper\" class=\"headerlink\" title=\"2、安装并启动kuiper\"></a>2、安装并启动kuiper</h2><p>sudo docker run -d –name kuiper –restart always -e EDGEX_SERVER=10.0.105.143 -e EDGEX_PORT=5563 -e EDGEX_SERVICE_SERVER=<a href=\"http://10.0.105.143:48080/\">http://10.0.105.143:48080</a> emqx/kuiper:0.2.1</p>\n<p>环境变量具体参考：<a href=\"https://hub.docker.com/r/emqx/kuiper\">https://hub.docker.com/r/emqx/kuiper</a> 中的说明<br>EDGEX_SERVER：edgex中zeromq的地址（zeromq集成到core data服务中了，可以看到core data服务暴露了两个端口一个5563，一个48080）<br>EDGEX_PORT：edgex中zeromq的端口<br>EDGEX_SERVICE_SERVER：edgex中core data的地址及端口<br>这里我使用的kuiper镜像为 emqx/kuiper:0.2.1，为目前最新版本</p>\n<h2 id=\"3、进入kuiper容器\"><a href=\"#3、进入kuiper容器\" class=\"headerlink\" title=\"3、进入kuiper容器\"></a>3、进入kuiper容器</h2><p>sudo docker exec -it kuiper /bin/sh</p>\n<h2 id=\"4、查看日志\"><a href=\"#4、查看日志\" class=\"headerlink\" title=\"4、查看日志\"></a>4、查看日志</h2><p>/kuiper # cat log/stream.log</p>\n<h2 id=\"5、创建流，订阅来自edgex的消息流\"><a href=\"#5、创建流，订阅来自edgex的消息流\" class=\"headerlink\" title=\"5、创建流，订阅来自edgex的消息流\"></a>5、创建流，订阅来自edgex的消息流</h2><p>/kuiper # bin/cli create stream demo’() WITH (FORMAT=”JSON”, TYPE=”edgex”)’</p>\n<h2 id=\"6、创建规则文件，内容如下\"><a href=\"#6、创建规则文件，内容如下\" class=\"headerlink\" title=\"6、创建规则文件，内容如下\"></a>6、创建规则文件，内容如下</h2><p>/kuiper # cat rule.txt</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo GROUP BY TUMBLINGWINDOW(ss, 10)&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;mqtt&quot;: &#123;</span><br><span class=\"line\">        &quot;server&quot;: &quot;tcp:&#x2F;&#x2F;broker.emqx.io:1883&quot;,</span><br><span class=\"line\">        &quot;topic&quot;: &quot;result&quot;,</span><br><span class=\"line\">        &quot;clientId&quot;: &quot;demo_001&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上述规则：Kuiper将接受edgex的数据，执行select操作（每10s钟），然后将处理后的数据发布到tcp://broker.emqx.io:1883（也可以换成其他的，比如broker.hivemq.com或者自己搭建的EMQ X edge）<br><strong>注意：</strong>Kuiper SQL相关的参考，见<a href=\"https://docs.emqx.io/kuiper/latest/cn/sqls/overview.html\">https://docs.emqx.io/kuiper/latest/cn/sqls/overview.html</a></p>\n<h2 id=\"7、创建规则，命名为rule1\"><a href=\"#7、创建规则，命名为rule1\" class=\"headerlink\" title=\"7、创建规则，命名为rule1\"></a>7、创建规则，命名为rule1</h2><p>/kuiper # bin/cli create rule rule1 -f rule.txt</p>\n<h2 id=\"8、查看日志，可以看到已经连通edgex，相关的规则也已经创建\"><a href=\"#8、查看日志，可以看到已经连通edgex，相关的规则也已经创建\" class=\"headerlink\" title=\"8、查看日志，可以看到已经连通edgex，相关的规则也已经创建\"></a>8、查看日志，可以看到已经连通edgex，相关的规则也已经创建</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-4f07b16e3735e2dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h2 id=\"9、查看规则状态\"><a href=\"#9、查看规则状态\" class=\"headerlink\" title=\"9、查看规则状态\"></a>9、查看规则状态</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-1349f6fd6210e627.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h2 id=\"10、使用mosquitto订阅broker-emqx-io中主题为result的消息\"><a href=\"#10、使用mosquitto订阅broker-emqx-io中主题为result的消息\" class=\"headerlink\" title=\"10、使用mosquitto订阅broker.emqx.io中主题为result的消息\"></a>10、使用mosquitto订阅broker.emqx.io中主题为result的消息</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-4fdbca2eb0e7af64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p>分析结果，发布到文件（<a href=\"https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/file.md\">https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/file.md</a>）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">   &#123;</span><br><span class=\"line\">      &quot;file&quot;: &#123;</span><br><span class=\"line\">        &quot;path&quot;: &quot;&#x2F;tmp&#x2F;result.txt&quot;,</span><br><span class=\"line\">        &quot;interval&quot;: 5000</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>分析结果，发布到zmq（<a href=\"https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/zmq.md\">https://github.com/emqx/kuiper/blob/master/docs/zh_CN/plugins/sinks/zmq.md</a>）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;zmq&quot;: &#123;</span><br><span class=\"line\">       &quot;server&quot;: &quot;tcp:&#x2F;&#x2F;127.0.0.1:5563&quot;,</span><br><span class=\"line\">       &quot;topic&quot;: &quot;temp&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>分析结果，通过调用rest（<a href=\"https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/rest.md\">https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/rest.md</a>）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;rest&quot;: &#123;</span><br><span class=\"line\">      &quot;url&quot;: &quot;http:&#x2F;&#x2F;127.0.0.1:48082&#x2F;api&#x2F;v1&#x2F;device&#x2F;cc622d99-f835-4e94-b5cb-b1eff8699dc4&#x2F;command&#x2F;51fce08a-ae19-4bce-b431-b9f363bba705&quot;,       </span><br><span class=\"line\">      &quot;method&quot;: &quot;post&quot;,</span><br><span class=\"line\">      &quot;dataTemplate&quot;: &quot;\\&quot;newKey\\&quot;:\\&quot;&#123;&#123;.key&#125;&#125;\\&quot;&quot;,</span><br><span class=\"line\">      &quot;sendSingle&quot;: true</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>这个类似于EdgeX中core services中的command服务</strong></p>\n<p>分析结果，发布到edgex（<a href=\"https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/edgex.md\">https://github.com/emqx/kuiper/blob/master/docs/en_US/rules/sinks/edgex.md</a>）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;edgex&quot;: &#123;</span><br><span class=\"line\">        &quot;protocol&quot;: &quot;tcp&quot;,</span><br><span class=\"line\">        &quot;host&quot;: &quot;*&quot;,</span><br><span class=\"line\">        &quot;port&quot;: 5571,</span><br><span class=\"line\">        &quot;topic&quot;: &quot;application&quot;,</span><br><span class=\"line\">        &quot;deviceName&quot;: &quot;kuiper&quot;,</span><br><span class=\"line\">        &quot;contentType&quot;: &quot;application&#x2F;json&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>分析结果，发布到日志文件，默认在log/stream.log</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;sql&quot;: &quot;SELECT * from demo&quot;,</span><br><span class=\"line\">  &quot;actions&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;log&quot;: &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>经验证，有些插件不完整</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;kuiper # .&#x2F;bin&#x2F;cli getstatus rule rule1</span><br><span class=\"line\">Connecting to 127.0.0.1:20498... </span><br><span class=\"line\">Stopped: cannot open &#x2F;kuiper&#x2F;plugins&#x2F;sinks&#x2F;File.so: plugin.Open(&quot;&#x2F;kuiper&#x2F;plugins&#x2F;sinks&#x2F;File.so&quot;): Error relocating &#x2F;kuiper&#x2F;plugins&#x2F;sinks&#x2F;File.so: __fprintf_chk: symbol not found.</span><br></pre></td></tr></table></figure>\n\n\n<p>参考：</p>\n<p>1、kuiper官方文档及github地址</p>\n<p><a href=\"https://docs.emqx.io/kuiper/latest/cn/\">https://docs.emqx.io/kuiper/latest/cn/</a></p>\n<p><a href=\"https://github.com/emqx/kuiper\">https://github.com/emqx/kuiper</a></p>\n<p>2、kuiper集成edgex文档<a href=\"https://github.com/emqx/kuiper/blob/master/docs/en_US/edgex/edgex_rule_engine_tutorial.md\">https://github.com/emqx/kuiper/blob/master/docs/en_US/edgex/edgex_rule_engine_tutorial.md</a></p>\n"},{"title":"Ubuntu搭建Kubernetes集群","_content":"本文介绍如何在Ubuntu系统上搭建Kubernetes集群。\n\n\n# 前提：\n1、操作系统Ubuntu 19.10\n```\nroot@ubuntu-001:~# uname -a\nLinux ubuntu-001 5.3.0-51-generic #44-Ubuntu SMP Wed Apr 22 21:09:44 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\nroot@ubuntu-001:~# lsb_release -a\nNo LSB modules are available.\nDistributor ID:\tUbuntu\nDescription:\tUbuntu 19.10\nRelease:\t19.10\nCodename:\teoan\n```\n2、通过阿里云相关镜像源安装\n\n\n**以下均为root用户下操作**\n\n# 操作步骤：\n## 1、修改主机名\n```\nhostnamectl set-hostname ubuntu-001\n```\n\n## 2、关闭防火墙\n```\napt-get install ufw\nufw disable\n```\n\n## 3、安装docker\n**安装必要的工具及GPG证书**\n```\napt-get update\napt-get -y install apt-transport-https ca-certificates curl software-properties-common\ncurl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -\n```\n\n**配置阿里云docker源**\n```\nadd-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\n\n```\n\n注意： 如果是arm架构系统，请对应更换， 如：add-apt-repository \"deb [arch=arm64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\n\n\n**查询docker版本（否则默认安装最新的版本）**\n```\napt-cache madison docker-ce\n#   docker-ce | 5:19.03.8~3-0~ubuntu-eoan | https://mirrors.aliyun.com/docker-ce/linux/ubuntu eoan/stable amd64 Packages\n#   docker-ce | 5:19.03.7~3-0~ubuntu-eoan | https://mirrors.aliyun.com/docker-ce/linux/ubuntu eoan/stable amd64 Packages\n#   docker-ce | 5:19.03.6~3-0~ubuntu-eoan | https://mirrors.aliyun.com/docker-ce/linux/ubuntu eoan/stable amd64 Packages\n```\n\n**安装指定版本docker**\n```\napt-get -y update\napt-get -y install docker-ce=5:19.03.8~3-0~ubuntu-eoan\n```\n\n**启动docker**\n```\nsystemctl enable docker && systemctl start docker\n```\n\n**查询docker服务状态**\n```\nsystemctl status docker\n```\n\n**查看docker版本**\n```\ndocker version\n```\n\n## 4、安装kubelet、kubeadm 和 kubectl\n**配置kubernetes.repo的源，由于官方源国内无法访问，这里使用阿里云源**\n\n```\ncurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - \ncat <<EOF >/etc/apt/sources.list.d/kubernetes.list\ndeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\nEOF  \n\n```\n\n**在所有节点上安装指定版本 kubelet、kubeadm 和 kubectl**\n```\napt-get update\napt-cache madison kubectl\napt-cache madison kubeadm\napt-cache madison kubelet\napt-get install -y kubelet=1.18.0-00 kubeadm=1.18.0-00 kubectl=1.18.0-00\n\n```\n\n**启动kubelet服务**\n```\nsystemctl enable kubelet && systemctl start kubelet \n```\n\n## 5、关闭swap分区\n```\nswapoff -a\n```\n\n## 6、初始化master节点\n\n```\nkubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --pod-network-cidr=10.244.0.0/16 --token-ttl 0 --ignore-preflight-errors=Swap\n```\n\n```\nroot@ubuntu-001:~# kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --pod-network-cidr=10.244.0.0/16 --token-ttl 0 --ignore-preflight-errors=Swap\nW0507 17:11:30.761887   14961 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]\n[init] Using Kubernetes version: v1.18.0\n[preflight] Running pre-flight checks\n\t[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [ubuntu-001 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.105.107]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [ubuntu-001 localhost] and IPs [10.0.105.107 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [ubuntu-001 localhost] and IPs [10.0.105.107 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\nW0507 17:11:34.680144   14961 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\nW0507 17:11:34.682546   14961 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 20.502602 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.18\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node ubuntu-001 as control-plane by adding the label \"node-role.kubernetes.io/master=''\"\n[mark-control-plane] Marking the node ubuntu-001 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: 10y2lc.v55p1f47j3lp15gg\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 10.0.105.107:6443 --token 10y2lc.v55p1f47j3lp15gg \\\n    --discovery-token-ca-cert-hash sha256:1093b027cf31d755dcaa7109ba890962c140e2d6e9c46bf4207a0c519ce7bf36 \n\n```\n按照kubeadm init成功后打印提示，继续操作：\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\nkubectl get nodes查询到节点处于NotReady状态，是因为网络插件还未就位，也就是这里要求运行的\n```\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\nhttps://kubernetes.io/docs/concepts/cluster-administration/addons/\n```\n\n如果要暂时忽略让节点Ready，将如下文件的--network-plugin=cni字段去掉, (该文件是在kubeadm init或者kubeadm join过程中生成的), 修改完后重启kubelet即可(systemctl restart kubelet)\n\n```\nroot@ubuntu-001:~# cat /var/lib/kubelet/kubeadm-flags.env\nKUBELET_KUBEADM_ARGS=\"--cgroup-driver=cgroupfs --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.2 --resolv-conf=/run/systemd/resolve/resolv.conf\"\n```\n安装flannel，kubectl apply -f kube-flannel.yaml\n\n## 7、join node节点\n```\nroot@ubuntu-002:~# kubeadm join 10.0.105.107:6443 --token 10y2lc.v55p1f47j3lp15gg --discovery-token-ca-cert-hash sha256:1093b027cf31d755dcaa7109ba890962c140e2d6e9c46bf4207a0c519ce7bf36\nW0507 17:16:18.524687   26000 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.\n[preflight] Running pre-flight checks\n\t[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/\n[preflight] Reading configuration from the cluster...\n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'\n[kubelet-start] Downloading configuration for the kubelet from the \"kubelet-config-1.18\" ConfigMap in the kube-system namespace\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Starting the kubelet\n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...\n\nThis node has joined the cluster:\n* Certificate signing request was sent to apiserver and a response was received.\n* The Kubelet was informed of the new secure connection details.\n\nRun 'kubectl get nodes' on the control-plane to see this node join the cluster.\n\n```\n\n## 查询所有node及pod状态\n```\nkubectl get node -o wide\nkubectl get pod --all-namespaces -o wide\n```\n\n## 增加kubectl命令自动补全功能\n```\nsource <(kubectl completion bash)\n```\n\n## 默认master节点不会调度pod，去掉此限制(可选做)\n``` \nkubectl taint node ubuntu-001 node-role.kubernetes.io/master:NoSchedule-\n```\nubuntu-001为主机名\n\n## node节点ROLES默认显示none，将其修改为显示worker(可选做)\n```\nkubectl label node ubuntu-002 node-role.kubernetes.io/worker= --overwrite\nkubectl label node ubuntu-003 node-role.kubernetes.io/worker= --overwrite\nroot@ubuntu-001:~# kubectl get node -o wide\nNAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION     CONTAINER-RUNTIME\nubuntu-001   Ready    master   16h   v1.18.0   10.0.105.107   <none>        Ubuntu 19.10   5.3.0-51-generic   docker://19.3.8\nubuntu-002   Ready    worker   16h   v1.18.0   10.0.105.21    <none>        Ubuntu 19.10   5.3.0-46-generic   docker://19.3.8\nubuntu-003   Ready    worker   61m   v1.18.0   10.0.105.62    <none>        Ubuntu 19.10   5.3.0-46-generic   docker://19.3.8\n```\n\n","source":"_posts/kubernetes_install_on_ubuntu.md","raw":"---\ntitle: Ubuntu搭建Kubernetes集群\ntags: \n- 云计算\n- 边缘计算\n- kubernetes\ncategories:\n- kubernetes\n---\n本文介绍如何在Ubuntu系统上搭建Kubernetes集群。\n\n\n# 前提：\n1、操作系统Ubuntu 19.10\n```\nroot@ubuntu-001:~# uname -a\nLinux ubuntu-001 5.3.0-51-generic #44-Ubuntu SMP Wed Apr 22 21:09:44 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\nroot@ubuntu-001:~# lsb_release -a\nNo LSB modules are available.\nDistributor ID:\tUbuntu\nDescription:\tUbuntu 19.10\nRelease:\t19.10\nCodename:\teoan\n```\n2、通过阿里云相关镜像源安装\n\n\n**以下均为root用户下操作**\n\n# 操作步骤：\n## 1、修改主机名\n```\nhostnamectl set-hostname ubuntu-001\n```\n\n## 2、关闭防火墙\n```\napt-get install ufw\nufw disable\n```\n\n## 3、安装docker\n**安装必要的工具及GPG证书**\n```\napt-get update\napt-get -y install apt-transport-https ca-certificates curl software-properties-common\ncurl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -\n```\n\n**配置阿里云docker源**\n```\nadd-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\n\n```\n\n注意： 如果是arm架构系统，请对应更换， 如：add-apt-repository \"deb [arch=arm64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\n\n\n**查询docker版本（否则默认安装最新的版本）**\n```\napt-cache madison docker-ce\n#   docker-ce | 5:19.03.8~3-0~ubuntu-eoan | https://mirrors.aliyun.com/docker-ce/linux/ubuntu eoan/stable amd64 Packages\n#   docker-ce | 5:19.03.7~3-0~ubuntu-eoan | https://mirrors.aliyun.com/docker-ce/linux/ubuntu eoan/stable amd64 Packages\n#   docker-ce | 5:19.03.6~3-0~ubuntu-eoan | https://mirrors.aliyun.com/docker-ce/linux/ubuntu eoan/stable amd64 Packages\n```\n\n**安装指定版本docker**\n```\napt-get -y update\napt-get -y install docker-ce=5:19.03.8~3-0~ubuntu-eoan\n```\n\n**启动docker**\n```\nsystemctl enable docker && systemctl start docker\n```\n\n**查询docker服务状态**\n```\nsystemctl status docker\n```\n\n**查看docker版本**\n```\ndocker version\n```\n\n## 4、安装kubelet、kubeadm 和 kubectl\n**配置kubernetes.repo的源，由于官方源国内无法访问，这里使用阿里云源**\n\n```\ncurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - \ncat <<EOF >/etc/apt/sources.list.d/kubernetes.list\ndeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\nEOF  \n\n```\n\n**在所有节点上安装指定版本 kubelet、kubeadm 和 kubectl**\n```\napt-get update\napt-cache madison kubectl\napt-cache madison kubeadm\napt-cache madison kubelet\napt-get install -y kubelet=1.18.0-00 kubeadm=1.18.0-00 kubectl=1.18.0-00\n\n```\n\n**启动kubelet服务**\n```\nsystemctl enable kubelet && systemctl start kubelet \n```\n\n## 5、关闭swap分区\n```\nswapoff -a\n```\n\n## 6、初始化master节点\n\n```\nkubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --pod-network-cidr=10.244.0.0/16 --token-ttl 0 --ignore-preflight-errors=Swap\n```\n\n```\nroot@ubuntu-001:~# kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --pod-network-cidr=10.244.0.0/16 --token-ttl 0 --ignore-preflight-errors=Swap\nW0507 17:11:30.761887   14961 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]\n[init] Using Kubernetes version: v1.18.0\n[preflight] Running pre-flight checks\n\t[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [ubuntu-001 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.105.107]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [ubuntu-001 localhost] and IPs [10.0.105.107 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [ubuntu-001 localhost] and IPs [10.0.105.107 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\nW0507 17:11:34.680144   14961 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\nW0507 17:11:34.682546   14961 manifests.go:225] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 20.502602 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.18\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node ubuntu-001 as control-plane by adding the label \"node-role.kubernetes.io/master=''\"\n[mark-control-plane] Marking the node ubuntu-001 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: 10y2lc.v55p1f47j3lp15gg\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 10.0.105.107:6443 --token 10y2lc.v55p1f47j3lp15gg \\\n    --discovery-token-ca-cert-hash sha256:1093b027cf31d755dcaa7109ba890962c140e2d6e9c46bf4207a0c519ce7bf36 \n\n```\n按照kubeadm init成功后打印提示，继续操作：\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\nkubectl get nodes查询到节点处于NotReady状态，是因为网络插件还未就位，也就是这里要求运行的\n```\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\nhttps://kubernetes.io/docs/concepts/cluster-administration/addons/\n```\n\n如果要暂时忽略让节点Ready，将如下文件的--network-plugin=cni字段去掉, (该文件是在kubeadm init或者kubeadm join过程中生成的), 修改完后重启kubelet即可(systemctl restart kubelet)\n\n```\nroot@ubuntu-001:~# cat /var/lib/kubelet/kubeadm-flags.env\nKUBELET_KUBEADM_ARGS=\"--cgroup-driver=cgroupfs --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.2 --resolv-conf=/run/systemd/resolve/resolv.conf\"\n```\n安装flannel，kubectl apply -f kube-flannel.yaml\n\n## 7、join node节点\n```\nroot@ubuntu-002:~# kubeadm join 10.0.105.107:6443 --token 10y2lc.v55p1f47j3lp15gg --discovery-token-ca-cert-hash sha256:1093b027cf31d755dcaa7109ba890962c140e2d6e9c46bf4207a0c519ce7bf36\nW0507 17:16:18.524687   26000 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.\n[preflight] Running pre-flight checks\n\t[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/\n[preflight] Reading configuration from the cluster...\n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'\n[kubelet-start] Downloading configuration for the kubelet from the \"kubelet-config-1.18\" ConfigMap in the kube-system namespace\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Starting the kubelet\n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...\n\nThis node has joined the cluster:\n* Certificate signing request was sent to apiserver and a response was received.\n* The Kubelet was informed of the new secure connection details.\n\nRun 'kubectl get nodes' on the control-plane to see this node join the cluster.\n\n```\n\n## 查询所有node及pod状态\n```\nkubectl get node -o wide\nkubectl get pod --all-namespaces -o wide\n```\n\n## 增加kubectl命令自动补全功能\n```\nsource <(kubectl completion bash)\n```\n\n## 默认master节点不会调度pod，去掉此限制(可选做)\n``` \nkubectl taint node ubuntu-001 node-role.kubernetes.io/master:NoSchedule-\n```\nubuntu-001为主机名\n\n## node节点ROLES默认显示none，将其修改为显示worker(可选做)\n```\nkubectl label node ubuntu-002 node-role.kubernetes.io/worker= --overwrite\nkubectl label node ubuntu-003 node-role.kubernetes.io/worker= --overwrite\nroot@ubuntu-001:~# kubectl get node -o wide\nNAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION     CONTAINER-RUNTIME\nubuntu-001   Ready    master   16h   v1.18.0   10.0.105.107   <none>        Ubuntu 19.10   5.3.0-51-generic   docker://19.3.8\nubuntu-002   Ready    worker   16h   v1.18.0   10.0.105.21    <none>        Ubuntu 19.10   5.3.0-46-generic   docker://19.3.8\nubuntu-003   Ready    worker   61m   v1.18.0   10.0.105.62    <none>        Ubuntu 19.10   5.3.0-46-generic   docker://19.3.8\n```\n\n","slug":"kubernetes_install_on_ubuntu","published":1,"date":"2020-11-26T08:41:01.137Z","updated":"2020-11-26T08:41:01.137Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cki73ih160003h0l70l0v4m1y","content":"<p>本文介绍如何在Ubuntu系统上搭建Kubernetes集群。</p>\n<h1 id=\"前提：\"><a href=\"#前提：\" class=\"headerlink\" title=\"前提：\"></a>前提：</h1><p>1、操作系统Ubuntu 19.10</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# uname -a</span><br><span class=\"line\">Linux ubuntu-001 5.3.0-51-generic #44-Ubuntu SMP Wed Apr 22 21:09:44 UTC 2020 x86_64 x86_64 x86_64 GNU&#x2F;Linux</span><br><span class=\"line\">root@ubuntu-001:~# lsb_release -a</span><br><span class=\"line\">No LSB modules are available.</span><br><span class=\"line\">Distributor ID:\tUbuntu</span><br><span class=\"line\">Description:\tUbuntu 19.10</span><br><span class=\"line\">Release:\t19.10</span><br><span class=\"line\">Codename:\teoan</span><br></pre></td></tr></table></figure>\n<p>2、通过阿里云相关镜像源安装</p>\n<p><strong>以下均为root用户下操作</strong></p>\n<h1 id=\"操作步骤：\"><a href=\"#操作步骤：\" class=\"headerlink\" title=\"操作步骤：\"></a>操作步骤：</h1><h2 id=\"1、修改主机名\"><a href=\"#1、修改主机名\" class=\"headerlink\" title=\"1、修改主机名\"></a>1、修改主机名</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostnamectl set-hostname ubuntu-001</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2、关闭防火墙\"><a href=\"#2、关闭防火墙\" class=\"headerlink\" title=\"2、关闭防火墙\"></a>2、关闭防火墙</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get install ufw</span><br><span class=\"line\">ufw disable</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、安装docker\"><a href=\"#3、安装docker\" class=\"headerlink\" title=\"3、安装docker\"></a>3、安装docker</h2><p><strong>安装必要的工具及GPG证书</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get update</span><br><span class=\"line\">apt-get -y install apt-transport-https ca-certificates curl software-properties-common</span><br><span class=\"line\">curl -fsSL https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add -</span><br></pre></td></tr></table></figure>\n\n<p><strong>配置阿里云docker源</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add-apt-repository &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu $(lsb_release -cs) stable&quot;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>注意： 如果是arm架构系统，请对应更换， 如：add-apt-repository “deb [arch=arm64] <a href=\"https://mirrors.aliyun.com/docker-ce/linux/ubuntu\">https://mirrors.aliyun.com/docker-ce/linux/ubuntu</a> $(lsb_release -cs) stable”</p>\n<p><strong>查询docker版本（否则默认安装最新的版本）</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-cache madison docker-ce</span><br><span class=\"line\">#   docker-ce | 5:19.03.8~3-0~ubuntu-eoan | https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu eoan&#x2F;stable amd64 Packages</span><br><span class=\"line\">#   docker-ce | 5:19.03.7~3-0~ubuntu-eoan | https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu eoan&#x2F;stable amd64 Packages</span><br><span class=\"line\">#   docker-ce | 5:19.03.6~3-0~ubuntu-eoan | https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu eoan&#x2F;stable amd64 Packages</span><br></pre></td></tr></table></figure>\n\n<p><strong>安装指定版本docker</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get -y update</span><br><span class=\"line\">apt-get -y install docker-ce&#x3D;5:19.03.8~3-0~ubuntu-eoan</span><br></pre></td></tr></table></figure>\n\n<p><strong>启动docker</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure>\n\n<p><strong>查询docker服务状态</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl status docker</span><br></pre></td></tr></table></figure>\n\n<p><strong>查看docker版本</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker version</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4、安装kubelet、kubeadm-和-kubectl\"><a href=\"#4、安装kubelet、kubeadm-和-kubectl\" class=\"headerlink\" title=\"4、安装kubelet、kubeadm 和 kubectl\"></a>4、安装kubelet、kubeadm 和 kubectl</h2><p><strong>配置kubernetes.repo的源，由于官方源国内无法访问，这里使用阿里云源</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;apt&#x2F;doc&#x2F;apt-key.gpg | apt-key add - </span><br><span class=\"line\">cat &lt;&lt;EOF &gt;&#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;kubernetes.list</span><br><span class=\"line\">deb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;apt&#x2F; kubernetes-xenial main</span><br><span class=\"line\">EOF  </span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><strong>在所有节点上安装指定版本 kubelet、kubeadm 和 kubectl</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get update</span><br><span class=\"line\">apt-cache madison kubectl</span><br><span class=\"line\">apt-cache madison kubeadm</span><br><span class=\"line\">apt-cache madison kubelet</span><br><span class=\"line\">apt-get install -y kubelet&#x3D;1.18.0-00 kubeadm&#x3D;1.18.0-00 kubectl&#x3D;1.18.0-00</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><strong>启动kubelet服务</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl enable kubelet &amp;&amp; systemctl start kubelet </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5、关闭swap分区\"><a href=\"#5、关闭swap分区\" class=\"headerlink\" title=\"5、关闭swap分区\"></a>5、关闭swap分区</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">swapoff -a</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6、初始化master节点\"><a href=\"#6、初始化master节点\" class=\"headerlink\" title=\"6、初始化master节点\"></a>6、初始化master节点</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm init --image-repository registry.aliyuncs.com&#x2F;google_containers --kubernetes-version v1.18.0 --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 --token-ttl 0 --ignore-preflight-errors&#x3D;Swap</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# kubeadm init --image-repository registry.aliyuncs.com&#x2F;google_containers --kubernetes-version v1.18.0 --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 --token-ttl 0 --ignore-preflight-errors&#x3D;Swap</span><br><span class=\"line\">W0507 17:11:30.761887   14961 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class=\"line\">[init] Using Kubernetes version: v1.18.0</span><br><span class=\"line\">[preflight] Running pre-flight checks</span><br><span class=\"line\">\t[WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;setup&#x2F;cri&#x2F;</span><br><span class=\"line\">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class=\"line\">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class=\"line\">[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;</span><br><span class=\"line\">[kubelet-start] Writing kubelet environment file with flags to file &quot;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet-start] Writing kubelet configuration to file &quot;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml&quot;</span><br><span class=\"line\">[kubelet-start] Starting the kubelet</span><br><span class=\"line\">[certs] Using certificateDir folder &quot;&#x2F;etc&#x2F;kubernetes&#x2F;pki&quot;</span><br><span class=\"line\">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class=\"line\">[certs] apiserver serving cert is signed for DNS names [ubuntu-001 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.105.107]</span><br><span class=\"line\">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd&#x2F;ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd&#x2F;server&quot; certificate and key</span><br><span class=\"line\">[certs] etcd&#x2F;server serving cert is signed for DNS names [ubuntu-001 localhost] and IPs [10.0.105.107 127.0.0.1 ::1]</span><br><span class=\"line\">[certs] Generating &quot;etcd&#x2F;peer&quot; certificate and key</span><br><span class=\"line\">[certs] etcd&#x2F;peer serving cert is signed for DNS names [ubuntu-001 localhost] and IPs [10.0.105.107 127.0.0.1 ::1]</span><br><span class=\"line\">[certs] Generating &quot;etcd&#x2F;healthcheck-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;sa&quot; key and public key</span><br><span class=\"line\">[kubeconfig] Using kubeconfig folder &quot;&#x2F;etc&#x2F;kubernetes&quot;</span><br><span class=\"line\">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class=\"line\">[control-plane] Using manifest folder &quot;&#x2F;etc&#x2F;kubernetes&#x2F;manifests&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class=\"line\">W0507 17:11:34.680144   14961 manifests.go:225] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class=\"line\">W0507 17:11:34.682546   14961 manifests.go:225] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class=\"line\">[etcd] Creating static Pod manifest for local etcd in &quot;&#x2F;etc&#x2F;kubernetes&#x2F;manifests&quot;</span><br><span class=\"line\">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;&#x2F;etc&#x2F;kubernetes&#x2F;manifests&quot;. This can take up to 4m0s</span><br><span class=\"line\">[apiclient] All control plane components are healthy after 20.502602 seconds</span><br><span class=\"line\">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class=\"line\">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.18&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class=\"line\">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class=\"line\">[mark-control-plane] Marking the node ubuntu-001 as control-plane by adding the label &quot;node-role.kubernetes.io&#x2F;master&#x3D;&#39;&#39;&quot;</span><br><span class=\"line\">[mark-control-plane] Marking the node ubuntu-001 as control-plane by adding the taints [node-role.kubernetes.io&#x2F;master:NoSchedule]</span><br><span class=\"line\">[bootstrap-token] Using token: 10y2lc.v55p1f47j3lp15gg</span><br><span class=\"line\">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class=\"line\">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class=\"line\">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class=\"line\">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class=\"line\">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class=\"line\">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class=\"line\">[kubelet-finalize] Updating &quot;&#x2F;etc&#x2F;kubernetes&#x2F;kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class=\"line\">[addons] Applied essential addon: CoreDNS</span><br><span class=\"line\">[addons] Applied essential addon: kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">Your Kubernetes control-plane has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME&#x2F;.kube</span><br><span class=\"line\">  sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;cluster-administration&#x2F;addons&#x2F;</span><br><span class=\"line\"></span><br><span class=\"line\">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class=\"line\"></span><br><span class=\"line\">kubeadm join 10.0.105.107:6443 --token 10y2lc.v55p1f47j3lp15gg \\</span><br><span class=\"line\">    --discovery-token-ca-cert-hash sha256:1093b027cf31d755dcaa7109ba890962c140e2d6e9c46bf4207a0c519ce7bf36 </span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>按照kubeadm init成功后打印提示，继续操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir -p $HOME&#x2F;.kube</span><br><span class=\"line\">sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure>\n\n<p>kubectl get nodes查询到节点处于NotReady状态，是因为网络插件还未就位，也就是这里要求运行的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;cluster-administration&#x2F;addons&#x2F;</span><br></pre></td></tr></table></figure>\n\n<p>如果要暂时忽略让节点Ready，将如下文件的–network-plugin=cni字段去掉, (该文件是在kubeadm init或者kubeadm join过程中生成的), 修改完后重启kubelet即可(systemctl restart kubelet)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# cat &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env</span><br><span class=\"line\">KUBELET_KUBEADM_ARGS&#x3D;&quot;--cgroup-driver&#x3D;cgroupfs --network-plugin&#x3D;cni --pod-infra-container-image&#x3D;registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.2 --resolv-conf&#x3D;&#x2F;run&#x2F;systemd&#x2F;resolve&#x2F;resolv.conf&quot;</span><br></pre></td></tr></table></figure>\n<p>安装flannel，kubectl apply -f kube-flannel.yaml</p>\n<h2 id=\"7、join-node节点\"><a href=\"#7、join-node节点\" class=\"headerlink\" title=\"7、join node节点\"></a>7、join node节点</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-002:~# kubeadm join 10.0.105.107:6443 --token 10y2lc.v55p1f47j3lp15gg --discovery-token-ca-cert-hash sha256:1093b027cf31d755dcaa7109ba890962c140e2d6e9c46bf4207a0c519ce7bf36</span><br><span class=\"line\">W0507 17:16:18.524687   26000 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.</span><br><span class=\"line\">[preflight] Running pre-flight checks</span><br><span class=\"line\">\t[WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;setup&#x2F;cri&#x2F;</span><br><span class=\"line\">[preflight] Reading configuration from the cluster...</span><br><span class=\"line\">[preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;</span><br><span class=\"line\">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.18&quot; ConfigMap in the kube-system namespace</span><br><span class=\"line\">[kubelet-start] Writing kubelet configuration to file &quot;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml&quot;</span><br><span class=\"line\">[kubelet-start] Writing kubelet environment file with flags to file &quot;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet-start] Starting the kubelet</span><br><span class=\"line\">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class=\"line\"></span><br><span class=\"line\">This node has joined the cluster:</span><br><span class=\"line\">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class=\"line\">* The Kubelet was informed of the new secure connection details.</span><br><span class=\"line\"></span><br><span class=\"line\">Run &#39;kubectl get nodes&#39; on the control-plane to see this node join the cluster.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"查询所有node及pod状态\"><a href=\"#查询所有node及pod状态\" class=\"headerlink\" title=\"查询所有node及pod状态\"></a>查询所有node及pod状态</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get node -o wide</span><br><span class=\"line\">kubectl get pod --all-namespaces -o wide</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"增加kubectl命令自动补全功能\"><a href=\"#增加kubectl命令自动补全功能\" class=\"headerlink\" title=\"增加kubectl命令自动补全功能\"></a>增加kubectl命令自动补全功能</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">source &lt;(kubectl completion bash)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"默认master节点不会调度pod，去掉此限制-可选做\"><a href=\"#默认master节点不会调度pod，去掉此限制-可选做\" class=\"headerlink\" title=\"默认master节点不会调度pod，去掉此限制(可选做)\"></a>默认master节点不会调度pod，去掉此限制(可选做)</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl taint node ubuntu-001 node-role.kubernetes.io&#x2F;master:NoSchedule-</span><br></pre></td></tr></table></figure>\n<p>ubuntu-001为主机名</p>\n<h2 id=\"node节点ROLES默认显示none，将其修改为显示worker-可选做\"><a href=\"#node节点ROLES默认显示none，将其修改为显示worker-可选做\" class=\"headerlink\" title=\"node节点ROLES默认显示none，将其修改为显示worker(可选做)\"></a>node节点ROLES默认显示none，将其修改为显示worker(可选做)</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl label node ubuntu-002 node-role.kubernetes.io&#x2F;worker&#x3D; --overwrite</span><br><span class=\"line\">kubectl label node ubuntu-003 node-role.kubernetes.io&#x2F;worker&#x3D; --overwrite</span><br><span class=\"line\">root@ubuntu-001:~# kubectl get node -o wide</span><br><span class=\"line\">NAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION     CONTAINER-RUNTIME</span><br><span class=\"line\">ubuntu-001   Ready    master   16h   v1.18.0   10.0.105.107   &lt;none&gt;        Ubuntu 19.10   5.3.0-51-generic   docker:&#x2F;&#x2F;19.3.8</span><br><span class=\"line\">ubuntu-002   Ready    worker   16h   v1.18.0   10.0.105.21    &lt;none&gt;        Ubuntu 19.10   5.3.0-46-generic   docker:&#x2F;&#x2F;19.3.8</span><br><span class=\"line\">ubuntu-003   Ready    worker   61m   v1.18.0   10.0.105.62    &lt;none&gt;        Ubuntu 19.10   5.3.0-46-generic   docker:&#x2F;&#x2F;19.3.8</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"本文介绍如何在Ubuntu系统上搭建Kubernetes集群。\n\n前提：\n1、操作系统Ubuntu 19.10\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nroot@ubuntu-001:~# uname -a\nLinux ubuntu-001 5.3.0-51-generic #44-Ubuntu SMP Wed Apr 22 21:09:44 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\nroot@ubuntu-001:~# lsb_release -a\nNo LSB modules are available.\nDistributor ID:\tUbuntu\nD","more":"<p>本文介绍如何在Ubuntu系统上搭建Kubernetes集群。</p>\n<h1 id=\"前提：\"><a href=\"#前提：\" class=\"headerlink\" title=\"前提：\"></a>前提：</h1><p>1、操作系统Ubuntu 19.10</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# uname -a</span><br><span class=\"line\">Linux ubuntu-001 5.3.0-51-generic #44-Ubuntu SMP Wed Apr 22 21:09:44 UTC 2020 x86_64 x86_64 x86_64 GNU&#x2F;Linux</span><br><span class=\"line\">root@ubuntu-001:~# lsb_release -a</span><br><span class=\"line\">No LSB modules are available.</span><br><span class=\"line\">Distributor ID:\tUbuntu</span><br><span class=\"line\">Description:\tUbuntu 19.10</span><br><span class=\"line\">Release:\t19.10</span><br><span class=\"line\">Codename:\teoan</span><br></pre></td></tr></table></figure>\n<p>2、通过阿里云相关镜像源安装</p>\n<p><strong>以下均为root用户下操作</strong></p>\n<h1 id=\"操作步骤：\"><a href=\"#操作步骤：\" class=\"headerlink\" title=\"操作步骤：\"></a>操作步骤：</h1><h2 id=\"1、修改主机名\"><a href=\"#1、修改主机名\" class=\"headerlink\" title=\"1、修改主机名\"></a>1、修改主机名</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostnamectl set-hostname ubuntu-001</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2、关闭防火墙\"><a href=\"#2、关闭防火墙\" class=\"headerlink\" title=\"2、关闭防火墙\"></a>2、关闭防火墙</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get install ufw</span><br><span class=\"line\">ufw disable</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、安装docker\"><a href=\"#3、安装docker\" class=\"headerlink\" title=\"3、安装docker\"></a>3、安装docker</h2><p><strong>安装必要的工具及GPG证书</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get update</span><br><span class=\"line\">apt-get -y install apt-transport-https ca-certificates curl software-properties-common</span><br><span class=\"line\">curl -fsSL https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add -</span><br></pre></td></tr></table></figure>\n\n<p><strong>配置阿里云docker源</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add-apt-repository &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu $(lsb_release -cs) stable&quot;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>注意： 如果是arm架构系统，请对应更换， 如：add-apt-repository “deb [arch=arm64] <a href=\"https://mirrors.aliyun.com/docker-ce/linux/ubuntu\">https://mirrors.aliyun.com/docker-ce/linux/ubuntu</a> $(lsb_release -cs) stable”</p>\n<p><strong>查询docker版本（否则默认安装最新的版本）</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-cache madison docker-ce</span><br><span class=\"line\">#   docker-ce | 5:19.03.8~3-0~ubuntu-eoan | https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu eoan&#x2F;stable amd64 Packages</span><br><span class=\"line\">#   docker-ce | 5:19.03.7~3-0~ubuntu-eoan | https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu eoan&#x2F;stable amd64 Packages</span><br><span class=\"line\">#   docker-ce | 5:19.03.6~3-0~ubuntu-eoan | https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu eoan&#x2F;stable amd64 Packages</span><br></pre></td></tr></table></figure>\n\n<p><strong>安装指定版本docker</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get -y update</span><br><span class=\"line\">apt-get -y install docker-ce&#x3D;5:19.03.8~3-0~ubuntu-eoan</span><br></pre></td></tr></table></figure>\n\n<p><strong>启动docker</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure>\n\n<p><strong>查询docker服务状态</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl status docker</span><br></pre></td></tr></table></figure>\n\n<p><strong>查看docker版本</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker version</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4、安装kubelet、kubeadm-和-kubectl\"><a href=\"#4、安装kubelet、kubeadm-和-kubectl\" class=\"headerlink\" title=\"4、安装kubelet、kubeadm 和 kubectl\"></a>4、安装kubelet、kubeadm 和 kubectl</h2><p><strong>配置kubernetes.repo的源，由于官方源国内无法访问，这里使用阿里云源</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;apt&#x2F;doc&#x2F;apt-key.gpg | apt-key add - </span><br><span class=\"line\">cat &lt;&lt;EOF &gt;&#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;kubernetes.list</span><br><span class=\"line\">deb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;apt&#x2F; kubernetes-xenial main</span><br><span class=\"line\">EOF  </span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><strong>在所有节点上安装指定版本 kubelet、kubeadm 和 kubectl</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get update</span><br><span class=\"line\">apt-cache madison kubectl</span><br><span class=\"line\">apt-cache madison kubeadm</span><br><span class=\"line\">apt-cache madison kubelet</span><br><span class=\"line\">apt-get install -y kubelet&#x3D;1.18.0-00 kubeadm&#x3D;1.18.0-00 kubectl&#x3D;1.18.0-00</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><strong>启动kubelet服务</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl enable kubelet &amp;&amp; systemctl start kubelet </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5、关闭swap分区\"><a href=\"#5、关闭swap分区\" class=\"headerlink\" title=\"5、关闭swap分区\"></a>5、关闭swap分区</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">swapoff -a</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6、初始化master节点\"><a href=\"#6、初始化master节点\" class=\"headerlink\" title=\"6、初始化master节点\"></a>6、初始化master节点</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm init --image-repository registry.aliyuncs.com&#x2F;google_containers --kubernetes-version v1.18.0 --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 --token-ttl 0 --ignore-preflight-errors&#x3D;Swap</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# kubeadm init --image-repository registry.aliyuncs.com&#x2F;google_containers --kubernetes-version v1.18.0 --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 --token-ttl 0 --ignore-preflight-errors&#x3D;Swap</span><br><span class=\"line\">W0507 17:11:30.761887   14961 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class=\"line\">[init] Using Kubernetes version: v1.18.0</span><br><span class=\"line\">[preflight] Running pre-flight checks</span><br><span class=\"line\">\t[WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;setup&#x2F;cri&#x2F;</span><br><span class=\"line\">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class=\"line\">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class=\"line\">[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;</span><br><span class=\"line\">[kubelet-start] Writing kubelet environment file with flags to file &quot;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet-start] Writing kubelet configuration to file &quot;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml&quot;</span><br><span class=\"line\">[kubelet-start] Starting the kubelet</span><br><span class=\"line\">[certs] Using certificateDir folder &quot;&#x2F;etc&#x2F;kubernetes&#x2F;pki&quot;</span><br><span class=\"line\">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class=\"line\">[certs] apiserver serving cert is signed for DNS names [ubuntu-001 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.105.107]</span><br><span class=\"line\">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd&#x2F;ca&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;etcd&#x2F;server&quot; certificate and key</span><br><span class=\"line\">[certs] etcd&#x2F;server serving cert is signed for DNS names [ubuntu-001 localhost] and IPs [10.0.105.107 127.0.0.1 ::1]</span><br><span class=\"line\">[certs] Generating &quot;etcd&#x2F;peer&quot; certificate and key</span><br><span class=\"line\">[certs] etcd&#x2F;peer serving cert is signed for DNS names [ubuntu-001 localhost] and IPs [10.0.105.107 127.0.0.1 ::1]</span><br><span class=\"line\">[certs] Generating &quot;etcd&#x2F;healthcheck-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class=\"line\">[certs] Generating &quot;sa&quot; key and public key</span><br><span class=\"line\">[kubeconfig] Using kubeconfig folder &quot;&#x2F;etc&#x2F;kubernetes&quot;</span><br><span class=\"line\">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class=\"line\">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class=\"line\">[control-plane] Using manifest folder &quot;&#x2F;etc&#x2F;kubernetes&#x2F;manifests&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class=\"line\">W0507 17:11:34.680144   14961 manifests.go:225] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class=\"line\">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class=\"line\">W0507 17:11:34.682546   14961 manifests.go:225] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class=\"line\">[etcd] Creating static Pod manifest for local etcd in &quot;&#x2F;etc&#x2F;kubernetes&#x2F;manifests&quot;</span><br><span class=\"line\">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;&#x2F;etc&#x2F;kubernetes&#x2F;manifests&quot;. This can take up to 4m0s</span><br><span class=\"line\">[apiclient] All control plane components are healthy after 20.502602 seconds</span><br><span class=\"line\">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class=\"line\">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.18&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class=\"line\">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class=\"line\">[mark-control-plane] Marking the node ubuntu-001 as control-plane by adding the label &quot;node-role.kubernetes.io&#x2F;master&#x3D;&#39;&#39;&quot;</span><br><span class=\"line\">[mark-control-plane] Marking the node ubuntu-001 as control-plane by adding the taints [node-role.kubernetes.io&#x2F;master:NoSchedule]</span><br><span class=\"line\">[bootstrap-token] Using token: 10y2lc.v55p1f47j3lp15gg</span><br><span class=\"line\">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class=\"line\">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class=\"line\">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class=\"line\">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class=\"line\">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class=\"line\">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class=\"line\">[kubelet-finalize] Updating &quot;&#x2F;etc&#x2F;kubernetes&#x2F;kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class=\"line\">[addons] Applied essential addon: CoreDNS</span><br><span class=\"line\">[addons] Applied essential addon: kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">Your Kubernetes control-plane has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME&#x2F;.kube</span><br><span class=\"line\">  sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;cluster-administration&#x2F;addons&#x2F;</span><br><span class=\"line\"></span><br><span class=\"line\">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class=\"line\"></span><br><span class=\"line\">kubeadm join 10.0.105.107:6443 --token 10y2lc.v55p1f47j3lp15gg \\</span><br><span class=\"line\">    --discovery-token-ca-cert-hash sha256:1093b027cf31d755dcaa7109ba890962c140e2d6e9c46bf4207a0c519ce7bf36 </span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>按照kubeadm init成功后打印提示，继续操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir -p $HOME&#x2F;.kube</span><br><span class=\"line\">sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure>\n\n<p>kubectl get nodes查询到节点处于NotReady状态，是因为网络插件还未就位，也就是这里要求运行的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;cluster-administration&#x2F;addons&#x2F;</span><br></pre></td></tr></table></figure>\n\n<p>如果要暂时忽略让节点Ready，将如下文件的–network-plugin=cni字段去掉, (该文件是在kubeadm init或者kubeadm join过程中生成的), 修改完后重启kubelet即可(systemctl restart kubelet)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# cat &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env</span><br><span class=\"line\">KUBELET_KUBEADM_ARGS&#x3D;&quot;--cgroup-driver&#x3D;cgroupfs --network-plugin&#x3D;cni --pod-infra-container-image&#x3D;registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.2 --resolv-conf&#x3D;&#x2F;run&#x2F;systemd&#x2F;resolve&#x2F;resolv.conf&quot;</span><br></pre></td></tr></table></figure>\n<p>安装flannel，kubectl apply -f kube-flannel.yaml</p>\n<h2 id=\"7、join-node节点\"><a href=\"#7、join-node节点\" class=\"headerlink\" title=\"7、join node节点\"></a>7、join node节点</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-002:~# kubeadm join 10.0.105.107:6443 --token 10y2lc.v55p1f47j3lp15gg --discovery-token-ca-cert-hash sha256:1093b027cf31d755dcaa7109ba890962c140e2d6e9c46bf4207a0c519ce7bf36</span><br><span class=\"line\">W0507 17:16:18.524687   26000 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.</span><br><span class=\"line\">[preflight] Running pre-flight checks</span><br><span class=\"line\">\t[WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;setup&#x2F;cri&#x2F;</span><br><span class=\"line\">[preflight] Reading configuration from the cluster...</span><br><span class=\"line\">[preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;</span><br><span class=\"line\">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.18&quot; ConfigMap in the kube-system namespace</span><br><span class=\"line\">[kubelet-start] Writing kubelet configuration to file &quot;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml&quot;</span><br><span class=\"line\">[kubelet-start] Writing kubelet environment file with flags to file &quot;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet-start] Starting the kubelet</span><br><span class=\"line\">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class=\"line\"></span><br><span class=\"line\">This node has joined the cluster:</span><br><span class=\"line\">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class=\"line\">* The Kubelet was informed of the new secure connection details.</span><br><span class=\"line\"></span><br><span class=\"line\">Run &#39;kubectl get nodes&#39; on the control-plane to see this node join the cluster.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"查询所有node及pod状态\"><a href=\"#查询所有node及pod状态\" class=\"headerlink\" title=\"查询所有node及pod状态\"></a>查询所有node及pod状态</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get node -o wide</span><br><span class=\"line\">kubectl get pod --all-namespaces -o wide</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"增加kubectl命令自动补全功能\"><a href=\"#增加kubectl命令自动补全功能\" class=\"headerlink\" title=\"增加kubectl命令自动补全功能\"></a>增加kubectl命令自动补全功能</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">source &lt;(kubectl completion bash)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"默认master节点不会调度pod，去掉此限制-可选做\"><a href=\"#默认master节点不会调度pod，去掉此限制-可选做\" class=\"headerlink\" title=\"默认master节点不会调度pod，去掉此限制(可选做)\"></a>默认master节点不会调度pod，去掉此限制(可选做)</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl taint node ubuntu-001 node-role.kubernetes.io&#x2F;master:NoSchedule-</span><br></pre></td></tr></table></figure>\n<p>ubuntu-001为主机名</p>\n<h2 id=\"node节点ROLES默认显示none，将其修改为显示worker-可选做\"><a href=\"#node节点ROLES默认显示none，将其修改为显示worker-可选做\" class=\"headerlink\" title=\"node节点ROLES默认显示none，将其修改为显示worker(可选做)\"></a>node节点ROLES默认显示none，将其修改为显示worker(可选做)</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl label node ubuntu-002 node-role.kubernetes.io&#x2F;worker&#x3D; --overwrite</span><br><span class=\"line\">kubectl label node ubuntu-003 node-role.kubernetes.io&#x2F;worker&#x3D; --overwrite</span><br><span class=\"line\">root@ubuntu-001:~# kubectl get node -o wide</span><br><span class=\"line\">NAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION     CONTAINER-RUNTIME</span><br><span class=\"line\">ubuntu-001   Ready    master   16h   v1.18.0   10.0.105.107   &lt;none&gt;        Ubuntu 19.10   5.3.0-51-generic   docker:&#x2F;&#x2F;19.3.8</span><br><span class=\"line\">ubuntu-002   Ready    worker   16h   v1.18.0   10.0.105.21    &lt;none&gt;        Ubuntu 19.10   5.3.0-46-generic   docker:&#x2F;&#x2F;19.3.8</span><br><span class=\"line\">ubuntu-003   Ready    worker   61m   v1.18.0   10.0.105.62    &lt;none&gt;        Ubuntu 19.10   5.3.0-46-generic   docker:&#x2F;&#x2F;19.3.8</span><br></pre></td></tr></table></figure>\n\n"},{"title":"kubernetes的python-client体验","date":"2020-12-01T05:56:09.000Z","_content":"kubernetes提供了丰富的API接口，用户不仅可以通过CLI命令行去调用API接口，而且还可以通过client库方便的调用API接口\n\nhttps://kubernetes.io/docs/reference/using-api/client-libraries/，提供了官方支持的和社区支持的不同语言的client库\n\n\n本文将着重体验python版本的client库的使用\n\n## 源码安装\n```\ngit clone --recursive https://github.com/kubernetes-client/python.git\ncd python\npython setup.py install\n```\n\n## pip安装\n```\npip install kubernetes\n```\n\n## Example\n\n```\nfrom kubernetes import client, config\n\n# Configs can be set in Configuration class directly or using helper utility\nconfig.load_kube_config()\n\nv1 = client.CoreV1Api()\nprint(\"Listing pods with their IPs:\")\nret = v1.list_pod_for_all_namespaces(watch=False)\nfor i in ret.items:\n    print(\"%s\\t%s\\t%s\" % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))\n```\n\n```\nroot@ubuntu:~/python# python test_list_pods.py\nListing pods with their IPs:\n10.244.0.8      default edgex-app-service-configurable-rules-d66d779c7-ksw7c\n10.244.0.9      default edgex-core-command-6f7cd7d57f-tnmmp\n10.244.0.18     default edgex-core-consul-64b88766-7q7kr\n10.244.0.10     default edgex-core-data-57b99d7f89-gpfgs\n10.244.0.11     default edgex-core-metadata-58dcc95ff4-9ssjg\n10.244.0.12     default edgex-device-rest-7944449548-nzcfj\n10.244.0.13     default edgex-device-virtual-6c7b8d7499-csz85\n10.244.0.14     default edgex-redis-67fffb7666-pvqgw\n10.244.0.15     default edgex-support-notifications-58dc7f76b4-tsdxn\n10.244.0.16     default edgex-support-rulesengine-8657b7c988-zr8pv\n10.244.0.17     default edgex-support-scheduler-d6fd467db-tfqw7\n10.244.0.19     default edgex-sys-mgmt-agent-79b476d8dc-2jdw4\n10.244.0.20     default edgex-ui-8cfc7f95d-vvhzc\n10.244.0.4      kube-system     coredns-f9fd979d6-cqpss\n10.244.0.3      kube-system     coredns-f9fd979d6-kvbzm\n172.18.0.2      kube-system     etcd-kind-control-plane\n172.18.0.2      kube-system     kindnet-br2qc\n172.18.0.2      kube-system     kube-apiserver-kind-control-plane\n172.18.0.2      kube-system     kube-controller-manager-kind-control-plane\n172.18.0.2      kube-system     kube-proxy-4chlm\n172.18.0.2      kube-system     kube-scheduler-kind-control-plane\n10.244.0.7      kube-system     metrics-server-8dc97c749-h6w8n\n10.244.0.6      kubernetes-dashboard    dashboard-metrics-scraper-7b59f7d4df-5rwc6\n10.244.0.5      kubernetes-dashboard    kubernetes-dashboard-665f4c5ff-l6tqn\n10.244.0.2      local-path-storage      local-path-provisioner-78776bfc44-xl4ht\nroot@ubuntu:~/python#\nroot@ubuntu:~/python# kubectl get pods --all-namespaces -o wide\nNAMESPACE              NAME                                                   READY   STATUS             RESTARTS   AGE    IP            NODE                 NOMINATED NODE   READINESS GATES\ndefault                edgex-app-service-configurable-rules-d66d779c7-ksw7c   1/1     Running            14         21h    10.244.0.8    kind-control-plane   <none>           <none>\ndefault                edgex-core-command-6f7cd7d57f-tnmmp                    1/1     Running            21         21h    10.244.0.9    kind-control-plane   <none>           <none>\ndefault                edgex-core-consul-64b88766-7q7kr                       1/1     Running            0          21h    10.244.0.18   kind-control-plane   <none>           <none>\ndefault                edgex-core-data-57b99d7f89-gpfgs                       1/1     Running            19         21h    10.244.0.10   kind-control-plane   <none>           <none>\ndefault                edgex-core-metadata-58dcc95ff4-9ssjg                   1/1     Running            21         21h    10.244.0.11   kind-control-plane   <none>           <none>\ndefault                edgex-device-rest-7944449548-nzcfj                     1/1     Running            15         21h    10.244.0.12   kind-control-plane   <none>           <none>\ndefault                edgex-device-virtual-6c7b8d7499-csz85                  1/1     Running            13         21h    10.244.0.13   kind-control-plane   <none>           <none>\ndefault                edgex-redis-67fffb7666-pvqgw                           1/1     Running            0          21h    10.244.0.14   kind-control-plane   <none>           <none>\ndefault                edgex-support-notifications-58dc7f76b4-tsdxn           1/1     Running            13         21h    10.244.0.15   kind-control-plane   <none>           <none>\ndefault                edgex-support-rulesengine-8657b7c988-zr8pv             1/1     Running            0          21h    10.244.0.16   kind-control-plane   <none>           <none>\ndefault                edgex-support-scheduler-d6fd467db-tfqw7                1/1     Running            14         21h    10.244.0.17   kind-control-plane   <none>           <none>\ndefault                edgex-sys-mgmt-agent-79b476d8dc-2jdw4                  1/1     Running            0          21h    10.244.0.19   kind-control-plane   <none>           <none>\ndefault                edgex-ui-8cfc7f95d-vvhzc                               0/1     ImagePullBackOff   0          21h    10.244.0.20   kind-control-plane   <none>           <none>\nkube-system            coredns-f9fd979d6-cqpss                                1/1     Running            0          4d6h   10.244.0.4    kind-control-plane   <none>           <none>\nkube-system            coredns-f9fd979d6-kvbzm                                1/1     Running            0          4d6h   10.244.0.3    kind-control-plane   <none>           <none>\nkube-system            etcd-kind-control-plane                                1/1     Running            0          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kindnet-br2qc                                          1/1     Running            0          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kube-apiserver-kind-control-plane                      1/1     Running            0          23h    172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kube-controller-manager-kind-control-plane             1/1     Running            1          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kube-proxy-4chlm                                       1/1     Running            0          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kube-scheduler-kind-control-plane                      1/1     Running            1          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            metrics-server-8dc97c749-h6w8n                         1/1     Running            0          21h    10.244.0.7    kind-control-plane   <none>           <none>\nkubernetes-dashboard   dashboard-metrics-scraper-7b59f7d4df-5rwc6             1/1     Running            0          21h    10.244.0.6    kind-control-plane   <none>           <none>\nkubernetes-dashboard   kubernetes-dashboard-665f4c5ff-l6tqn                   1/1     Running            0          21h    10.244.0.5    kind-control-plane   <none>           <none>\nlocal-path-storage     local-path-provisioner-78776bfc44-xl4ht                1/1     Running            1          4d6h   10.244.0.2    kind-control-plane   <none>           <none>\n```\n\n更多的examples：https://github.com/kubernetes-client/python/tree/master/example\n","source":"_posts/kubernetes的python-client体验.md","raw":"---\ntitle: kubernetes的python-client体验\ndate: 2020-12-01 13:56:09\ntags:\n- kubernetes\n- python\ncategories:\n- python\n- kubernetes\n---\nkubernetes提供了丰富的API接口，用户不仅可以通过CLI命令行去调用API接口，而且还可以通过client库方便的调用API接口\n\nhttps://kubernetes.io/docs/reference/using-api/client-libraries/，提供了官方支持的和社区支持的不同语言的client库\n\n\n本文将着重体验python版本的client库的使用\n\n## 源码安装\n```\ngit clone --recursive https://github.com/kubernetes-client/python.git\ncd python\npython setup.py install\n```\n\n## pip安装\n```\npip install kubernetes\n```\n\n## Example\n\n```\nfrom kubernetes import client, config\n\n# Configs can be set in Configuration class directly or using helper utility\nconfig.load_kube_config()\n\nv1 = client.CoreV1Api()\nprint(\"Listing pods with their IPs:\")\nret = v1.list_pod_for_all_namespaces(watch=False)\nfor i in ret.items:\n    print(\"%s\\t%s\\t%s\" % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))\n```\n\n```\nroot@ubuntu:~/python# python test_list_pods.py\nListing pods with their IPs:\n10.244.0.8      default edgex-app-service-configurable-rules-d66d779c7-ksw7c\n10.244.0.9      default edgex-core-command-6f7cd7d57f-tnmmp\n10.244.0.18     default edgex-core-consul-64b88766-7q7kr\n10.244.0.10     default edgex-core-data-57b99d7f89-gpfgs\n10.244.0.11     default edgex-core-metadata-58dcc95ff4-9ssjg\n10.244.0.12     default edgex-device-rest-7944449548-nzcfj\n10.244.0.13     default edgex-device-virtual-6c7b8d7499-csz85\n10.244.0.14     default edgex-redis-67fffb7666-pvqgw\n10.244.0.15     default edgex-support-notifications-58dc7f76b4-tsdxn\n10.244.0.16     default edgex-support-rulesengine-8657b7c988-zr8pv\n10.244.0.17     default edgex-support-scheduler-d6fd467db-tfqw7\n10.244.0.19     default edgex-sys-mgmt-agent-79b476d8dc-2jdw4\n10.244.0.20     default edgex-ui-8cfc7f95d-vvhzc\n10.244.0.4      kube-system     coredns-f9fd979d6-cqpss\n10.244.0.3      kube-system     coredns-f9fd979d6-kvbzm\n172.18.0.2      kube-system     etcd-kind-control-plane\n172.18.0.2      kube-system     kindnet-br2qc\n172.18.0.2      kube-system     kube-apiserver-kind-control-plane\n172.18.0.2      kube-system     kube-controller-manager-kind-control-plane\n172.18.0.2      kube-system     kube-proxy-4chlm\n172.18.0.2      kube-system     kube-scheduler-kind-control-plane\n10.244.0.7      kube-system     metrics-server-8dc97c749-h6w8n\n10.244.0.6      kubernetes-dashboard    dashboard-metrics-scraper-7b59f7d4df-5rwc6\n10.244.0.5      kubernetes-dashboard    kubernetes-dashboard-665f4c5ff-l6tqn\n10.244.0.2      local-path-storage      local-path-provisioner-78776bfc44-xl4ht\nroot@ubuntu:~/python#\nroot@ubuntu:~/python# kubectl get pods --all-namespaces -o wide\nNAMESPACE              NAME                                                   READY   STATUS             RESTARTS   AGE    IP            NODE                 NOMINATED NODE   READINESS GATES\ndefault                edgex-app-service-configurable-rules-d66d779c7-ksw7c   1/1     Running            14         21h    10.244.0.8    kind-control-plane   <none>           <none>\ndefault                edgex-core-command-6f7cd7d57f-tnmmp                    1/1     Running            21         21h    10.244.0.9    kind-control-plane   <none>           <none>\ndefault                edgex-core-consul-64b88766-7q7kr                       1/1     Running            0          21h    10.244.0.18   kind-control-plane   <none>           <none>\ndefault                edgex-core-data-57b99d7f89-gpfgs                       1/1     Running            19         21h    10.244.0.10   kind-control-plane   <none>           <none>\ndefault                edgex-core-metadata-58dcc95ff4-9ssjg                   1/1     Running            21         21h    10.244.0.11   kind-control-plane   <none>           <none>\ndefault                edgex-device-rest-7944449548-nzcfj                     1/1     Running            15         21h    10.244.0.12   kind-control-plane   <none>           <none>\ndefault                edgex-device-virtual-6c7b8d7499-csz85                  1/1     Running            13         21h    10.244.0.13   kind-control-plane   <none>           <none>\ndefault                edgex-redis-67fffb7666-pvqgw                           1/1     Running            0          21h    10.244.0.14   kind-control-plane   <none>           <none>\ndefault                edgex-support-notifications-58dc7f76b4-tsdxn           1/1     Running            13         21h    10.244.0.15   kind-control-plane   <none>           <none>\ndefault                edgex-support-rulesengine-8657b7c988-zr8pv             1/1     Running            0          21h    10.244.0.16   kind-control-plane   <none>           <none>\ndefault                edgex-support-scheduler-d6fd467db-tfqw7                1/1     Running            14         21h    10.244.0.17   kind-control-plane   <none>           <none>\ndefault                edgex-sys-mgmt-agent-79b476d8dc-2jdw4                  1/1     Running            0          21h    10.244.0.19   kind-control-plane   <none>           <none>\ndefault                edgex-ui-8cfc7f95d-vvhzc                               0/1     ImagePullBackOff   0          21h    10.244.0.20   kind-control-plane   <none>           <none>\nkube-system            coredns-f9fd979d6-cqpss                                1/1     Running            0          4d6h   10.244.0.4    kind-control-plane   <none>           <none>\nkube-system            coredns-f9fd979d6-kvbzm                                1/1     Running            0          4d6h   10.244.0.3    kind-control-plane   <none>           <none>\nkube-system            etcd-kind-control-plane                                1/1     Running            0          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kindnet-br2qc                                          1/1     Running            0          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kube-apiserver-kind-control-plane                      1/1     Running            0          23h    172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kube-controller-manager-kind-control-plane             1/1     Running            1          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kube-proxy-4chlm                                       1/1     Running            0          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            kube-scheduler-kind-control-plane                      1/1     Running            1          4d6h   172.18.0.2    kind-control-plane   <none>           <none>\nkube-system            metrics-server-8dc97c749-h6w8n                         1/1     Running            0          21h    10.244.0.7    kind-control-plane   <none>           <none>\nkubernetes-dashboard   dashboard-metrics-scraper-7b59f7d4df-5rwc6             1/1     Running            0          21h    10.244.0.6    kind-control-plane   <none>           <none>\nkubernetes-dashboard   kubernetes-dashboard-665f4c5ff-l6tqn                   1/1     Running            0          21h    10.244.0.5    kind-control-plane   <none>           <none>\nlocal-path-storage     local-path-provisioner-78776bfc44-xl4ht                1/1     Running            1          4d6h   10.244.0.2    kind-control-plane   <none>           <none>\n```\n\n更多的examples：https://github.com/kubernetes-client/python/tree/master/example\n","slug":"kubernetes的python-client体验","published":1,"updated":"2020-12-01T06:48:27.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cki73ih180007h0l79chxdzbu","content":"<p>kubernetes提供了丰富的API接口，用户不仅可以通过CLI命令行去调用API接口，而且还可以通过client库方便的调用API接口</p>\n<p><a href=\"https://kubernetes.io/docs/reference/using-api/client-libraries/%EF%BC%8C%E6%8F%90%E4%BE%9B%E4%BA%86%E5%AE%98%E6%96%B9%E6%94%AF%E6%8C%81%E7%9A%84%E5%92%8C%E7%A4%BE%E5%8C%BA%E6%94%AF%E6%8C%81%E7%9A%84%E4%B8%8D%E5%90%8C%E8%AF%AD%E8%A8%80%E7%9A%84client%E5%BA%93\">https://kubernetes.io/docs/reference/using-api/client-libraries/，提供了官方支持的和社区支持的不同语言的client库</a></p>\n<p>本文将着重体验python版本的client库的使用</p>\n<h2 id=\"源码安装\"><a href=\"#源码安装\" class=\"headerlink\" title=\"源码安装\"></a>源码安装</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone --recursive https:&#x2F;&#x2F;github.com&#x2F;kubernetes-client&#x2F;python.git</span><br><span class=\"line\">cd python</span><br><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"pip安装\"><a href=\"#pip安装\" class=\"headerlink\" title=\"pip安装\"></a>pip安装</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install kubernetes</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from kubernetes import client, config</span><br><span class=\"line\"></span><br><span class=\"line\"># Configs can be set in Configuration class directly or using helper utility</span><br><span class=\"line\">config.load_kube_config()</span><br><span class=\"line\"></span><br><span class=\"line\">v1 &#x3D; client.CoreV1Api()</span><br><span class=\"line\">print(&quot;Listing pods with their IPs:&quot;)</span><br><span class=\"line\">ret &#x3D; v1.list_pod_for_all_namespaces(watch&#x3D;False)</span><br><span class=\"line\">for i in ret.items:</span><br><span class=\"line\">    print(&quot;%s\\t%s\\t%s&quot; % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~&#x2F;python# python test_list_pods.py</span><br><span class=\"line\">Listing pods with their IPs:</span><br><span class=\"line\">10.244.0.8      default edgex-app-service-configurable-rules-d66d779c7-ksw7c</span><br><span class=\"line\">10.244.0.9      default edgex-core-command-6f7cd7d57f-tnmmp</span><br><span class=\"line\">10.244.0.18     default edgex-core-consul-64b88766-7q7kr</span><br><span class=\"line\">10.244.0.10     default edgex-core-data-57b99d7f89-gpfgs</span><br><span class=\"line\">10.244.0.11     default edgex-core-metadata-58dcc95ff4-9ssjg</span><br><span class=\"line\">10.244.0.12     default edgex-device-rest-7944449548-nzcfj</span><br><span class=\"line\">10.244.0.13     default edgex-device-virtual-6c7b8d7499-csz85</span><br><span class=\"line\">10.244.0.14     default edgex-redis-67fffb7666-pvqgw</span><br><span class=\"line\">10.244.0.15     default edgex-support-notifications-58dc7f76b4-tsdxn</span><br><span class=\"line\">10.244.0.16     default edgex-support-rulesengine-8657b7c988-zr8pv</span><br><span class=\"line\">10.244.0.17     default edgex-support-scheduler-d6fd467db-tfqw7</span><br><span class=\"line\">10.244.0.19     default edgex-sys-mgmt-agent-79b476d8dc-2jdw4</span><br><span class=\"line\">10.244.0.20     default edgex-ui-8cfc7f95d-vvhzc</span><br><span class=\"line\">10.244.0.4      kube-system     coredns-f9fd979d6-cqpss</span><br><span class=\"line\">10.244.0.3      kube-system     coredns-f9fd979d6-kvbzm</span><br><span class=\"line\">172.18.0.2      kube-system     etcd-kind-control-plane</span><br><span class=\"line\">172.18.0.2      kube-system     kindnet-br2qc</span><br><span class=\"line\">172.18.0.2      kube-system     kube-apiserver-kind-control-plane</span><br><span class=\"line\">172.18.0.2      kube-system     kube-controller-manager-kind-control-plane</span><br><span class=\"line\">172.18.0.2      kube-system     kube-proxy-4chlm</span><br><span class=\"line\">172.18.0.2      kube-system     kube-scheduler-kind-control-plane</span><br><span class=\"line\">10.244.0.7      kube-system     metrics-server-8dc97c749-h6w8n</span><br><span class=\"line\">10.244.0.6      kubernetes-dashboard    dashboard-metrics-scraper-7b59f7d4df-5rwc6</span><br><span class=\"line\">10.244.0.5      kubernetes-dashboard    kubernetes-dashboard-665f4c5ff-l6tqn</span><br><span class=\"line\">10.244.0.2      local-path-storage      local-path-provisioner-78776bfc44-xl4ht</span><br><span class=\"line\">root@ubuntu:~&#x2F;python#</span><br><span class=\"line\">root@ubuntu:~&#x2F;python# kubectl get pods --all-namespaces -o wide</span><br><span class=\"line\">NAMESPACE              NAME                                                   READY   STATUS             RESTARTS   AGE    IP            NODE                 NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">default                edgex-app-service-configurable-rules-d66d779c7-ksw7c   1&#x2F;1     Running            14         21h    10.244.0.8    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-core-command-6f7cd7d57f-tnmmp                    1&#x2F;1     Running            21         21h    10.244.0.9    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-core-consul-64b88766-7q7kr                       1&#x2F;1     Running            0          21h    10.244.0.18   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-core-data-57b99d7f89-gpfgs                       1&#x2F;1     Running            19         21h    10.244.0.10   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-core-metadata-58dcc95ff4-9ssjg                   1&#x2F;1     Running            21         21h    10.244.0.11   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-device-rest-7944449548-nzcfj                     1&#x2F;1     Running            15         21h    10.244.0.12   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-device-virtual-6c7b8d7499-csz85                  1&#x2F;1     Running            13         21h    10.244.0.13   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-redis-67fffb7666-pvqgw                           1&#x2F;1     Running            0          21h    10.244.0.14   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-support-notifications-58dc7f76b4-tsdxn           1&#x2F;1     Running            13         21h    10.244.0.15   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-support-rulesengine-8657b7c988-zr8pv             1&#x2F;1     Running            0          21h    10.244.0.16   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-support-scheduler-d6fd467db-tfqw7                1&#x2F;1     Running            14         21h    10.244.0.17   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-sys-mgmt-agent-79b476d8dc-2jdw4                  1&#x2F;1     Running            0          21h    10.244.0.19   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-ui-8cfc7f95d-vvhzc                               0&#x2F;1     ImagePullBackOff   0          21h    10.244.0.20   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            coredns-f9fd979d6-cqpss                                1&#x2F;1     Running            0          4d6h   10.244.0.4    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            coredns-f9fd979d6-kvbzm                                1&#x2F;1     Running            0          4d6h   10.244.0.3    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            etcd-kind-control-plane                                1&#x2F;1     Running            0          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kindnet-br2qc                                          1&#x2F;1     Running            0          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kube-apiserver-kind-control-plane                      1&#x2F;1     Running            0          23h    172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kube-controller-manager-kind-control-plane             1&#x2F;1     Running            1          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kube-proxy-4chlm                                       1&#x2F;1     Running            0          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kube-scheduler-kind-control-plane                      1&#x2F;1     Running            1          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            metrics-server-8dc97c749-h6w8n                         1&#x2F;1     Running            0          21h    10.244.0.7    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kubernetes-dashboard   dashboard-metrics-scraper-7b59f7d4df-5rwc6             1&#x2F;1     Running            0          21h    10.244.0.6    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kubernetes-dashboard   kubernetes-dashboard-665f4c5ff-l6tqn                   1&#x2F;1     Running            0          21h    10.244.0.5    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">local-path-storage     local-path-provisioner-78776bfc44-xl4ht                1&#x2F;1     Running            1          4d6h   10.244.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n\n<p>更多的examples：<a href=\"https://github.com/kubernetes-client/python/tree/master/example\">https://github.com/kubernetes-client/python/tree/master/example</a></p>\n","site":{"data":{}},"excerpt":"kubernetes提供了丰富的API接口，用户不仅可以通过CLI命令行去调用API接口，而且还可以通过client库方便的调用API接口\n\nhttps://kubernetes.io/docs/reference/using-api/client-libraries/，提供了官方支持的和社区支持的不同语言的client库\n\n本文将着重体验python版本的client库的使用\n\n源码安装\n1\n2\n3\n\n\ngit clone --recursive https://github.com/kubernetes-client/python.git\ncd python\npython setup.py","more":"<p>kubernetes提供了丰富的API接口，用户不仅可以通过CLI命令行去调用API接口，而且还可以通过client库方便的调用API接口</p>\n<p><a href=\"https://kubernetes.io/docs/reference/using-api/client-libraries/%EF%BC%8C%E6%8F%90%E4%BE%9B%E4%BA%86%E5%AE%98%E6%96%B9%E6%94%AF%E6%8C%81%E7%9A%84%E5%92%8C%E7%A4%BE%E5%8C%BA%E6%94%AF%E6%8C%81%E7%9A%84%E4%B8%8D%E5%90%8C%E8%AF%AD%E8%A8%80%E7%9A%84client%E5%BA%93\">https://kubernetes.io/docs/reference/using-api/client-libraries/，提供了官方支持的和社区支持的不同语言的client库</a></p>\n<p>本文将着重体验python版本的client库的使用</p>\n<h2 id=\"源码安装\"><a href=\"#源码安装\" class=\"headerlink\" title=\"源码安装\"></a>源码安装</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone --recursive https:&#x2F;&#x2F;github.com&#x2F;kubernetes-client&#x2F;python.git</span><br><span class=\"line\">cd python</span><br><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"pip安装\"><a href=\"#pip安装\" class=\"headerlink\" title=\"pip安装\"></a>pip安装</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install kubernetes</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from kubernetes import client, config</span><br><span class=\"line\"></span><br><span class=\"line\"># Configs can be set in Configuration class directly or using helper utility</span><br><span class=\"line\">config.load_kube_config()</span><br><span class=\"line\"></span><br><span class=\"line\">v1 &#x3D; client.CoreV1Api()</span><br><span class=\"line\">print(&quot;Listing pods with their IPs:&quot;)</span><br><span class=\"line\">ret &#x3D; v1.list_pod_for_all_namespaces(watch&#x3D;False)</span><br><span class=\"line\">for i in ret.items:</span><br><span class=\"line\">    print(&quot;%s\\t%s\\t%s&quot; % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~&#x2F;python# python test_list_pods.py</span><br><span class=\"line\">Listing pods with their IPs:</span><br><span class=\"line\">10.244.0.8      default edgex-app-service-configurable-rules-d66d779c7-ksw7c</span><br><span class=\"line\">10.244.0.9      default edgex-core-command-6f7cd7d57f-tnmmp</span><br><span class=\"line\">10.244.0.18     default edgex-core-consul-64b88766-7q7kr</span><br><span class=\"line\">10.244.0.10     default edgex-core-data-57b99d7f89-gpfgs</span><br><span class=\"line\">10.244.0.11     default edgex-core-metadata-58dcc95ff4-9ssjg</span><br><span class=\"line\">10.244.0.12     default edgex-device-rest-7944449548-nzcfj</span><br><span class=\"line\">10.244.0.13     default edgex-device-virtual-6c7b8d7499-csz85</span><br><span class=\"line\">10.244.0.14     default edgex-redis-67fffb7666-pvqgw</span><br><span class=\"line\">10.244.0.15     default edgex-support-notifications-58dc7f76b4-tsdxn</span><br><span class=\"line\">10.244.0.16     default edgex-support-rulesengine-8657b7c988-zr8pv</span><br><span class=\"line\">10.244.0.17     default edgex-support-scheduler-d6fd467db-tfqw7</span><br><span class=\"line\">10.244.0.19     default edgex-sys-mgmt-agent-79b476d8dc-2jdw4</span><br><span class=\"line\">10.244.0.20     default edgex-ui-8cfc7f95d-vvhzc</span><br><span class=\"line\">10.244.0.4      kube-system     coredns-f9fd979d6-cqpss</span><br><span class=\"line\">10.244.0.3      kube-system     coredns-f9fd979d6-kvbzm</span><br><span class=\"line\">172.18.0.2      kube-system     etcd-kind-control-plane</span><br><span class=\"line\">172.18.0.2      kube-system     kindnet-br2qc</span><br><span class=\"line\">172.18.0.2      kube-system     kube-apiserver-kind-control-plane</span><br><span class=\"line\">172.18.0.2      kube-system     kube-controller-manager-kind-control-plane</span><br><span class=\"line\">172.18.0.2      kube-system     kube-proxy-4chlm</span><br><span class=\"line\">172.18.0.2      kube-system     kube-scheduler-kind-control-plane</span><br><span class=\"line\">10.244.0.7      kube-system     metrics-server-8dc97c749-h6w8n</span><br><span class=\"line\">10.244.0.6      kubernetes-dashboard    dashboard-metrics-scraper-7b59f7d4df-5rwc6</span><br><span class=\"line\">10.244.0.5      kubernetes-dashboard    kubernetes-dashboard-665f4c5ff-l6tqn</span><br><span class=\"line\">10.244.0.2      local-path-storage      local-path-provisioner-78776bfc44-xl4ht</span><br><span class=\"line\">root@ubuntu:~&#x2F;python#</span><br><span class=\"line\">root@ubuntu:~&#x2F;python# kubectl get pods --all-namespaces -o wide</span><br><span class=\"line\">NAMESPACE              NAME                                                   READY   STATUS             RESTARTS   AGE    IP            NODE                 NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">default                edgex-app-service-configurable-rules-d66d779c7-ksw7c   1&#x2F;1     Running            14         21h    10.244.0.8    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-core-command-6f7cd7d57f-tnmmp                    1&#x2F;1     Running            21         21h    10.244.0.9    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-core-consul-64b88766-7q7kr                       1&#x2F;1     Running            0          21h    10.244.0.18   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-core-data-57b99d7f89-gpfgs                       1&#x2F;1     Running            19         21h    10.244.0.10   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-core-metadata-58dcc95ff4-9ssjg                   1&#x2F;1     Running            21         21h    10.244.0.11   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-device-rest-7944449548-nzcfj                     1&#x2F;1     Running            15         21h    10.244.0.12   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-device-virtual-6c7b8d7499-csz85                  1&#x2F;1     Running            13         21h    10.244.0.13   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-redis-67fffb7666-pvqgw                           1&#x2F;1     Running            0          21h    10.244.0.14   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-support-notifications-58dc7f76b4-tsdxn           1&#x2F;1     Running            13         21h    10.244.0.15   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-support-rulesengine-8657b7c988-zr8pv             1&#x2F;1     Running            0          21h    10.244.0.16   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-support-scheduler-d6fd467db-tfqw7                1&#x2F;1     Running            14         21h    10.244.0.17   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-sys-mgmt-agent-79b476d8dc-2jdw4                  1&#x2F;1     Running            0          21h    10.244.0.19   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">default                edgex-ui-8cfc7f95d-vvhzc                               0&#x2F;1     ImagePullBackOff   0          21h    10.244.0.20   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            coredns-f9fd979d6-cqpss                                1&#x2F;1     Running            0          4d6h   10.244.0.4    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            coredns-f9fd979d6-kvbzm                                1&#x2F;1     Running            0          4d6h   10.244.0.3    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            etcd-kind-control-plane                                1&#x2F;1     Running            0          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kindnet-br2qc                                          1&#x2F;1     Running            0          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kube-apiserver-kind-control-plane                      1&#x2F;1     Running            0          23h    172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kube-controller-manager-kind-control-plane             1&#x2F;1     Running            1          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kube-proxy-4chlm                                       1&#x2F;1     Running            0          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            kube-scheduler-kind-control-plane                      1&#x2F;1     Running            1          4d6h   172.18.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system            metrics-server-8dc97c749-h6w8n                         1&#x2F;1     Running            0          21h    10.244.0.7    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kubernetes-dashboard   dashboard-metrics-scraper-7b59f7d4df-5rwc6             1&#x2F;1     Running            0          21h    10.244.0.6    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kubernetes-dashboard   kubernetes-dashboard-665f4c5ff-l6tqn                   1&#x2F;1     Running            0          21h    10.244.0.5    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">local-path-storage     local-path-provisioner-78776bfc44-xl4ht                1&#x2F;1     Running            1          4d6h   10.244.0.2    kind-control-plane   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n\n<p>更多的examples：<a href=\"https://github.com/kubernetes-client/python/tree/master/example\">https://github.com/kubernetes-client/python/tree/master/example</a></p>\n"},{"title":"kubernetes部署httpd服务","date":"2020-12-02T07:08:32.000Z","_content":"\n```\nroot@ubuntu-001:~# cat httpd.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: httpd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: httpd\n  template:\n    metadata:\n      labels:\n        run: httpd\n    spec:\n      containers:\n      - name: httpd\n        image: httpd\n        ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: httpd-svc\nspec:\n  type: NodePort\n  selector:\n    run: httpd\n  ports:\n  - protocol: TCP\n    nodePort: 30000\n    port: 8080\n    targetPort: 80\n\nroot@ubuntu-001:~# kubectl apply -f httpd.yaml\ndeployment.apps/httpd created\nservice/httpd-svc created\n\nroot@ubuntu-001:~# kubectl get pods\nNAME                    READY   STATUS    RESTARTS   AGE\nhttpd-ff8d77b9b-zz4d4   1/1     Running   0          10s\n\nroot@ubuntu-001:~# kubectl get svc\nNAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE\nhttpd-svc    NodePort    10.97.219.48   <none>        8080:30000/TCP   14s\nkubernetes   ClusterIP   10.96.0.1      <none>        443/TCP          69d\n\n进入pod\nroot@ubuntu-001:~# kubectl exec -it httpd-ff8d77b9b-zz4d4 -- /bin/bash\nroot@httpd-ff8d77b9b-zz4d4:/usr/local/apache2#\n\nroot@httpd-ff8d77b9b-zz4d4:/usr/local/apache2# cat htdocs/index.html\n<html><body><h1>It works!</h1></body></html>\n```\n浏览器输入：http://主机IP:30000/\n\n![1](/images/2020-12-02/1.jpg)\n\n\n```\nroot@ubuntu-001:~# cat httpd.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: httpd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: httpd\n  template:\n    metadata:\n      labels:\n        run: httpd\n    spec:\n      containers:\n      - name: httpd\n        image: httpd\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: host-path\n          mountPath: /usr/local/apache2/htdocs\n      volumes:\n      - name: host-path\n        hostPath:\n           path: /root/test\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: httpd-svc\nspec:\n  type: NodePort\n  selector:\n    run: httpd\n  ports:\n  - protocol: TCP\n    nodePort: 30000\n    port: 8080\n    targetPort: 80\n\n这里进一步使用hostPath将本地test目录，映射到容器的/usr/local/apache2/htdocs目录下\n\nroot@ubuntu-001:~# kubectl apply -f httpd.yaml\ndeployment.apps/httpd configured\nservice/httpd-svc configured\n\nroot@ubuntu-001:~# kubectl get pods\nNAME                     READY   STATUS    RESTARTS   AGE\nhttpd-589bbcf648-28n9x   1/1     Running   0          7m19s\n\nroot@ubuntu-001:~# kubectl get svc\nNAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE\nhttpd-svc    NodePort    10.104.70.26   <none>        8080:30000/TCP   3h52m\nkubernetes   ClusterIP   10.96.0.1      <none>        443/TCP          69d\n\n```\n\n浏览器输入：http://主机IP:30000/\n\n![2](/images/2020-12-02/2.jpg)\n\n\n特别说明：这里我使用了hostPath，且httpd副本我修改成了1，实际上，httpd pod可能落在其他node上，所以严格来说，hostPath难以保证所在node上test的存在\n\n可以考虑使用glusterfs做统一的后端存储\n","source":"_posts/kubernetes部署httpd服务.md","raw":"---\ntitle: kubernetes部署httpd服务\ndate: 2020-12-02 15:08:32\ntags:\n- kubernetes\ncategories:\n- kubernetes\n---\n\n```\nroot@ubuntu-001:~# cat httpd.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: httpd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: httpd\n  template:\n    metadata:\n      labels:\n        run: httpd\n    spec:\n      containers:\n      - name: httpd\n        image: httpd\n        ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: httpd-svc\nspec:\n  type: NodePort\n  selector:\n    run: httpd\n  ports:\n  - protocol: TCP\n    nodePort: 30000\n    port: 8080\n    targetPort: 80\n\nroot@ubuntu-001:~# kubectl apply -f httpd.yaml\ndeployment.apps/httpd created\nservice/httpd-svc created\n\nroot@ubuntu-001:~# kubectl get pods\nNAME                    READY   STATUS    RESTARTS   AGE\nhttpd-ff8d77b9b-zz4d4   1/1     Running   0          10s\n\nroot@ubuntu-001:~# kubectl get svc\nNAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE\nhttpd-svc    NodePort    10.97.219.48   <none>        8080:30000/TCP   14s\nkubernetes   ClusterIP   10.96.0.1      <none>        443/TCP          69d\n\n进入pod\nroot@ubuntu-001:~# kubectl exec -it httpd-ff8d77b9b-zz4d4 -- /bin/bash\nroot@httpd-ff8d77b9b-zz4d4:/usr/local/apache2#\n\nroot@httpd-ff8d77b9b-zz4d4:/usr/local/apache2# cat htdocs/index.html\n<html><body><h1>It works!</h1></body></html>\n```\n浏览器输入：http://主机IP:30000/\n\n![1](/images/2020-12-02/1.jpg)\n\n\n```\nroot@ubuntu-001:~# cat httpd.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: httpd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: httpd\n  template:\n    metadata:\n      labels:\n        run: httpd\n    spec:\n      containers:\n      - name: httpd\n        image: httpd\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: host-path\n          mountPath: /usr/local/apache2/htdocs\n      volumes:\n      - name: host-path\n        hostPath:\n           path: /root/test\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: httpd-svc\nspec:\n  type: NodePort\n  selector:\n    run: httpd\n  ports:\n  - protocol: TCP\n    nodePort: 30000\n    port: 8080\n    targetPort: 80\n\n这里进一步使用hostPath将本地test目录，映射到容器的/usr/local/apache2/htdocs目录下\n\nroot@ubuntu-001:~# kubectl apply -f httpd.yaml\ndeployment.apps/httpd configured\nservice/httpd-svc configured\n\nroot@ubuntu-001:~# kubectl get pods\nNAME                     READY   STATUS    RESTARTS   AGE\nhttpd-589bbcf648-28n9x   1/1     Running   0          7m19s\n\nroot@ubuntu-001:~# kubectl get svc\nNAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE\nhttpd-svc    NodePort    10.104.70.26   <none>        8080:30000/TCP   3h52m\nkubernetes   ClusterIP   10.96.0.1      <none>        443/TCP          69d\n\n```\n\n浏览器输入：http://主机IP:30000/\n\n![2](/images/2020-12-02/2.jpg)\n\n\n特别说明：这里我使用了hostPath，且httpd副本我修改成了1，实际上，httpd pod可能落在其他node上，所以严格来说，hostPath难以保证所在node上test的存在\n\n可以考虑使用glusterfs做统一的后端存储\n","slug":"kubernetes部署httpd服务","published":1,"updated":"2020-12-02T07:35:21.898Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cki73ih190009h0l7hxnacgw6","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# cat httpd.yaml</span><br><span class=\"line\">apiVersion: apps&#x2F;v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: httpd</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      run: httpd</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        run: httpd</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: httpd</span><br><span class=\"line\">        image: httpd</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 80</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: httpd-svc</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    run: httpd</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - protocol: TCP</span><br><span class=\"line\">    nodePort: 30000</span><br><span class=\"line\">    port: 8080</span><br><span class=\"line\">    targetPort: 80</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl apply -f httpd.yaml</span><br><span class=\"line\">deployment.apps&#x2F;httpd created</span><br><span class=\"line\">service&#x2F;httpd-svc created</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl get pods</span><br><span class=\"line\">NAME                    READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">httpd-ff8d77b9b-zz4d4   1&#x2F;1     Running   0          10s</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl get svc</span><br><span class=\"line\">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class=\"line\">httpd-svc    NodePort    10.97.219.48   &lt;none&gt;        8080:30000&#x2F;TCP   14s</span><br><span class=\"line\">kubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443&#x2F;TCP          69d</span><br><span class=\"line\"></span><br><span class=\"line\">进入pod</span><br><span class=\"line\">root@ubuntu-001:~# kubectl exec -it httpd-ff8d77b9b-zz4d4 -- &#x2F;bin&#x2F;bash</span><br><span class=\"line\">root@httpd-ff8d77b9b-zz4d4:&#x2F;usr&#x2F;local&#x2F;apache2#</span><br><span class=\"line\"></span><br><span class=\"line\">root@httpd-ff8d77b9b-zz4d4:&#x2F;usr&#x2F;local&#x2F;apache2# cat htdocs&#x2F;index.html</span><br><span class=\"line\">&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;&#x2F;h1&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>\n<p>浏览器输入：http://主机IP:30000/</p>\n<p><img src=\"/images/2020-12-02/1.jpg\" alt=\"1\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# cat httpd.yaml</span><br><span class=\"line\">apiVersion: apps&#x2F;v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: httpd</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      run: httpd</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        run: httpd</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: httpd</span><br><span class=\"line\">        image: httpd</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 80</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: host-path</span><br><span class=\"line\">          mountPath: &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: host-path</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">           path: &#x2F;root&#x2F;test</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: httpd-svc</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    run: httpd</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - protocol: TCP</span><br><span class=\"line\">    nodePort: 30000</span><br><span class=\"line\">    port: 8080</span><br><span class=\"line\">    targetPort: 80</span><br><span class=\"line\"></span><br><span class=\"line\">这里进一步使用hostPath将本地test目录，映射到容器的&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs目录下</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl apply -f httpd.yaml</span><br><span class=\"line\">deployment.apps&#x2F;httpd configured</span><br><span class=\"line\">service&#x2F;httpd-svc configured</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl get pods</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">httpd-589bbcf648-28n9x   1&#x2F;1     Running   0          7m19s</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl get svc</span><br><span class=\"line\">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class=\"line\">httpd-svc    NodePort    10.104.70.26   &lt;none&gt;        8080:30000&#x2F;TCP   3h52m</span><br><span class=\"line\">kubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443&#x2F;TCP          69d</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>浏览器输入：http://主机IP:30000/</p>\n<p><img src=\"/images/2020-12-02/2.jpg\" alt=\"2\"></p>\n<p>特别说明：这里我使用了hostPath，且httpd副本我修改成了1，实际上，httpd pod可能落在其他node上，所以严格来说，hostPath难以保证所在node上test的存在</p>\n<p>可以考虑使用glusterfs做统一的后端存储</p>\n","site":{"data":{}},"excerpt":"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n\n\nroot@ubuntu-001:~# cat httpd.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: httpd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n ","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# cat httpd.yaml</span><br><span class=\"line\">apiVersion: apps&#x2F;v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: httpd</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      run: httpd</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        run: httpd</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: httpd</span><br><span class=\"line\">        image: httpd</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 80</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: httpd-svc</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    run: httpd</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - protocol: TCP</span><br><span class=\"line\">    nodePort: 30000</span><br><span class=\"line\">    port: 8080</span><br><span class=\"line\">    targetPort: 80</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl apply -f httpd.yaml</span><br><span class=\"line\">deployment.apps&#x2F;httpd created</span><br><span class=\"line\">service&#x2F;httpd-svc created</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl get pods</span><br><span class=\"line\">NAME                    READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">httpd-ff8d77b9b-zz4d4   1&#x2F;1     Running   0          10s</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl get svc</span><br><span class=\"line\">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class=\"line\">httpd-svc    NodePort    10.97.219.48   &lt;none&gt;        8080:30000&#x2F;TCP   14s</span><br><span class=\"line\">kubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443&#x2F;TCP          69d</span><br><span class=\"line\"></span><br><span class=\"line\">进入pod</span><br><span class=\"line\">root@ubuntu-001:~# kubectl exec -it httpd-ff8d77b9b-zz4d4 -- &#x2F;bin&#x2F;bash</span><br><span class=\"line\">root@httpd-ff8d77b9b-zz4d4:&#x2F;usr&#x2F;local&#x2F;apache2#</span><br><span class=\"line\"></span><br><span class=\"line\">root@httpd-ff8d77b9b-zz4d4:&#x2F;usr&#x2F;local&#x2F;apache2# cat htdocs&#x2F;index.html</span><br><span class=\"line\">&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;&#x2F;h1&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>\n<p>浏览器输入：http://主机IP:30000/</p>\n<p><img src=\"/images/2020-12-02/1.jpg\" alt=\"1\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu-001:~# cat httpd.yaml</span><br><span class=\"line\">apiVersion: apps&#x2F;v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: httpd</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      run: httpd</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        run: httpd</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: httpd</span><br><span class=\"line\">        image: httpd</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 80</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: host-path</span><br><span class=\"line\">          mountPath: &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: host-path</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">           path: &#x2F;root&#x2F;test</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: httpd-svc</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    run: httpd</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - protocol: TCP</span><br><span class=\"line\">    nodePort: 30000</span><br><span class=\"line\">    port: 8080</span><br><span class=\"line\">    targetPort: 80</span><br><span class=\"line\"></span><br><span class=\"line\">这里进一步使用hostPath将本地test目录，映射到容器的&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs目录下</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl apply -f httpd.yaml</span><br><span class=\"line\">deployment.apps&#x2F;httpd configured</span><br><span class=\"line\">service&#x2F;httpd-svc configured</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl get pods</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">httpd-589bbcf648-28n9x   1&#x2F;1     Running   0          7m19s</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu-001:~# kubectl get svc</span><br><span class=\"line\">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class=\"line\">httpd-svc    NodePort    10.104.70.26   &lt;none&gt;        8080:30000&#x2F;TCP   3h52m</span><br><span class=\"line\">kubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443&#x2F;TCP          69d</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>浏览器输入：http://主机IP:30000/</p>\n<p><img src=\"/images/2020-12-02/2.jpg\" alt=\"2\"></p>\n<p>特别说明：这里我使用了hostPath，且httpd副本我修改成了1，实际上，httpd pod可能落在其他node上，所以严格来说，hostPath难以保证所在node上test的存在</p>\n<p>可以考虑使用glusterfs做统一的后端存储</p>\n"},{"title":"如何使用github作为Helm的chart仓库","date":"2020-12-01T01:35:30.000Z","_content":"\n# 前提条件：\n1、已安装git\n2、已注册github账户\n3、安装helm（推荐helm3，下载地址：[https://github.com/helm/helm/releases/(https://github.com/helm/helm/releases/)）\n\n# 操作步骤：\n## 1、在github创建仓库，取名为helm-chart\n![创建仓库](https://upload-images.jianshu.io/upload_images/10839544-8d2d6093ca2aff4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n## 2、下载helm-chart仓库到本地\n```\nzj@zj-Z390-UD:~/code$ git clone https://github.com/yushanjin/helm-chart.git\n正克隆到 'helm-chart'...\nremote: Enumerating objects: 3, done.\nremote: Counting objects: 100% (3/3), done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\n展开对象中: 100% (3/3), 完成.\n```\n## 3、创建chart目录\n ```\nzj@zj-Z390-UD:~/code$ cd helm-chart/\nzj@zj-Z390-UD:~/code/helm-chart$ ll\n总用量 16\ndrwxr-xr-x 3 zj zj 4096 4月   8 14:04 ./\ndrwxr-xr-x 4 zj zj 4096 4月   8 14:04 ../\ndrwxr-xr-x 8 zj zj 4096 4月   8 14:04 .git/\n-rw-r--r-- 1 zj zj   77 4月   8 14:04 README.md\nzj@zj-Z390-UD:~/code/helm-chart$ helm create test\nCreating test\n\n注意：可以在终端执行 source <(helm completion bash)，启动helm命令自动补全功能\nzj@zj-Z390-UD:~/code/helm-chart$ tree test/\ntest/\n├── charts\n├── Chart.yaml\n├── templates\n│   ├── deployment.yaml\n│   ├── _helpers.tpl\n│   ├── ingress.yaml\n│   ├── NOTES.txt\n│   ├── serviceaccount.yaml\n│   ├── service.yaml\n│   └── tests\n│       └── test-connection.yaml\n└── values.yaml\n\n3 directories, 9 files\n```\n## 4、打包chart包\n```\nzj@zj-Z390-UD:~/code/helm-chart$ helm package test/\nSuccessfully packaged chart and saved it to: /home/zj/code/helm-chart/test-0.1.0.tgz\nzj@zj-Z390-UD:~/code/helm-chart$ helm repo index --url https://yushanjin.github.io/helm-chart/ .\nzj@zj-Z390-UD:~/code/helm-chart$ cat index.yaml \napiVersion: v1\nentries:\n  test:\n  - apiVersion: v2\n    appVersion: 1.16.0\n    created: \"2020-04-08T14:19:31.079089336+08:00\"\n    description: A Helm chart for Kubernetes\n    digest: 6de7ab4f2da011db9ef8e1def8d2fca7d4e79bb4e81e46152a8d3a2969b73820\n    name: test\n    type: application\n    urls:\n    - https://yushanjin.github.io/helm-chart/test-0.1.0.tgz\n    version: 0.1.0\ngenerated: \"2020-04-08T14:19:31.078672885+08:00\"\n```\n## 5、push到github\n```\nzj@zj-Z390-UD:~/code/helm-chart$ git status\n位于分支 master\n您的分支与上游分支 'origin/master' 一致。\n\n未跟踪的文件:\n  （使用 \"git add <文件>...\" 以包含要提交的内容）\n\n\tindex.yaml\n\ttest-0.1.0.tgz\n\ttest/\n\n提交为空，但是存在尚未跟踪的文件（使用 \"git add\" 建立跟踪）\nzj@zj-Z390-UD:~/code/helm-chart$ git add .\nzj@zj-Z390-UD:~/code/helm-chart$ git status\n位于分支 master\n您的分支与上游分支 'origin/master' 一致。\n\n要提交的变更：\n  （使用 \"git reset HEAD <文件>...\" 以取消暂存）\n\n\t新文件：   index.yaml\n\t新文件：   test-0.1.0.tgz\n\t新文件：   test/.helmignore\n\t新文件：   test/Chart.yaml\n\t新文件：   test/templates/NOTES.txt\n\t新文件：   test/templates/_helpers.tpl\n\t新文件：   test/templates/deployment.yaml\n\t新文件：   test/templates/ingress.yaml\n\t新文件：   test/templates/service.yaml\n\t新文件：   test/templates/serviceaccount.yaml\n\t新文件：   test/templates/tests/test-connection.yaml\n\t新文件：   test/values.yaml\n\nzj@zj-Z390-UD:~/code/helm-chart$ git commit -m \"创建test的chart包\"\n[master 5ae813c] 创建test的chart包\n 12 files changed, 348 insertions(+)\n create mode 100644 index.yaml\n create mode 100644 test-0.1.0.tgz\n create mode 100644 test/.helmignore\n create mode 100644 test/Chart.yaml\n create mode 100644 test/templates/NOTES.txt\n create mode 100644 test/templates/_helpers.tpl\n create mode 100644 test/templates/deployment.yaml\n create mode 100644 test/templates/ingress.yaml\n create mode 100644 test/templates/service.yaml\n create mode 100644 test/templates/serviceaccount.yaml\n create mode 100644 test/templates/tests/test-connection.yaml\n create mode 100644 test/values.yaml\nzj@zj-Z390-UD:~/code/helm-chart$ git push origin master\nUsername for 'https://github.com': yushanjin\nPassword for 'https://yushanjin@github.com': \n对象计数中: 17, 完成.\nDelta compression using up to 8 threads.\n压缩对象中: 100% (16/16), 完成.\n写入对象中: 100% (17/17), 8.32 KiB | 1.66 MiB/s, 完成.\nTotal 17 (delta 0), reused 0 (delta 0)\nTo https://github.com/yushanjin/helm-chart.git\n   48e2023..5ae813c  master -> master\n```\n注意： 我这里本地没有创建其他分支，所以直接push到master分支了\n## 6、设置github上helm-chart仓库的GitHub Pages（在仓库的settings里设置）\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-fece4f06795a48d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n登录：https://yushanjin.github.io/helm-chart，页面内容为README.md的内容\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-9f84217a461cce46.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n**注意**： 我修改过README.md文件\n## 7、本地添加自己的chart仓库\n```\nzj@zj-Z390-UD:~/code/helm-chart$ helm repo list\nError: no repositories to show\nzj@zj-Z390-UD:~/code/helm-chart$ helm repo add myrepo https://yushanjin.github.io/helm-chart\n\"myrepo\" has been added to your repositories\nzj@zj-Z390-UD:~/code/helm-chart$ helm repo list\nNAME  \tURL                                   \nmyrepo\thttps://yushanjin.github.io/helm-chart\nzj@zj-Z390-UD:~/code/helm-chart$ helm search repo test\nNAME       \tCHART VERSION\tAPP VERSION\tDESCRIPTION                \nmyrepo/test\t0.1.0        \t1.16.0     \tA Helm chart for Kubernetes\n```\n\n至此，就可以使用**helm install xxx myrepo/test** 安装test了\n","source":"_posts/如何使用github作为Helm的chart仓库.md","raw":"---\ntitle: 如何使用github作为Helm的chart仓库\ndate: 2020-12-01 09:35:30\ntags:\n- GitHub\n- helm\ncategories:\n- helm \n---\n\n# 前提条件：\n1、已安装git\n2、已注册github账户\n3、安装helm（推荐helm3，下载地址：[https://github.com/helm/helm/releases/(https://github.com/helm/helm/releases/)）\n\n# 操作步骤：\n## 1、在github创建仓库，取名为helm-chart\n![创建仓库](https://upload-images.jianshu.io/upload_images/10839544-8d2d6093ca2aff4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n## 2、下载helm-chart仓库到本地\n```\nzj@zj-Z390-UD:~/code$ git clone https://github.com/yushanjin/helm-chart.git\n正克隆到 'helm-chart'...\nremote: Enumerating objects: 3, done.\nremote: Counting objects: 100% (3/3), done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\n展开对象中: 100% (3/3), 完成.\n```\n## 3、创建chart目录\n ```\nzj@zj-Z390-UD:~/code$ cd helm-chart/\nzj@zj-Z390-UD:~/code/helm-chart$ ll\n总用量 16\ndrwxr-xr-x 3 zj zj 4096 4月   8 14:04 ./\ndrwxr-xr-x 4 zj zj 4096 4月   8 14:04 ../\ndrwxr-xr-x 8 zj zj 4096 4月   8 14:04 .git/\n-rw-r--r-- 1 zj zj   77 4月   8 14:04 README.md\nzj@zj-Z390-UD:~/code/helm-chart$ helm create test\nCreating test\n\n注意：可以在终端执行 source <(helm completion bash)，启动helm命令自动补全功能\nzj@zj-Z390-UD:~/code/helm-chart$ tree test/\ntest/\n├── charts\n├── Chart.yaml\n├── templates\n│   ├── deployment.yaml\n│   ├── _helpers.tpl\n│   ├── ingress.yaml\n│   ├── NOTES.txt\n│   ├── serviceaccount.yaml\n│   ├── service.yaml\n│   └── tests\n│       └── test-connection.yaml\n└── values.yaml\n\n3 directories, 9 files\n```\n## 4、打包chart包\n```\nzj@zj-Z390-UD:~/code/helm-chart$ helm package test/\nSuccessfully packaged chart and saved it to: /home/zj/code/helm-chart/test-0.1.0.tgz\nzj@zj-Z390-UD:~/code/helm-chart$ helm repo index --url https://yushanjin.github.io/helm-chart/ .\nzj@zj-Z390-UD:~/code/helm-chart$ cat index.yaml \napiVersion: v1\nentries:\n  test:\n  - apiVersion: v2\n    appVersion: 1.16.0\n    created: \"2020-04-08T14:19:31.079089336+08:00\"\n    description: A Helm chart for Kubernetes\n    digest: 6de7ab4f2da011db9ef8e1def8d2fca7d4e79bb4e81e46152a8d3a2969b73820\n    name: test\n    type: application\n    urls:\n    - https://yushanjin.github.io/helm-chart/test-0.1.0.tgz\n    version: 0.1.0\ngenerated: \"2020-04-08T14:19:31.078672885+08:00\"\n```\n## 5、push到github\n```\nzj@zj-Z390-UD:~/code/helm-chart$ git status\n位于分支 master\n您的分支与上游分支 'origin/master' 一致。\n\n未跟踪的文件:\n  （使用 \"git add <文件>...\" 以包含要提交的内容）\n\n\tindex.yaml\n\ttest-0.1.0.tgz\n\ttest/\n\n提交为空，但是存在尚未跟踪的文件（使用 \"git add\" 建立跟踪）\nzj@zj-Z390-UD:~/code/helm-chart$ git add .\nzj@zj-Z390-UD:~/code/helm-chart$ git status\n位于分支 master\n您的分支与上游分支 'origin/master' 一致。\n\n要提交的变更：\n  （使用 \"git reset HEAD <文件>...\" 以取消暂存）\n\n\t新文件：   index.yaml\n\t新文件：   test-0.1.0.tgz\n\t新文件：   test/.helmignore\n\t新文件：   test/Chart.yaml\n\t新文件：   test/templates/NOTES.txt\n\t新文件：   test/templates/_helpers.tpl\n\t新文件：   test/templates/deployment.yaml\n\t新文件：   test/templates/ingress.yaml\n\t新文件：   test/templates/service.yaml\n\t新文件：   test/templates/serviceaccount.yaml\n\t新文件：   test/templates/tests/test-connection.yaml\n\t新文件：   test/values.yaml\n\nzj@zj-Z390-UD:~/code/helm-chart$ git commit -m \"创建test的chart包\"\n[master 5ae813c] 创建test的chart包\n 12 files changed, 348 insertions(+)\n create mode 100644 index.yaml\n create mode 100644 test-0.1.0.tgz\n create mode 100644 test/.helmignore\n create mode 100644 test/Chart.yaml\n create mode 100644 test/templates/NOTES.txt\n create mode 100644 test/templates/_helpers.tpl\n create mode 100644 test/templates/deployment.yaml\n create mode 100644 test/templates/ingress.yaml\n create mode 100644 test/templates/service.yaml\n create mode 100644 test/templates/serviceaccount.yaml\n create mode 100644 test/templates/tests/test-connection.yaml\n create mode 100644 test/values.yaml\nzj@zj-Z390-UD:~/code/helm-chart$ git push origin master\nUsername for 'https://github.com': yushanjin\nPassword for 'https://yushanjin@github.com': \n对象计数中: 17, 完成.\nDelta compression using up to 8 threads.\n压缩对象中: 100% (16/16), 完成.\n写入对象中: 100% (17/17), 8.32 KiB | 1.66 MiB/s, 完成.\nTotal 17 (delta 0), reused 0 (delta 0)\nTo https://github.com/yushanjin/helm-chart.git\n   48e2023..5ae813c  master -> master\n```\n注意： 我这里本地没有创建其他分支，所以直接push到master分支了\n## 6、设置github上helm-chart仓库的GitHub Pages（在仓库的settings里设置）\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-fece4f06795a48d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n登录：https://yushanjin.github.io/helm-chart，页面内容为README.md的内容\n![image.png](https://upload-images.jianshu.io/upload_images/10839544-9f84217a461cce46.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n**注意**： 我修改过README.md文件\n## 7、本地添加自己的chart仓库\n```\nzj@zj-Z390-UD:~/code/helm-chart$ helm repo list\nError: no repositories to show\nzj@zj-Z390-UD:~/code/helm-chart$ helm repo add myrepo https://yushanjin.github.io/helm-chart\n\"myrepo\" has been added to your repositories\nzj@zj-Z390-UD:~/code/helm-chart$ helm repo list\nNAME  \tURL                                   \nmyrepo\thttps://yushanjin.github.io/helm-chart\nzj@zj-Z390-UD:~/code/helm-chart$ helm search repo test\nNAME       \tCHART VERSION\tAPP VERSION\tDESCRIPTION                \nmyrepo/test\t0.1.0        \t1.16.0     \tA Helm chart for Kubernetes\n```\n\n至此，就可以使用**helm install xxx myrepo/test** 安装test了\n","slug":"如何使用github作为Helm的chart仓库","published":1,"updated":"2020-12-01T01:39:15.943Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cki73ih1a000ah0l7ek6e38vx","content":"<h1 id=\"前提条件：\"><a href=\"#前提条件：\" class=\"headerlink\" title=\"前提条件：\"></a>前提条件：</h1><p>1、已安装git<br>2、已注册github账户<br>3、安装helm（推荐helm3，下载地址：[<a href=\"https://github.com/helm/helm/releases/(https://github.com/helm/helm/releases/)%EF%BC%89\">https://github.com/helm/helm/releases/(https://github.com/helm/helm/releases/)）</a></p>\n<h1 id=\"操作步骤：\"><a href=\"#操作步骤：\" class=\"headerlink\" title=\"操作步骤：\"></a>操作步骤：</h1><h2 id=\"1、在github创建仓库，取名为helm-chart\"><a href=\"#1、在github创建仓库，取名为helm-chart\" class=\"headerlink\" title=\"1、在github创建仓库，取名为helm-chart\"></a>1、在github创建仓库，取名为helm-chart</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-8d2d6093ca2aff4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"创建仓库\"></p>\n<h2 id=\"2、下载helm-chart仓库到本地\"><a href=\"#2、下载helm-chart仓库到本地\" class=\"headerlink\" title=\"2、下载helm-chart仓库到本地\"></a>2、下载helm-chart仓库到本地</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code$ git clone https:&#x2F;&#x2F;github.com&#x2F;yushanjin&#x2F;helm-chart.git</span><br><span class=\"line\">正克隆到 &#39;helm-chart&#39;...</span><br><span class=\"line\">remote: Enumerating objects: 3, done.</span><br><span class=\"line\">remote: Counting objects: 100% (3&#x2F;3), done.</span><br><span class=\"line\">remote: Compressing objects: 100% (2&#x2F;2), done.</span><br><span class=\"line\">remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class=\"line\">展开对象中: 100% (3&#x2F;3), 完成.</span><br></pre></td></tr></table></figure>\n<h2 id=\"3、创建chart目录\"><a href=\"#3、创建chart目录\" class=\"headerlink\" title=\"3、创建chart目录\"></a>3、创建chart目录</h2> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code$ cd helm-chart&#x2F;</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ ll</span><br><span class=\"line\">总用量 16</span><br><span class=\"line\">drwxr-xr-x 3 zj zj 4096 4月   8 14:04 .&#x2F;</span><br><span class=\"line\">drwxr-xr-x 4 zj zj 4096 4月   8 14:04 ..&#x2F;</span><br><span class=\"line\">drwxr-xr-x 8 zj zj 4096 4月   8 14:04 .git&#x2F;</span><br><span class=\"line\">-rw-r--r-- 1 zj zj   77 4月   8 14:04 README.md</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm create test</span><br><span class=\"line\">Creating test</span><br><span class=\"line\"></span><br><span class=\"line\">注意：可以在终端执行 source &lt;(helm completion bash)，启动helm命令自动补全功能</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ tree test&#x2F;</span><br><span class=\"line\">test&#x2F;</span><br><span class=\"line\">├── charts</span><br><span class=\"line\">├── Chart.yaml</span><br><span class=\"line\">├── templates</span><br><span class=\"line\">│   ├── deployment.yaml</span><br><span class=\"line\">│   ├── _helpers.tpl</span><br><span class=\"line\">│   ├── ingress.yaml</span><br><span class=\"line\">│   ├── NOTES.txt</span><br><span class=\"line\">│   ├── serviceaccount.yaml</span><br><span class=\"line\">│   ├── service.yaml</span><br><span class=\"line\">│   └── tests</span><br><span class=\"line\">│       └── test-connection.yaml</span><br><span class=\"line\">└── values.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">3 directories, 9 files</span><br></pre></td></tr></table></figure>\n<h2 id=\"4、打包chart包\"><a href=\"#4、打包chart包\" class=\"headerlink\" title=\"4、打包chart包\"></a>4、打包chart包</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm package test&#x2F;</span><br><span class=\"line\">Successfully packaged chart and saved it to: &#x2F;home&#x2F;zj&#x2F;code&#x2F;helm-chart&#x2F;test-0.1.0.tgz</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm repo index --url https:&#x2F;&#x2F;yushanjin.github.io&#x2F;helm-chart&#x2F; .</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ cat index.yaml </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">entries:</span><br><span class=\"line\">  test:</span><br><span class=\"line\">  - apiVersion: v2</span><br><span class=\"line\">    appVersion: 1.16.0</span><br><span class=\"line\">    created: &quot;2020-04-08T14:19:31.079089336+08:00&quot;</span><br><span class=\"line\">    description: A Helm chart for Kubernetes</span><br><span class=\"line\">    digest: 6de7ab4f2da011db9ef8e1def8d2fca7d4e79bb4e81e46152a8d3a2969b73820</span><br><span class=\"line\">    name: test</span><br><span class=\"line\">    type: application</span><br><span class=\"line\">    urls:</span><br><span class=\"line\">    - https:&#x2F;&#x2F;yushanjin.github.io&#x2F;helm-chart&#x2F;test-0.1.0.tgz</span><br><span class=\"line\">    version: 0.1.0</span><br><span class=\"line\">generated: &quot;2020-04-08T14:19:31.078672885+08:00&quot;</span><br></pre></td></tr></table></figure>\n<h2 id=\"5、push到github\"><a href=\"#5、push到github\" class=\"headerlink\" title=\"5、push到github\"></a>5、push到github</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git status</span><br><span class=\"line\">位于分支 master</span><br><span class=\"line\">您的分支与上游分支 &#39;origin&#x2F;master&#39; 一致。</span><br><span class=\"line\"></span><br><span class=\"line\">未跟踪的文件:</span><br><span class=\"line\">  （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）</span><br><span class=\"line\"></span><br><span class=\"line\">\tindex.yaml</span><br><span class=\"line\">\ttest-0.1.0.tgz</span><br><span class=\"line\">\ttest&#x2F;</span><br><span class=\"line\"></span><br><span class=\"line\">提交为空，但是存在尚未跟踪的文件（使用 &quot;git add&quot; 建立跟踪）</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git add .</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git status</span><br><span class=\"line\">位于分支 master</span><br><span class=\"line\">您的分支与上游分支 &#39;origin&#x2F;master&#39; 一致。</span><br><span class=\"line\"></span><br><span class=\"line\">要提交的变更：</span><br><span class=\"line\">  （使用 &quot;git reset HEAD &lt;文件&gt;...&quot; 以取消暂存）</span><br><span class=\"line\"></span><br><span class=\"line\">\t新文件：   index.yaml</span><br><span class=\"line\">\t新文件：   test-0.1.0.tgz</span><br><span class=\"line\">\t新文件：   test&#x2F;.helmignore</span><br><span class=\"line\">\t新文件：   test&#x2F;Chart.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;NOTES.txt</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;_helpers.tpl</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;deployment.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;ingress.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;service.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;serviceaccount.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;tests&#x2F;test-connection.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;values.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git commit -m &quot;创建test的chart包&quot;</span><br><span class=\"line\">[master 5ae813c] 创建test的chart包</span><br><span class=\"line\"> 12 files changed, 348 insertions(+)</span><br><span class=\"line\"> create mode 100644 index.yaml</span><br><span class=\"line\"> create mode 100644 test-0.1.0.tgz</span><br><span class=\"line\"> create mode 100644 test&#x2F;.helmignore</span><br><span class=\"line\"> create mode 100644 test&#x2F;Chart.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;NOTES.txt</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;_helpers.tpl</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;deployment.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;ingress.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;service.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;serviceaccount.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;tests&#x2F;test-connection.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;values.yaml</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git push origin master</span><br><span class=\"line\">Username for &#39;https:&#x2F;&#x2F;github.com&#39;: yushanjin</span><br><span class=\"line\">Password for &#39;https:&#x2F;&#x2F;yushanjin@github.com&#39;: </span><br><span class=\"line\">对象计数中: 17, 完成.</span><br><span class=\"line\">Delta compression using up to 8 threads.</span><br><span class=\"line\">压缩对象中: 100% (16&#x2F;16), 完成.</span><br><span class=\"line\">写入对象中: 100% (17&#x2F;17), 8.32 KiB | 1.66 MiB&#x2F;s, 完成.</span><br><span class=\"line\">Total 17 (delta 0), reused 0 (delta 0)</span><br><span class=\"line\">To https:&#x2F;&#x2F;github.com&#x2F;yushanjin&#x2F;helm-chart.git</span><br><span class=\"line\">   48e2023..5ae813c  master -&gt; master</span><br></pre></td></tr></table></figure>\n<p>注意： 我这里本地没有创建其他分支，所以直接push到master分支了</p>\n<h2 id=\"6、设置github上helm-chart仓库的GitHub-Pages（在仓库的settings里设置）\"><a href=\"#6、设置github上helm-chart仓库的GitHub-Pages（在仓库的settings里设置）\" class=\"headerlink\" title=\"6、设置github上helm-chart仓库的GitHub Pages（在仓库的settings里设置）\"></a>6、设置github上helm-chart仓库的GitHub Pages（在仓库的settings里设置）</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-fece4f06795a48d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"><br>登录：<a href=\"https://yushanjin.github.io/helm-chart%EF%BC%8C%E9%A1%B5%E9%9D%A2%E5%86%85%E5%AE%B9%E4%B8%BAREADME.md%E7%9A%84%E5%86%85%E5%AE%B9\">https://yushanjin.github.io/helm-chart，页面内容为README.md的内容</a><br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-9f84217a461cce46.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p><strong>注意</strong>： 我修改过README.md文件</p>\n<h2 id=\"7、本地添加自己的chart仓库\"><a href=\"#7、本地添加自己的chart仓库\" class=\"headerlink\" title=\"7、本地添加自己的chart仓库\"></a>7、本地添加自己的chart仓库</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm repo list</span><br><span class=\"line\">Error: no repositories to show</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm repo add myrepo https:&#x2F;&#x2F;yushanjin.github.io&#x2F;helm-chart</span><br><span class=\"line\">&quot;myrepo&quot; has been added to your repositories</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm repo list</span><br><span class=\"line\">NAME  \tURL                                   </span><br><span class=\"line\">myrepo\thttps:&#x2F;&#x2F;yushanjin.github.io&#x2F;helm-chart</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm search repo test</span><br><span class=\"line\">NAME       \tCHART VERSION\tAPP VERSION\tDESCRIPTION                </span><br><span class=\"line\">myrepo&#x2F;test\t0.1.0        \t1.16.0     \tA Helm chart for Kubernetes</span><br></pre></td></tr></table></figure>\n\n<p>至此，就可以使用<strong>helm install xxx myrepo/test</strong> 安装test了</p>\n","site":{"data":{}},"excerpt":"前提条件：\n1、已安装git\n2、已注册github账户\n3、安装helm（推荐helm3，下载地址：[https://github.com/helm/helm/releases/(https://github.com/helm/helm/releases/)）\n\n操作步骤：\n1、在github创建仓库，取名为helm-chart\n\n\n2、下载helm-chart仓库到本地\n1\n2\n3\n4\n5\n6\n7\n\n\nzj@zj-Z390-UD:~/code$ git clone https://github.com/yushanjin/helm-chart.git\n正克隆到 'helm-chart'..","more":"<h1 id=\"前提条件：\"><a href=\"#前提条件：\" class=\"headerlink\" title=\"前提条件：\"></a>前提条件：</h1><p>1、已安装git<br>2、已注册github账户<br>3、安装helm（推荐helm3，下载地址：[<a href=\"https://github.com/helm/helm/releases/(https://github.com/helm/helm/releases/)%EF%BC%89\">https://github.com/helm/helm/releases/(https://github.com/helm/helm/releases/)）</a></p>\n<h1 id=\"操作步骤：\"><a href=\"#操作步骤：\" class=\"headerlink\" title=\"操作步骤：\"></a>操作步骤：</h1><h2 id=\"1、在github创建仓库，取名为helm-chart\"><a href=\"#1、在github创建仓库，取名为helm-chart\" class=\"headerlink\" title=\"1、在github创建仓库，取名为helm-chart\"></a>1、在github创建仓库，取名为helm-chart</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-8d2d6093ca2aff4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"创建仓库\"></p>\n<h2 id=\"2、下载helm-chart仓库到本地\"><a href=\"#2、下载helm-chart仓库到本地\" class=\"headerlink\" title=\"2、下载helm-chart仓库到本地\"></a>2、下载helm-chart仓库到本地</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code$ git clone https:&#x2F;&#x2F;github.com&#x2F;yushanjin&#x2F;helm-chart.git</span><br><span class=\"line\">正克隆到 &#39;helm-chart&#39;...</span><br><span class=\"line\">remote: Enumerating objects: 3, done.</span><br><span class=\"line\">remote: Counting objects: 100% (3&#x2F;3), done.</span><br><span class=\"line\">remote: Compressing objects: 100% (2&#x2F;2), done.</span><br><span class=\"line\">remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class=\"line\">展开对象中: 100% (3&#x2F;3), 完成.</span><br></pre></td></tr></table></figure>\n<h2 id=\"3、创建chart目录\"><a href=\"#3、创建chart目录\" class=\"headerlink\" title=\"3、创建chart目录\"></a>3、创建chart目录</h2> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code$ cd helm-chart&#x2F;</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ ll</span><br><span class=\"line\">总用量 16</span><br><span class=\"line\">drwxr-xr-x 3 zj zj 4096 4月   8 14:04 .&#x2F;</span><br><span class=\"line\">drwxr-xr-x 4 zj zj 4096 4月   8 14:04 ..&#x2F;</span><br><span class=\"line\">drwxr-xr-x 8 zj zj 4096 4月   8 14:04 .git&#x2F;</span><br><span class=\"line\">-rw-r--r-- 1 zj zj   77 4月   8 14:04 README.md</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm create test</span><br><span class=\"line\">Creating test</span><br><span class=\"line\"></span><br><span class=\"line\">注意：可以在终端执行 source &lt;(helm completion bash)，启动helm命令自动补全功能</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ tree test&#x2F;</span><br><span class=\"line\">test&#x2F;</span><br><span class=\"line\">├── charts</span><br><span class=\"line\">├── Chart.yaml</span><br><span class=\"line\">├── templates</span><br><span class=\"line\">│   ├── deployment.yaml</span><br><span class=\"line\">│   ├── _helpers.tpl</span><br><span class=\"line\">│   ├── ingress.yaml</span><br><span class=\"line\">│   ├── NOTES.txt</span><br><span class=\"line\">│   ├── serviceaccount.yaml</span><br><span class=\"line\">│   ├── service.yaml</span><br><span class=\"line\">│   └── tests</span><br><span class=\"line\">│       └── test-connection.yaml</span><br><span class=\"line\">└── values.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">3 directories, 9 files</span><br></pre></td></tr></table></figure>\n<h2 id=\"4、打包chart包\"><a href=\"#4、打包chart包\" class=\"headerlink\" title=\"4、打包chart包\"></a>4、打包chart包</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm package test&#x2F;</span><br><span class=\"line\">Successfully packaged chart and saved it to: &#x2F;home&#x2F;zj&#x2F;code&#x2F;helm-chart&#x2F;test-0.1.0.tgz</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm repo index --url https:&#x2F;&#x2F;yushanjin.github.io&#x2F;helm-chart&#x2F; .</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ cat index.yaml </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">entries:</span><br><span class=\"line\">  test:</span><br><span class=\"line\">  - apiVersion: v2</span><br><span class=\"line\">    appVersion: 1.16.0</span><br><span class=\"line\">    created: &quot;2020-04-08T14:19:31.079089336+08:00&quot;</span><br><span class=\"line\">    description: A Helm chart for Kubernetes</span><br><span class=\"line\">    digest: 6de7ab4f2da011db9ef8e1def8d2fca7d4e79bb4e81e46152a8d3a2969b73820</span><br><span class=\"line\">    name: test</span><br><span class=\"line\">    type: application</span><br><span class=\"line\">    urls:</span><br><span class=\"line\">    - https:&#x2F;&#x2F;yushanjin.github.io&#x2F;helm-chart&#x2F;test-0.1.0.tgz</span><br><span class=\"line\">    version: 0.1.0</span><br><span class=\"line\">generated: &quot;2020-04-08T14:19:31.078672885+08:00&quot;</span><br></pre></td></tr></table></figure>\n<h2 id=\"5、push到github\"><a href=\"#5、push到github\" class=\"headerlink\" title=\"5、push到github\"></a>5、push到github</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git status</span><br><span class=\"line\">位于分支 master</span><br><span class=\"line\">您的分支与上游分支 &#39;origin&#x2F;master&#39; 一致。</span><br><span class=\"line\"></span><br><span class=\"line\">未跟踪的文件:</span><br><span class=\"line\">  （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）</span><br><span class=\"line\"></span><br><span class=\"line\">\tindex.yaml</span><br><span class=\"line\">\ttest-0.1.0.tgz</span><br><span class=\"line\">\ttest&#x2F;</span><br><span class=\"line\"></span><br><span class=\"line\">提交为空，但是存在尚未跟踪的文件（使用 &quot;git add&quot; 建立跟踪）</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git add .</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git status</span><br><span class=\"line\">位于分支 master</span><br><span class=\"line\">您的分支与上游分支 &#39;origin&#x2F;master&#39; 一致。</span><br><span class=\"line\"></span><br><span class=\"line\">要提交的变更：</span><br><span class=\"line\">  （使用 &quot;git reset HEAD &lt;文件&gt;...&quot; 以取消暂存）</span><br><span class=\"line\"></span><br><span class=\"line\">\t新文件：   index.yaml</span><br><span class=\"line\">\t新文件：   test-0.1.0.tgz</span><br><span class=\"line\">\t新文件：   test&#x2F;.helmignore</span><br><span class=\"line\">\t新文件：   test&#x2F;Chart.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;NOTES.txt</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;_helpers.tpl</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;deployment.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;ingress.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;service.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;serviceaccount.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;templates&#x2F;tests&#x2F;test-connection.yaml</span><br><span class=\"line\">\t新文件：   test&#x2F;values.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git commit -m &quot;创建test的chart包&quot;</span><br><span class=\"line\">[master 5ae813c] 创建test的chart包</span><br><span class=\"line\"> 12 files changed, 348 insertions(+)</span><br><span class=\"line\"> create mode 100644 index.yaml</span><br><span class=\"line\"> create mode 100644 test-0.1.0.tgz</span><br><span class=\"line\"> create mode 100644 test&#x2F;.helmignore</span><br><span class=\"line\"> create mode 100644 test&#x2F;Chart.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;NOTES.txt</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;_helpers.tpl</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;deployment.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;ingress.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;service.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;serviceaccount.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;templates&#x2F;tests&#x2F;test-connection.yaml</span><br><span class=\"line\"> create mode 100644 test&#x2F;values.yaml</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ git push origin master</span><br><span class=\"line\">Username for &#39;https:&#x2F;&#x2F;github.com&#39;: yushanjin</span><br><span class=\"line\">Password for &#39;https:&#x2F;&#x2F;yushanjin@github.com&#39;: </span><br><span class=\"line\">对象计数中: 17, 完成.</span><br><span class=\"line\">Delta compression using up to 8 threads.</span><br><span class=\"line\">压缩对象中: 100% (16&#x2F;16), 完成.</span><br><span class=\"line\">写入对象中: 100% (17&#x2F;17), 8.32 KiB | 1.66 MiB&#x2F;s, 完成.</span><br><span class=\"line\">Total 17 (delta 0), reused 0 (delta 0)</span><br><span class=\"line\">To https:&#x2F;&#x2F;github.com&#x2F;yushanjin&#x2F;helm-chart.git</span><br><span class=\"line\">   48e2023..5ae813c  master -&gt; master</span><br></pre></td></tr></table></figure>\n<p>注意： 我这里本地没有创建其他分支，所以直接push到master分支了</p>\n<h2 id=\"6、设置github上helm-chart仓库的GitHub-Pages（在仓库的settings里设置）\"><a href=\"#6、设置github上helm-chart仓库的GitHub-Pages（在仓库的settings里设置）\" class=\"headerlink\" title=\"6、设置github上helm-chart仓库的GitHub Pages（在仓库的settings里设置）\"></a>6、设置github上helm-chart仓库的GitHub Pages（在仓库的settings里设置）</h2><p><img src=\"https://upload-images.jianshu.io/upload_images/10839544-fece4f06795a48d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"><br>登录：<a href=\"https://yushanjin.github.io/helm-chart%EF%BC%8C%E9%A1%B5%E9%9D%A2%E5%86%85%E5%AE%B9%E4%B8%BAREADME.md%E7%9A%84%E5%86%85%E5%AE%B9\">https://yushanjin.github.io/helm-chart，页面内容为README.md的内容</a><br><img src=\"https://upload-images.jianshu.io/upload_images/10839544-9f84217a461cce46.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p><strong>注意</strong>： 我修改过README.md文件</p>\n<h2 id=\"7、本地添加自己的chart仓库\"><a href=\"#7、本地添加自己的chart仓库\" class=\"headerlink\" title=\"7、本地添加自己的chart仓库\"></a>7、本地添加自己的chart仓库</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm repo list</span><br><span class=\"line\">Error: no repositories to show</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm repo add myrepo https:&#x2F;&#x2F;yushanjin.github.io&#x2F;helm-chart</span><br><span class=\"line\">&quot;myrepo&quot; has been added to your repositories</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm repo list</span><br><span class=\"line\">NAME  \tURL                                   </span><br><span class=\"line\">myrepo\thttps:&#x2F;&#x2F;yushanjin.github.io&#x2F;helm-chart</span><br><span class=\"line\">zj@zj-Z390-UD:~&#x2F;code&#x2F;helm-chart$ helm search repo test</span><br><span class=\"line\">NAME       \tCHART VERSION\tAPP VERSION\tDESCRIPTION                </span><br><span class=\"line\">myrepo&#x2F;test\t0.1.0        \t1.16.0     \tA Helm chart for Kubernetes</span><br></pre></td></tr></table></figure>\n\n<p>至此，就可以使用<strong>helm install xxx myrepo/test</strong> 安装test了</p>\n"},{"title":"如何配置kubernetes的pod从私有仓库拉取镜像","date":"2020-12-01T07:30:19.000Z","_content":"\n在实际使用中，用户往往搭建了自己的私有镜像仓库。kubernetes用户创建pod的过程中，如何从私有镜像仓库拉取容器镜像？\n\n本文重点要介绍：如何让使用secret从私有的 Docker 镜像仓库或代码仓库拉取镜像来创建 Pod\n\n\n# 前提条件：\n   1. kubernetes集群\n\n   2. docker私有镜像仓库或者docker hub上有Docker ID（这里使用Docker ID来演示）\n\n创建secret有两种方法：\n\n   1. 使用config.json文件\n\n   2. 直接使用用户名+密码\n\n# 生成config.json文件\n```\nroot@ubuntu:~# docker login\nLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\nUsername: shayu\nPassword:\nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n```\n根据提示，输入用户名及密码。\n\n用户名及密码会被存储到本地文件config.json中。\n\n```\nroot@ubuntu:~# cat /root/.docker/config.json\n{\n        \"auths\": {\n                \"https://index.docker.io/v1/\": {\n                        \"auth\": \"c2hheXU6MDI4Mxxxxxxx4=\"\n                }\n        },\n        \"HttpHeaders\": {\n                \"User-Agent\": \"Docker-Client/19.03.13 (linux)\"\n        }\n}\n\nroot@ubuntu:~# echo \"\"c2hheXU6MDI4Mxxxxxxx4=\" |base64 -d\nshayu:xxxxxxx\n```\n\n# 创建secret\n\n方法一：\n\n```\nroot@ubuntu:~# kubectl create secret generic regcred --from-file=.dockerconfigjson=.docker/config.json --type=kubernetes.io/dockerconfigjson\nsecret/regcred created\nroot@ubuntu:~#\nroot@ubuntu:~# kubectl get secret regcred -o yaml\napiVersion: v1\ndata:\n  .dockerconfigjson: ewoJImF1dGhzIjogewoJCSJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOiB7CgkWFkZXJzIjogewoJCSJVc2VyLUFnZW50IjogIkRvY2tlci1DbGllbnQvMTkuMDMuMTMgKGxpbnV4KSIKCX0KfQ==\nkind: Secret\nmetadata:\n  creationTimestamp: \"2020-12-01T07:09:19Z\"\n  managedFields:\n  - apiVersion: v1\n    fieldsType: FieldsV1\n    fieldsV1:\n      f:data:\n        .: {}\n        f:.dockerconfigjson: {}\n      f:type: {}\n    manager: kubectl-create\n    operation: Update\n    time: \"2020-12-01T07:09:19Z\"\n  name: regcred\n  namespace: default\n  resourceVersion: \"974703\"\n  selfLink: /api/v1/namespaces/default/secrets/regcred\n  uid: 96ed63a0-90d8-47e3-a1d9-aa841a9d1813\ntype: kubernetes.io/dockerconfigjson\n\nroot@ubuntu:~# kubectl get secret regcred --output=\"jsonpath={.data.\\.dockerconfigjson}\" | base64 --decode\n{\n        \"auths\": {\n                \"https://index.docker.io/v1/\": {\n                        \"auth\": \"c2hheXU6MDI4Mxxxxxxxxxx4=\"\n                }\n        },\n        \"HttpHeaders\": {\n                \"User-Agent\": \"Docker-Client/19.03.13 (linux)\"\n        }\n}\n```\n\n方法二：\n\n```\nroot@ubuntu:~# kubectl create secret docker-registry regcred1 --docker-username=shayu --docker-password=xxxxxx --docker-email=xxxxxxx@163.com\nsecret/regcred1 created\n\n其中:\nregcred1: 指定密钥的键名称, 可自行定义\n--docker-server: 指定docker仓库地址\n--docker-username: 指定docker仓库账号\n--docker-password: 指定docker仓库密码\n--docker-email: 指定邮件地址\n\nroot@ubuntu:~#kubectl get secret regcred1 -o yaml\napiVersion: v1\ndata:\n  .dockerconfigjson: eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pbxxxxxxxxxxxxxFpbCI6Inl1c2hhbmppbjA3NjdAMTYzLmNvbSIsImF1dGgiOiJjMmhoZVhVNk1ESTRNVEV3ZVhOcUxDND0ifX19\nkind: Secret\nmetadata:\n  creationTimestamp: \"2020-12-01T07:26:30Z\"\n  managedFields:\n  - apiVersion: v1\n    fieldsType: FieldsV1\n    fieldsV1:\n      f:data:\n        .: {}\n        f:.dockerconfigjson: {}\n      f:type: {}\n    manager: kubectl-create\n    operation: Update\n    time: \"2020-12-01T07:26:30Z\"\n  name: regcred1\n  namespace: default\n  resourceVersion: \"977436\"\n  selfLink: /api/v1/namespaces/default/secrets/regcred1\n  uid: b552c5ac-92eb-424e-bf4b-2a2c281cb75a\ntype: kubernetes.io/dockerconfigjson\n\nroot@ubuntu:~# kubectl get secret regcred1 --output=\"jsonpath={.data.\\.dockerconfigjson}\" | base64 --decode\n{\"auths\":{\"https://index.docker.io/v1/\":{\"username\":\"shayu\",\"password\":\"xxxxxxx\",\"email\":\"xxxxxxxx@163.com\",\"auth\":\"c2hheXU6MDI4xxxxxxxxx4=\"}}}\n\n```\n\n# pod指定imagePullSecrets为上述创建的secret\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: private-reg\nspec:\n  containers:\n  - name: private-reg-container\n    image: xxxxxxx:yyyy\n  imagePullSecrets:\n  - name: regcred\n```\n\n参考：\n\n(1) https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry\n\n(2) https://kubernetes.io/docs/concepts/containers/images/\n","source":"_posts/如何配置kubernetes的pod从私有仓库拉取镜像.md","raw":"---\ntitle: 如何配置kubernetes的pod从私有仓库拉取镜像\ndate: 2020-12-01 15:30:19\ntags:\n- docker\n- kubernetes\ncategories:\n- registry\n- docker\n- kubernetes\n---\n\n在实际使用中，用户往往搭建了自己的私有镜像仓库。kubernetes用户创建pod的过程中，如何从私有镜像仓库拉取容器镜像？\n\n本文重点要介绍：如何让使用secret从私有的 Docker 镜像仓库或代码仓库拉取镜像来创建 Pod\n\n\n# 前提条件：\n   1. kubernetes集群\n\n   2. docker私有镜像仓库或者docker hub上有Docker ID（这里使用Docker ID来演示）\n\n创建secret有两种方法：\n\n   1. 使用config.json文件\n\n   2. 直接使用用户名+密码\n\n# 生成config.json文件\n```\nroot@ubuntu:~# docker login\nLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\nUsername: shayu\nPassword:\nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n```\n根据提示，输入用户名及密码。\n\n用户名及密码会被存储到本地文件config.json中。\n\n```\nroot@ubuntu:~# cat /root/.docker/config.json\n{\n        \"auths\": {\n                \"https://index.docker.io/v1/\": {\n                        \"auth\": \"c2hheXU6MDI4Mxxxxxxx4=\"\n                }\n        },\n        \"HttpHeaders\": {\n                \"User-Agent\": \"Docker-Client/19.03.13 (linux)\"\n        }\n}\n\nroot@ubuntu:~# echo \"\"c2hheXU6MDI4Mxxxxxxx4=\" |base64 -d\nshayu:xxxxxxx\n```\n\n# 创建secret\n\n方法一：\n\n```\nroot@ubuntu:~# kubectl create secret generic regcred --from-file=.dockerconfigjson=.docker/config.json --type=kubernetes.io/dockerconfigjson\nsecret/regcred created\nroot@ubuntu:~#\nroot@ubuntu:~# kubectl get secret regcred -o yaml\napiVersion: v1\ndata:\n  .dockerconfigjson: ewoJImF1dGhzIjogewoJCSJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOiB7CgkWFkZXJzIjogewoJCSJVc2VyLUFnZW50IjogIkRvY2tlci1DbGllbnQvMTkuMDMuMTMgKGxpbnV4KSIKCX0KfQ==\nkind: Secret\nmetadata:\n  creationTimestamp: \"2020-12-01T07:09:19Z\"\n  managedFields:\n  - apiVersion: v1\n    fieldsType: FieldsV1\n    fieldsV1:\n      f:data:\n        .: {}\n        f:.dockerconfigjson: {}\n      f:type: {}\n    manager: kubectl-create\n    operation: Update\n    time: \"2020-12-01T07:09:19Z\"\n  name: regcred\n  namespace: default\n  resourceVersion: \"974703\"\n  selfLink: /api/v1/namespaces/default/secrets/regcred\n  uid: 96ed63a0-90d8-47e3-a1d9-aa841a9d1813\ntype: kubernetes.io/dockerconfigjson\n\nroot@ubuntu:~# kubectl get secret regcred --output=\"jsonpath={.data.\\.dockerconfigjson}\" | base64 --decode\n{\n        \"auths\": {\n                \"https://index.docker.io/v1/\": {\n                        \"auth\": \"c2hheXU6MDI4Mxxxxxxxxxx4=\"\n                }\n        },\n        \"HttpHeaders\": {\n                \"User-Agent\": \"Docker-Client/19.03.13 (linux)\"\n        }\n}\n```\n\n方法二：\n\n```\nroot@ubuntu:~# kubectl create secret docker-registry regcred1 --docker-username=shayu --docker-password=xxxxxx --docker-email=xxxxxxx@163.com\nsecret/regcred1 created\n\n其中:\nregcred1: 指定密钥的键名称, 可自行定义\n--docker-server: 指定docker仓库地址\n--docker-username: 指定docker仓库账号\n--docker-password: 指定docker仓库密码\n--docker-email: 指定邮件地址\n\nroot@ubuntu:~#kubectl get secret regcred1 -o yaml\napiVersion: v1\ndata:\n  .dockerconfigjson: eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pbxxxxxxxxxxxxxFpbCI6Inl1c2hhbmppbjA3NjdAMTYzLmNvbSIsImF1dGgiOiJjMmhoZVhVNk1ESTRNVEV3ZVhOcUxDND0ifX19\nkind: Secret\nmetadata:\n  creationTimestamp: \"2020-12-01T07:26:30Z\"\n  managedFields:\n  - apiVersion: v1\n    fieldsType: FieldsV1\n    fieldsV1:\n      f:data:\n        .: {}\n        f:.dockerconfigjson: {}\n      f:type: {}\n    manager: kubectl-create\n    operation: Update\n    time: \"2020-12-01T07:26:30Z\"\n  name: regcred1\n  namespace: default\n  resourceVersion: \"977436\"\n  selfLink: /api/v1/namespaces/default/secrets/regcred1\n  uid: b552c5ac-92eb-424e-bf4b-2a2c281cb75a\ntype: kubernetes.io/dockerconfigjson\n\nroot@ubuntu:~# kubectl get secret regcred1 --output=\"jsonpath={.data.\\.dockerconfigjson}\" | base64 --decode\n{\"auths\":{\"https://index.docker.io/v1/\":{\"username\":\"shayu\",\"password\":\"xxxxxxx\",\"email\":\"xxxxxxxx@163.com\",\"auth\":\"c2hheXU6MDI4xxxxxxxxx4=\"}}}\n\n```\n\n# pod指定imagePullSecrets为上述创建的secret\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: private-reg\nspec:\n  containers:\n  - name: private-reg-container\n    image: xxxxxxx:yyyy\n  imagePullSecrets:\n  - name: regcred\n```\n\n参考：\n\n(1) https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry\n\n(2) https://kubernetes.io/docs/concepts/containers/images/\n","slug":"如何配置kubernetes的pod从私有仓库拉取镜像","published":1,"updated":"2020-12-01T08:17:58.431Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cki73ih1b000dh0l77vh59mmk","content":"<p>在实际使用中，用户往往搭建了自己的私有镜像仓库。kubernetes用户创建pod的过程中，如何从私有镜像仓库拉取容器镜像？</p>\n<p>本文重点要介绍：如何让使用secret从私有的 Docker 镜像仓库或代码仓库拉取镜像来创建 Pod</p>\n<h1 id=\"前提条件：\"><a href=\"#前提条件：\" class=\"headerlink\" title=\"前提条件：\"></a>前提条件：</h1><ol>\n<li><p>kubernetes集群</p>\n</li>\n<li><p>docker私有镜像仓库或者docker hub上有Docker ID（这里使用Docker ID来演示）</p>\n</li>\n</ol>\n<p>创建secret有两种方法：</p>\n<ol>\n<li><p>使用config.json文件</p>\n</li>\n<li><p>直接使用用户名+密码</p>\n</li>\n</ol>\n<h1 id=\"生成config-json文件\"><a href=\"#生成config-json文件\" class=\"headerlink\" title=\"生成config.json文件\"></a>生成config.json文件</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# docker login</span><br><span class=\"line\">Login with your Docker ID to push and pull images from Docker Hub. If you don&#39;t have a Docker ID, head over to https:&#x2F;&#x2F;hub.docker.com to create one.</span><br><span class=\"line\">Username: shayu</span><br><span class=\"line\">Password:</span><br><span class=\"line\">WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.</span><br><span class=\"line\">Configure a credential helper to remove this warning. See</span><br><span class=\"line\">https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;reference&#x2F;commandline&#x2F;login&#x2F;#credentials-store</span><br><span class=\"line\"></span><br><span class=\"line\">Login Succeeded</span><br></pre></td></tr></table></figure>\n<p>根据提示，输入用户名及密码。</p>\n<p>用户名及密码会被存储到本地文件config.json中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# cat &#x2F;root&#x2F;.docker&#x2F;config.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        &quot;auths&quot;: &#123;</span><br><span class=\"line\">                &quot;https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;&quot;: &#123;</span><br><span class=\"line\">                        &quot;auth&quot;: &quot;c2hheXU6MDI4Mxxxxxxx4&#x3D;&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;HttpHeaders&quot;: &#123;</span><br><span class=\"line\">                &quot;User-Agent&quot;: &quot;Docker-Client&#x2F;19.03.13 (linux)&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# echo &quot;&quot;c2hheXU6MDI4Mxxxxxxx4&#x3D;&quot; |base64 -d</span><br><span class=\"line\">shayu:xxxxxxx</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"创建secret\"><a href=\"#创建secret\" class=\"headerlink\" title=\"创建secret\"></a>创建secret</h1><p>方法一：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl create secret generic regcred --from-file&#x3D;.dockerconfigjson&#x3D;.docker&#x2F;config.json --type&#x3D;kubernetes.io&#x2F;dockerconfigjson</span><br><span class=\"line\">secret&#x2F;regcred created</span><br><span class=\"line\">root@ubuntu:~#</span><br><span class=\"line\">root@ubuntu:~# kubectl get secret regcred -o yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">data:</span><br><span class=\"line\">  .dockerconfigjson: ewoJImF1dGhzIjogewoJCSJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOiB7CgkWFkZXJzIjogewoJCSJVc2VyLUFnZW50IjogIkRvY2tlci1DbGllbnQvMTkuMDMuMTMgKGxpbnV4KSIKCX0KfQ&#x3D;&#x3D;</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2020-12-01T07:09:19Z&quot;</span><br><span class=\"line\">  managedFields:</span><br><span class=\"line\">  - apiVersion: v1</span><br><span class=\"line\">    fieldsType: FieldsV1</span><br><span class=\"line\">    fieldsV1:</span><br><span class=\"line\">      f:data:</span><br><span class=\"line\">        .: &#123;&#125;</span><br><span class=\"line\">        f:.dockerconfigjson: &#123;&#125;</span><br><span class=\"line\">      f:type: &#123;&#125;</span><br><span class=\"line\">    manager: kubectl-create</span><br><span class=\"line\">    operation: Update</span><br><span class=\"line\">    time: &quot;2020-12-01T07:09:19Z&quot;</span><br><span class=\"line\">  name: regcred</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;974703&quot;</span><br><span class=\"line\">  selfLink: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;secrets&#x2F;regcred</span><br><span class=\"line\">  uid: 96ed63a0-90d8-47e3-a1d9-aa841a9d1813</span><br><span class=\"line\">type: kubernetes.io&#x2F;dockerconfigjson</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get secret regcred --output&#x3D;&quot;jsonpath&#x3D;&#123;.data.\\.dockerconfigjson&#125;&quot; | base64 --decode</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        &quot;auths&quot;: &#123;</span><br><span class=\"line\">                &quot;https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;&quot;: &#123;</span><br><span class=\"line\">                        &quot;auth&quot;: &quot;c2hheXU6MDI4Mxxxxxxxxxx4&#x3D;&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;HttpHeaders&quot;: &#123;</span><br><span class=\"line\">                &quot;User-Agent&quot;: &quot;Docker-Client&#x2F;19.03.13 (linux)&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>方法二：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl create secret docker-registry regcred1 --docker-username&#x3D;shayu --docker-password&#x3D;xxxxxx --docker-email&#x3D;xxxxxxx@163.com</span><br><span class=\"line\">secret&#x2F;regcred1 created</span><br><span class=\"line\"></span><br><span class=\"line\">其中:</span><br><span class=\"line\">regcred1: 指定密钥的键名称, 可自行定义</span><br><span class=\"line\">--docker-server: 指定docker仓库地址</span><br><span class=\"line\">--docker-username: 指定docker仓库账号</span><br><span class=\"line\">--docker-password: 指定docker仓库密码</span><br><span class=\"line\">--docker-email: 指定邮件地址</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~#kubectl get secret regcred1 -o yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">data:</span><br><span class=\"line\">  .dockerconfigjson: eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pbxxxxxxxxxxxxxFpbCI6Inl1c2hhbmppbjA3NjdAMTYzLmNvbSIsImF1dGgiOiJjMmhoZVhVNk1ESTRNVEV3ZVhOcUxDND0ifX19</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2020-12-01T07:26:30Z&quot;</span><br><span class=\"line\">  managedFields:</span><br><span class=\"line\">  - apiVersion: v1</span><br><span class=\"line\">    fieldsType: FieldsV1</span><br><span class=\"line\">    fieldsV1:</span><br><span class=\"line\">      f:data:</span><br><span class=\"line\">        .: &#123;&#125;</span><br><span class=\"line\">        f:.dockerconfigjson: &#123;&#125;</span><br><span class=\"line\">      f:type: &#123;&#125;</span><br><span class=\"line\">    manager: kubectl-create</span><br><span class=\"line\">    operation: Update</span><br><span class=\"line\">    time: &quot;2020-12-01T07:26:30Z&quot;</span><br><span class=\"line\">  name: regcred1</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;977436&quot;</span><br><span class=\"line\">  selfLink: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;secrets&#x2F;regcred1</span><br><span class=\"line\">  uid: b552c5ac-92eb-424e-bf4b-2a2c281cb75a</span><br><span class=\"line\">type: kubernetes.io&#x2F;dockerconfigjson</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get secret regcred1 --output&#x3D;&quot;jsonpath&#x3D;&#123;.data.\\.dockerconfigjson&#125;&quot; | base64 --decode</span><br><span class=\"line\">&#123;&quot;auths&quot;:&#123;&quot;https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;&quot;:&#123;&quot;username&quot;:&quot;shayu&quot;,&quot;password&quot;:&quot;xxxxxxx&quot;,&quot;email&quot;:&quot;xxxxxxxx@163.com&quot;,&quot;auth&quot;:&quot;c2hheXU6MDI4xxxxxxxxx4&#x3D;&quot;&#125;&#125;&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"pod指定imagePullSecrets为上述创建的secret\"><a href=\"#pod指定imagePullSecrets为上述创建的secret\" class=\"headerlink\" title=\"pod指定imagePullSecrets为上述创建的secret\"></a>pod指定imagePullSecrets为上述创建的secret</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: private-reg</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - name: private-reg-container</span><br><span class=\"line\">    image: xxxxxxx:yyyy</span><br><span class=\"line\">  imagePullSecrets:</span><br><span class=\"line\">  - name: regcred</span><br></pre></td></tr></table></figure>\n\n<p>参考：</p>\n<p>(1) <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry\">https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry</a></p>\n<p>(2) <a href=\"https://kubernetes.io/docs/concepts/containers/images/\">https://kubernetes.io/docs/concepts/containers/images/</a></p>\n","site":{"data":{}},"excerpt":"在实际使用中，用户往往搭建了自己的私有镜像仓库。kubernetes用户创建pod的过程中，如何从私有镜像仓库拉取容器镜像？\n\n本文重点要介绍：如何让使用secret从私有的 Docker 镜像仓库或代码仓库拉取镜像来创建 Pod\n\n前提条件：\n 1. kubernetes集群\n    \n    \n 2. docker私有镜像仓库或者docker hub上有Docker ID（这里使用Docker ID来演示）\n    \n    \n\n创建secret有两种方法：\n\n 1. 使用config.json文件\n    \n    \n 2. 直接使用用户名+密码\n    \n    \n\n生成config.","more":"<p>在实际使用中，用户往往搭建了自己的私有镜像仓库。kubernetes用户创建pod的过程中，如何从私有镜像仓库拉取容器镜像？</p>\n<p>本文重点要介绍：如何让使用secret从私有的 Docker 镜像仓库或代码仓库拉取镜像来创建 Pod</p>\n<h1 id=\"前提条件：\"><a href=\"#前提条件：\" class=\"headerlink\" title=\"前提条件：\"></a>前提条件：</h1><ol>\n<li><p>kubernetes集群</p>\n</li>\n<li><p>docker私有镜像仓库或者docker hub上有Docker ID（这里使用Docker ID来演示）</p>\n</li>\n</ol>\n<p>创建secret有两种方法：</p>\n<ol>\n<li><p>使用config.json文件</p>\n</li>\n<li><p>直接使用用户名+密码</p>\n</li>\n</ol>\n<h1 id=\"生成config-json文件\"><a href=\"#生成config-json文件\" class=\"headerlink\" title=\"生成config.json文件\"></a>生成config.json文件</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# docker login</span><br><span class=\"line\">Login with your Docker ID to push and pull images from Docker Hub. If you don&#39;t have a Docker ID, head over to https:&#x2F;&#x2F;hub.docker.com to create one.</span><br><span class=\"line\">Username: shayu</span><br><span class=\"line\">Password:</span><br><span class=\"line\">WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.</span><br><span class=\"line\">Configure a credential helper to remove this warning. See</span><br><span class=\"line\">https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;reference&#x2F;commandline&#x2F;login&#x2F;#credentials-store</span><br><span class=\"line\"></span><br><span class=\"line\">Login Succeeded</span><br></pre></td></tr></table></figure>\n<p>根据提示，输入用户名及密码。</p>\n<p>用户名及密码会被存储到本地文件config.json中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# cat &#x2F;root&#x2F;.docker&#x2F;config.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        &quot;auths&quot;: &#123;</span><br><span class=\"line\">                &quot;https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;&quot;: &#123;</span><br><span class=\"line\">                        &quot;auth&quot;: &quot;c2hheXU6MDI4Mxxxxxxx4&#x3D;&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;HttpHeaders&quot;: &#123;</span><br><span class=\"line\">                &quot;User-Agent&quot;: &quot;Docker-Client&#x2F;19.03.13 (linux)&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# echo &quot;&quot;c2hheXU6MDI4Mxxxxxxx4&#x3D;&quot; |base64 -d</span><br><span class=\"line\">shayu:xxxxxxx</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"创建secret\"><a href=\"#创建secret\" class=\"headerlink\" title=\"创建secret\"></a>创建secret</h1><p>方法一：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl create secret generic regcred --from-file&#x3D;.dockerconfigjson&#x3D;.docker&#x2F;config.json --type&#x3D;kubernetes.io&#x2F;dockerconfigjson</span><br><span class=\"line\">secret&#x2F;regcred created</span><br><span class=\"line\">root@ubuntu:~#</span><br><span class=\"line\">root@ubuntu:~# kubectl get secret regcred -o yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">data:</span><br><span class=\"line\">  .dockerconfigjson: ewoJImF1dGhzIjogewoJCSJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOiB7CgkWFkZXJzIjogewoJCSJVc2VyLUFnZW50IjogIkRvY2tlci1DbGllbnQvMTkuMDMuMTMgKGxpbnV4KSIKCX0KfQ&#x3D;&#x3D;</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2020-12-01T07:09:19Z&quot;</span><br><span class=\"line\">  managedFields:</span><br><span class=\"line\">  - apiVersion: v1</span><br><span class=\"line\">    fieldsType: FieldsV1</span><br><span class=\"line\">    fieldsV1:</span><br><span class=\"line\">      f:data:</span><br><span class=\"line\">        .: &#123;&#125;</span><br><span class=\"line\">        f:.dockerconfigjson: &#123;&#125;</span><br><span class=\"line\">      f:type: &#123;&#125;</span><br><span class=\"line\">    manager: kubectl-create</span><br><span class=\"line\">    operation: Update</span><br><span class=\"line\">    time: &quot;2020-12-01T07:09:19Z&quot;</span><br><span class=\"line\">  name: regcred</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;974703&quot;</span><br><span class=\"line\">  selfLink: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;secrets&#x2F;regcred</span><br><span class=\"line\">  uid: 96ed63a0-90d8-47e3-a1d9-aa841a9d1813</span><br><span class=\"line\">type: kubernetes.io&#x2F;dockerconfigjson</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get secret regcred --output&#x3D;&quot;jsonpath&#x3D;&#123;.data.\\.dockerconfigjson&#125;&quot; | base64 --decode</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        &quot;auths&quot;: &#123;</span><br><span class=\"line\">                &quot;https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;&quot;: &#123;</span><br><span class=\"line\">                        &quot;auth&quot;: &quot;c2hheXU6MDI4Mxxxxxxxxxx4&#x3D;&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;HttpHeaders&quot;: &#123;</span><br><span class=\"line\">                &quot;User-Agent&quot;: &quot;Docker-Client&#x2F;19.03.13 (linux)&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>方法二：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl create secret docker-registry regcred1 --docker-username&#x3D;shayu --docker-password&#x3D;xxxxxx --docker-email&#x3D;xxxxxxx@163.com</span><br><span class=\"line\">secret&#x2F;regcred1 created</span><br><span class=\"line\"></span><br><span class=\"line\">其中:</span><br><span class=\"line\">regcred1: 指定密钥的键名称, 可自行定义</span><br><span class=\"line\">--docker-server: 指定docker仓库地址</span><br><span class=\"line\">--docker-username: 指定docker仓库账号</span><br><span class=\"line\">--docker-password: 指定docker仓库密码</span><br><span class=\"line\">--docker-email: 指定邮件地址</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~#kubectl get secret regcred1 -o yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">data:</span><br><span class=\"line\">  .dockerconfigjson: eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pbxxxxxxxxxxxxxFpbCI6Inl1c2hhbmppbjA3NjdAMTYzLmNvbSIsImF1dGgiOiJjMmhoZVhVNk1ESTRNVEV3ZVhOcUxDND0ifX19</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2020-12-01T07:26:30Z&quot;</span><br><span class=\"line\">  managedFields:</span><br><span class=\"line\">  - apiVersion: v1</span><br><span class=\"line\">    fieldsType: FieldsV1</span><br><span class=\"line\">    fieldsV1:</span><br><span class=\"line\">      f:data:</span><br><span class=\"line\">        .: &#123;&#125;</span><br><span class=\"line\">        f:.dockerconfigjson: &#123;&#125;</span><br><span class=\"line\">      f:type: &#123;&#125;</span><br><span class=\"line\">    manager: kubectl-create</span><br><span class=\"line\">    operation: Update</span><br><span class=\"line\">    time: &quot;2020-12-01T07:26:30Z&quot;</span><br><span class=\"line\">  name: regcred1</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;977436&quot;</span><br><span class=\"line\">  selfLink: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;secrets&#x2F;regcred1</span><br><span class=\"line\">  uid: b552c5ac-92eb-424e-bf4b-2a2c281cb75a</span><br><span class=\"line\">type: kubernetes.io&#x2F;dockerconfigjson</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get secret regcred1 --output&#x3D;&quot;jsonpath&#x3D;&#123;.data.\\.dockerconfigjson&#125;&quot; | base64 --decode</span><br><span class=\"line\">&#123;&quot;auths&quot;:&#123;&quot;https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;&quot;:&#123;&quot;username&quot;:&quot;shayu&quot;,&quot;password&quot;:&quot;xxxxxxx&quot;,&quot;email&quot;:&quot;xxxxxxxx@163.com&quot;,&quot;auth&quot;:&quot;c2hheXU6MDI4xxxxxxxxx4&#x3D;&quot;&#125;&#125;&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"pod指定imagePullSecrets为上述创建的secret\"><a href=\"#pod指定imagePullSecrets为上述创建的secret\" class=\"headerlink\" title=\"pod指定imagePullSecrets为上述创建的secret\"></a>pod指定imagePullSecrets为上述创建的secret</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: private-reg</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - name: private-reg-container</span><br><span class=\"line\">    image: xxxxxxx:yyyy</span><br><span class=\"line\">  imagePullSecrets:</span><br><span class=\"line\">  - name: regcred</span><br></pre></td></tr></table></figure>\n\n<p>参考：</p>\n<p>(1) <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry\">https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry</a></p>\n<p>(2) <a href=\"https://kubernetes.io/docs/concepts/containers/images/\">https://kubernetes.io/docs/concepts/containers/images/</a></p>\n"},{"title":"kind快速部署Kubernetes环境","date":"2020-11-26T08:56:12.000Z","_content":"\n# 什么是kind\n\nkind：Kubernetes In Docker，顾名思义，就是将kubernetes所需要的所有组件，全部部署在一个docker容器中，是一套开箱即用的kubernetes环境搭建方案。使用kind搭建的集群无法在生产中使用，但是如果你只是想在本地测试或者开发使用，不想占用太多的资源，那么使用kind是不错的选择。同样，kind还可以很方便的帮你本地的kubernetes源代码打成对应的镜像，方便测试。\n\nGitHub: https://github.com/kubernetes-sigs/kind\n\nDocumentation: https://kind.sigs.k8s.io/\n\n# 安装kind\n\n以Linux下安装为例：\n\n```\ncurl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.9.0/kind-linux-amd64\nchmod +x ./kind\nmv ./kind /usr/local/bin/kind\n```\n\n# 创建、查询集群\n\n```\nkind create cluster\n```\n该命令将默认创建名为kind的集群\n\n```\nroot@ubuntu:~# kind create cluster\nCreating cluster \"kind\" ...\n ✓ Ensuring node image (kindest/node:v1.19.1) 🖼\n ✓ Preparing nodes 📦\n ✓ Writing configuration 📜\n ✓ Starting control-plane 🕹️\n ✓ Installing CNI 🔌\n ✓ Installing StorageClass 💾\nSet kubectl context to \"kind-kind\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-kind\n\nHave a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂\n\nroot@ubuntu:~# kind get clusters\nkind\n```\n\n```\nkind create cluster --name test\n```\n该命令将创建名为test的集群\n\n```\nroot@ubuntu:~# kind create cluster --name test\nCreating cluster \"test\" ...\n ✓ Ensuring node image (kindest/node:v1.19.1) 🖼\n ✓ Preparing nodes 📦\n ✓ Writing configuration 📜\n ✓ Starting control-plane 🕹️\n ✓ Installing CNI 🔌\n ✓ Installing StorageClass 💾\nSet kubectl context to \"kind-test\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-test\n\nThanks for using kind! 😊\n\nroot@ubuntu:~# kind get clusters\nkind\ntest\n\nroot@ubuntu:~# kubectl cluster-info --context kind-test\nKubernetes master is running at https://127.0.0.1:44543\nKubeDNS is running at https://127.0.0.1:44543/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n```\n\nkubectl安装：https://kubernetes.io/docs/tasks/tools/install-kubectl/\n\n\n查询集群节点\n```\nroot@ubuntu:~# kubectl get nodes --context kind-test\nNAME                 STATUS   ROLES    AGE     VERSION\ntest-control-plane   Ready    master   4m55s   v1.19.1\n\nroot@ubuntu:~# kubectl get nodes --context kind-kind\nNAME                 STATUS   ROLES    AGE     VERSION\nkind-control-plane   Ready    master   9m14s   v1.19.1\n```\n\n```\nroot@ubuntu:~# docker ps\nCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES\n7fa7f8313453        kindest/node:v1.19.1   \"/usr/local/bin/entr…\"   16 minutes ago      Up 16 minutes       127.0.0.1:44543->6443/tcp   test-control-plane\n6fee527273e2        kindest/node:v1.19.1   \"/usr/local/bin/entr…\"   20 minutes ago      Up 20 minutes       127.0.0.1:36585->6443/tcp   kind-control-plane\nroot@ubuntu:~# docker ps -a\nCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES\n7fa7f8313453        kindest/node:v1.19.1   \"/usr/local/bin/entr…\"   16 minutes ago      Up 16 minutes       127.0.0.1:44543->6443/tcp   test-control-plane\n6fee527273e2        kindest/node:v1.19.1   \"/usr/local/bin/entr…\"   20 minutes ago      Up 20 minutes       127.0.0.1:36585->6443/tcp   kind-control-plane\n```\ntest-control-plane、kind-control-plane是运行在容器内的kubernetes节点，也正是kubernetes in Docker的意思\n\n查询集群内运行的pod\n```\nroot@ubuntu:~# kubectl get pods --all-namespaces --context kind-kind\nNAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE\nkube-system          coredns-f9fd979d6-cqpss                      1/1     Running   0          22m\nkube-system          coredns-f9fd979d6-kvbzm                      1/1     Running   0          22m\nkube-system          etcd-kind-control-plane                      1/1     Running   0          22m\nkube-system          kindnet-br2qc                                1/1     Running   0          22m\nkube-system          kube-apiserver-kind-control-plane            1/1     Running   0          22m\nkube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          22m\nkube-system          kube-proxy-4chlm                             1/1     Running   0          22m\nkube-system          kube-scheduler-kind-control-plane            1/1     Running   0          22m\nlocal-path-storage   local-path-provisioner-78776bfc44-xl4ht      1/1     Running   0          22m\n\nroot@ubuntu:~# kubectl get pods --all-namespaces --context kind-test\nNAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE\nkube-system          coredns-f9fd979d6-f7wsz                      1/1     Running   0          18m\nkube-system          coredns-f9fd979d6-j9xtx                      1/1     Running   0          18m\nkube-system          etcd-test-control-plane                      1/1     Running   0          18m\nkube-system          kindnet-jq867                                1/1     Running   0          18m\nkube-system          kube-apiserver-test-control-plane            1/1     Running   0          18m\nkube-system          kube-controller-manager-test-control-plane   1/1     Running   0          18m\nkube-system          kube-proxy-swn5j                             1/1     Running   0          18m\nkube-system          kube-scheduler-test-control-plane            1/1     Running   0          18m\nlocal-path-storage   local-path-provisioner-78776bfc44-nwqjq      1/1     Running   0          18m\n```\n\n查询pod使用的镜像\n```\nroot@ubuntu:~# docker exec -it kind-control-plane crictl images\nIMAGE                                      TAG                  IMAGE ID            SIZE\ndocker.io/kindest/kindnetd                 v20200725-4d6bea59   b77790820d015       119MB\ndocker.io/rancher/local-path-provisioner   v0.0.14              e422121c9c5f9       42MB\nk8s.gcr.io/build-image/debian-base         v2.1.0               c7c6c86897b63       53.9MB\nk8s.gcr.io/coredns                         1.7.0                bfe3a36ebd252       45.4MB\nk8s.gcr.io/etcd                            3.4.13-0             0369cf4303ffd       255MB\nk8s.gcr.io/kube-apiserver                  v1.19.1              8cba89a89aaa8       95MB\nk8s.gcr.io/kube-controller-manager         v1.19.1              7dafbafe72c90       84.1MB\nk8s.gcr.io/kube-proxy                      v1.19.1              47e289e332426       136MB\nk8s.gcr.io/kube-scheduler                  v1.19.1              4d648fc900179       65.1MB\nk8s.gcr.io/pause                           3.3                  0184c1613d929       686kB\nroot@ubuntu:~# docker exec -it kind-control-plane crictl ps\nCONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID\n1c881f7f0d306       bfe3a36ebd252       25 minutes ago      Running             coredns                   0                   75e161b37ab2d\nc64dd6bb666f3       bfe3a36ebd252       25 minutes ago      Running             coredns                   0                   a8305dc572af5\nfea2b69f5472d       e422121c9c5f9       26 minutes ago      Running             local-path-provisioner    0                   fb704b6340b63\n52f0995ba00f8       47e289e332426       26 minutes ago      Running             kube-proxy                0                   4c787e616d5a7\nb87cdcc514f59       b77790820d015       26 minutes ago      Running             kindnet-cni               0                   14eb70f9ca549\nce2c4e5b2b57f       0369cf4303ffd       27 minutes ago      Running             etcd                      0                   744a99a558714\n93b5084a29992       8cba89a89aaa8       27 minutes ago      Running             kube-apiserver            0                   91f88afc5a39b\n8b9579313058f       7dafbafe72c90       27 minutes ago      Running             kube-controller-manager   0                   8d54fdffef86e\n10fbb8244ad3b       4d648fc900179       27 minutes ago      Running             kube-scheduler            0                   a985ae4a105bc\n```\n其中，crictl命令可以理解为docker命令\n\n\n# 删除集群\n\n```\nkind delete cluster --name test\n```\n删除名为test的集群，--name未指定的话，将默认删除kind集群\n\n\n# 创建高可用kubernetes集群\n```\nroot@ubuntu:~# cat kind-config.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n- role: control-plane\n- role: control-plane\n- role: worker\n- role: worker\n- role: worker\n\nroot@ubuntu:~# kind create cluster --config kind-config.yaml --name test2\nCreating cluster \"test2\" ...\n ✓ Ensuring node image (kindest/node:v1.19.1) 🖼\n ✓ Preparing nodes 📦 📦 📦 📦 📦 📦\n ✓ Configuring the external load balancer ⚖️\n ✓ Writing configuration 📜\n ✓ Starting control-plane 🕹️\n ✓ Installing CNI 🔌\n ✓ Installing StorageClass 💾\n ✓ Joining more control-plane nodes 🎮\n ✓ Joining worker nodes 🚜\nSet kubectl context to \"kind-test2\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-test2\n\nHave a nice day! 👋\n\nroot@ubuntu:~# kubectl get nodes --context kind-test2\nNAME                   STATUS   ROLES    AGE     VERSION\ntest2-control-plane    Ready    master   5m12s   v1.19.1\ntest2-control-plane2   Ready    master   4m38s   v1.19.1\ntest2-control-plane3   Ready    master   3m22s   v1.19.1\ntest2-worker           Ready    <none>   2m5s    v1.19.1\ntest2-worker2          Ready    <none>   2m5s    v1.19.1\ntest2-worker3          Ready    <none>   2m5s    v1.19.1\n\nroot@ubuntu:~# kubectl get pods --all-namespaces --context kind-test2\nNAMESPACE            NAME                                           READY   STATUS    RESTARTS   AGE\nkube-system          coredns-f9fd979d6-jbpcz                        1/1     Running   0          5m16s\nkube-system          coredns-f9fd979d6-ng4qp                        1/1     Running   0          5m16s\nkube-system          etcd-test2-control-plane                       1/1     Running   0          5m15s\nkube-system          etcd-test2-control-plane2                      1/1     Running   0          4m54s\nkube-system          etcd-test2-control-plane3                      1/1     Running   0          2m59s\nkube-system          kindnet-gxpjn                                  1/1     Running   0          4m55s\nkube-system          kindnet-jqnx5                                  1/1     Running   0          2m20s\nkube-system          kindnet-lczmx                                  1/1     Running   0          2m18s\nkube-system          kindnet-q8bcn                                  1/1     Running   0          2m19s\nkube-system          kindnet-q9ng2                                  1/1     Running   0          3m37s\nkube-system          kindnet-s7kfb                                  1/1     Running   0          5m14s\nkube-system          kube-apiserver-test2-control-plane             1/1     Running   0          5m15s\nkube-system          kube-apiserver-test2-control-plane2            1/1     Running   0          4m54s\nkube-system          kube-apiserver-test2-control-plane3            1/1     Running   1          3m9s\nkube-system          kube-controller-manager-test2-control-plane    1/1     Running   2          5m14s\nkube-system          kube-controller-manager-test2-control-plane2   1/1     Running   0          4m54s\nkube-system          kube-controller-manager-test2-control-plane3   1/1     Running   0          2m8s\nkube-system          kube-proxy-47nc7                               1/1     Running   0          5m16s\nkube-system          kube-proxy-5799m                               1/1     Running   0          4m55s\nkube-system          kube-proxy-cvm49                               1/1     Running   0          2m18s\nkube-system          kube-proxy-s7rsp                               1/1     Running   0          2m18s\nkube-system          kube-proxy-sxwgl                               1/1     Running   0          3m37s\nkube-system          kube-proxy-wvskh                               1/1     Running   0          2m20s\nkube-system          kube-scheduler-test2-control-plane             0/1     Running   2          5m15s\nkube-system          kube-scheduler-test2-control-plane2            1/1     Running   0          4m54s\nkube-system          kube-scheduler-test2-control-plane3            1/1     Running   0          2m31s\nlocal-path-storage   local-path-provisioner-78776bfc44-fkdwq        1/1     Running   1          5m12s\n```\n\n上述过程，我们创建了两个kubernetes集群，kind和test2；可以看到我们在使用kubectl访问集群时，增加了参数：--context，这在本地的配置文件里指定了\n```\nroot@ubuntu:~# cat .kube/config\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01URXlOekF3TkRJeU9Wb1hEVE13TVRFeU5UQXdOREl5T1Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTERTCm5TU1NHS05PUUlCVWpQeXpYOFRDZm5IamExV2JxeXZJeHV3Y1Aybmh6Zi9EdG9wVDRnSTVjMlBMV3Qrd05BUFUKUHA2dGV3ZkhNQ3N6MnJLbnhaRmtWS2c5NXVFdW53V1ZuZnlmeGV0TjlOU1JTZ2s2dkJuVUt6SFliRXIybEY0LwpicFVxT2IzWnkxQXdYNlpyRTN3Y1I1RjdLV2trT0FZbHdobUtiLzIwOVZJRG4yMW9CMHMzNXgrM3Z2L2gzQ3VaCkJCQjJnNVBKMm4xc1pwd05scnZDMmh0RmJDSjQwQVNXZmNsUksyejBYUEIvdzdNQlBXMHp1cnpEMUVBcGdZVUcKUGUwOEx3dW1zMllZR3Y5TDJXMERhWW90c2JoVXlWZWRDNnpjeWtUZ0hOb1B6LytvZlBHQmxYTko3S2lwd2Z6ZQo2dzdHZGJhbjlpRms4cjAyaVQ4Q0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZEY2liT2RWZTN4U0w0RmMxOWVJdmZnSTBHcjZNQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFCS1lKSVFaenhSblFWWWp4TnlTaXJualFvZUM3OGtDMERNYjZpRFBvMFdEbmdTUjhRYgpqRjZxR2ZPMTFTcDNjeVl3V1IrM3UzU2pzQUJUUG5jcWZpWnEyN3VDMlRYNjdMQzRPNVFoVkdlRlBDdXJNNHluCi8weDZuOUZrMko5YmpTT0o1aDB2NmQ1eXBibk5sNVgvN1czWFVyK2tjOSswWG1sMFN0dmJVZ0hCaWVmWGxtZ3AKUXl5TlFtNU1yWlRFcWJOT0JubW1RWUJYWDdydWVLZXhVYUJ4QXQrRVJVWHBVOWNhbkNWWWhuZFBuMVNBYVladApsQkZyamRSNzg1SE1EV21qTW5UalJXSUhOSWd2NUgwKyt2MmN5cjRSK1lUWGo3S0JrdEZTRDA2U0I0RDZVeFk2CmRUZ25UMngzRXJvSERPZURjWWRrVmt2TkF5aC9JUGFTd2R6cwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    server: https://127.0.0.1:36585\n  name: kind-kind\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01URXlOekF6TWpJeE9Gb1hEVE13TVRFeU5UQXpNakl4T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBSi85CjlZQ0VseTNRLzRuc2t5dGZZY2Zpby9jcDJoaSsxRWpPOGMrVmF4YTkrbTIrdldBT1VhU0xQZnQ0VmRSL1hIWjYKT3FQSEY5K3ozNEZIb1p4RTJIY3kxd3R0Y1hOTXk1Qy9VMUdnakgramZLaWNmbVJmS3luS1M4SU80T3pLRHBKUQpodHQzb0JxeDVHdU0wSUpkVmsydVg5RjhmVHEyTllaN2lzK0NOVWdXM2dxMXA4SzNkZWxjaDYyM2NBSHhSS0JLCmZEZC9iZnZiZitvR0ZQS29BNWhLcXVKb3BDVFcrN1VZdnA4ZCs0QTgwYkZ2cG5CSmlUK1pGU0sxRExKZHBuRlgKV0pDOHdwNzNBYU9KSHAydnNTZ0p6ajFvUHUvL1lnSWNPNStoSGl6bThVcnVGQWxkWmE2ZzN4VnFCazNDZnducApsaU50MzdiblJrZ3VUNUU5cFFNQ0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZNdnpFOXJORVFUWGNyUmJHcllmQ0J6VEpZby9NQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFBMjJZS1htS29kTkVmUklGS1ZOMXk1alRjQ2FIVnAyd3QvR1RNT3dHU1pYQXhlN2xBOQpIZDVCWHJoaXB6bkNPR1hxakRoZkVkaWVIa3VlcDNQWGxVTWxxa20yUGZkdUp0cTJ3T0piR0ZTVWZRR2xpS09MCkJ0eDRwVmd1dC9EQW11ZHNNNFlSeGRTS1R3bkppcjBBbkNnSWprd0gvZzdzekFYTVppMmZkYk9oL3NzcVFlZU4KREYrc01ld0czK2pSaVVqTEM2ck9sb0UySzArVjNhMDlMbmNiYlRCNDBVM0pZR0VvallzVExEdXZPakhuZElkKwpyM0FHMlNXMDRYek8wcHF4VDhlRjlkUE5qVG83SlpIeDc3RUtuNVNYU1YweGRuTTR1eHVBWDBoVExLenFyMlRNCmVJTzlZNGZWeHdCQk9BaFBQVmFTMW5SZy9GMXFIWWNKK20wUgotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    server: https://127.0.0.1:34927\n  name: kind-test2\ncontexts:\n- context:\n    cluster: kind-kind\n    user: kind-kind\n  name: kind-kind\n- context:\n    cluster: kind-test2\n    user: kind-test2\n  name: kind-test2\ncurrent-context: kind-test2\nkind: Config\npreferences: {}\nusers:\n- name: kind-kind\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lJTHRQZkozeVliVHN3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURFeE1qY3dNRFF5TWpsYUZ3MHlNVEV4TWpjd01EUXlNekZhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXJEaURMOWhSUGduVzNwdlcKQ1pNekVlTG0vRTJuVmlXdG9icTVoZUdrdG1Udi9aWEUydG9uKy96ZWROOThvM3J4ZEdneDNTZDRndjZtSnpQbgpFZ3hTRDcrQnErSmt5WG5oQThPM1RQakN0aHdES1JIZjEzbkI4NDNlbjZ3S3E5K3A1RHB2UFNNSkgyQkJLckkrCjlHWTFvTWp2SnRWSjMyZ1dhTnlJV0hzTkE0QmdPM0RRT2Y2cGN6bXZhbllKZFliYTFpQmpKUEVaRURPNEpFdHIKZWYrTUFHb1diSFlaeDdySWo5eTJoNzdOQi9DV0k1alVSUXp6MWQ0ZlFnV05WR1cyblVXbGlGZjlEWlRVR25CMwpHMHBUTjc5N1U0bUNYdWVBUjFxY25idS9YNjBMb2l6bEpKVWJzcjZYUWFaRmtKS2FzSGx2Tmdydm11cWhnSjZTCmxCWWNIUUlEQVFBQm8wZ3dSakFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0h3WURWUjBqQkJnd0ZvQVVOeUpzNTFWN2ZGSXZnVnpYMTRpOStBalFhdm93RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFBay8xbjJqLzhGdlhISm94V0Q3dUl4WUxTUmlrTjcxWWdOOW1yckVYRjVFUkxBMjI5eEtyT1c1ClV2Tm9nZGlqdWpEbDhoVjRoU1hkY3M0dE9ZNmZYbExkN3JhN25vL054UUtHM1lPdktWM2g0eS9wUEYxMENQL0sKTTFhSnNkY1U2aG8wbnZrL1dQSDB2ckxtNE1jUHpBbFUvazdvd3FiemcybHZQdDBCMTJjZHh4bk44UHp5VU4zZwpQQVBzT3hab1hwQnVpNjkxcEt2a1VDUm1MY0dUTHowT0Y5YXVOaUhRRG1qMG1hSEg2ckI2c0kvQzBuZ08vaCtSCmNsUnBGYk9uQnZRbW1nRjZER0E4cGxUSUM2ZE1JOGtXRzVaQWFSbzMrblFLME5sMERaUDVBTjM1cE1yS0M1R3cKeTdHaVlRQkFCVlJOZ2FJemg1bktHUXFJVVFXRUU5TT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\n    client-key-data: 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\n- name: kind-test2\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lJR2toZno1Qy9Yc2d3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURFeE1qY3dNekl5TVRoYUZ3MHlNVEV4TWpjd016SXlNakJhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXJ6azZ2RFJsMjI4V1RndUEKYnNNN0tLVUVaaWRmbVBKVW1kaitmdCs1UTZFSHFvUitzOHVycDVVc0tOY0krZzdoYkNJa2VzdzE4OGZ0NDVlSwp4eGpmV1NiUXNiSjYyb3RQRUVoSGpPZElRTHVxQlBqR1J1N3NwUE8yRzFnMFZTMm9UY0VUVlYzQ2RCUFFPRjNOCm9WblhPdzQwSWttWXVURDZHUEdNT2VwN05Rak4vZERybVphMy94WWxJK2loVHZJbnZXNjVYYmd0NTNwS203YXgKOUNSVGhjNUtONjg2TzVLekR6ZnhPZGtpUUhJdzNXL3BpTXRvOVV5QUF3V2RoUmc0K0VacW5OTjZXREl4RlNPNQpJN0Z6c3dtT2s0L29wcW55ZHhmNnFYamF6MGlvTTNyM0I4bUY0c09VakhtaDJyUnB3a3ZpQUxkV3AvbVo0ek5uClJYYVp3UUlEQVFBQm8wZ3dSakFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0h3WURWUjBqQkJnd0ZvQVV5L01UMnMwUkJOZHl0RnNhdGg4SUhOTWxpajh3RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFIMHg2am5uajNSQWxBY0dOZmxyY1Zob01XVUpOZCtVak5OSXNSTHRaSzJTYTh6SThCK0VIeUxFCndhRjJGMzZ0VTV6L1JiSFluK3d3Q3ByQVJjLzhYTUx2OEpnMVU2aDg2SkxpNm9qc29Vb0dhUFNoWmI3S1YyOUQKSE5JQ2p5M2QrenhjdEV4OWFTRDB3WkR0cFpVaS9tZlQ3MklRekVUazQ2QTQ4bldYdkx0MWJ6TEZ4T1hQZVB1WgpiZG1lcWR5QmN1TXI0MUppcEJVUlpOWDgxQ0xIQ1ZQU2tsRHkySVl0OUgxeVNmb3RHMUV4ZHlDZE1vRjZTVUdhCkpLY0psNGFSQ3JNLzNqSGx3YVpGcWR0WkFFZ2pzM3lOYXllTW9SYi93bEdpWkdaQTFhQ3JNZlU5bXRnTlMrMWIKbmE1M0RxVmRKZHBTSnhWSjNPQXpUY2s0OVV1Z2c4ND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\n    client-key-data: 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\n```\n可以看到两个cluster，两个context。context指定了cluster及user，users字段列出了两个user\n\ncontext名为kind-kind，cluser为kind-kind，user为kind-kind，意思就是当指定--context为kind-kind时，将使用kind-kind的user去访问cluster为kind-kind的集群。\n\ncurrent-context: kind-test2说明当前的context使用的是kind-test2，如果不指定--context，将默认使用kind-test2\n\n当然，用户可以修改当然默认的current-context\n```\nroot@ubuntu:~# kubectl get node\nNAME                   STATUS   ROLES    AGE     VERSION\ntest2-control-plane    Ready    master   2d23h   v1.19.1\ntest2-control-plane2   Ready    master   2d23h   v1.19.1\ntest2-control-plane3   Ready    master   2d23h   v1.19.1\ntest2-worker           Ready    <none>   2d23h   v1.19.1\ntest2-worker2          Ready    <none>   2d23h   v1.19.1\ntest2-worker3          Ready    <none>   2d23h   v1.19.1\n\nroot@ubuntu:~# kubectl config\nModify kubeconfig files using subcommands like \"kubectl config set current-context my-context\"\n\n The loading order follows these rules:\n\n  1.  If the --kubeconfig flag is set, then only that file is loaded. The flag may only be set once and no merging takes\nplace.\n  2.  If $KUBECONFIG environment variable is set, then it is used as a list of paths (normal path delimiting rules for\nyour system). These paths are merged. When a value is modified, it is modified in the file that defines the stanza. When\na value is created, it is created in the first file that exists. If no files in the chain exist, then it creates the\nlast file in the list.\n  3.  Otherwise, ${HOME}/.kube/config is used and no merging takes place.\n\nAvailable Commands:\n  current-context Displays the current-context\n  delete-cluster  Delete the specified cluster from the kubeconfig\n  delete-context  Delete the specified context from the kubeconfig\n  get-clusters    Display clusters defined in the kubeconfig\n  get-contexts    Describe one or many contexts\n  rename-context  Renames a context from the kubeconfig file.\n  set             Sets an individual value in a kubeconfig file\n  set-cluster     Sets a cluster entry in kubeconfig\n  set-context     Sets a context entry in kubeconfig\n  set-credentials Sets a user entry in kubeconfig\n  unset           Unsets an individual value in a kubeconfig file\n  use-context     Sets the current-context in a kubeconfig file\n  view            Display merged kubeconfig settings or a specified kubeconfig file\n\nUsage:\n  kubectl config SUBCOMMAND [options]\n\nUse \"kubectl <command> --help\" for more information about a given command.\nUse \"kubectl options\" for a list of global command-line options (applies to all commands).\n\nroot@ubuntu:~# kubectl config use-context\nSets the current-context in a kubeconfig file\n\nAliases:\nuse-context, use\n\nExamples:\n  # Use the context for the minikube cluster\n  kubectl config use-context minikube\n\nUsage:\n  kubectl config use-context CONTEXT_NAME [options]\n\nUse \"kubectl options\" for a list of global command-line options (applies to all commands).\nerror: Unexpected args: []\n\nroot@ubuntu:~# kubectl config use-context kind-kind\nSwitched to context \"kind-kind\".\n\nroot@ubuntu:~# kubectl get node\nNAME                 STATUS   ROLES    AGE    VERSION\nkind-control-plane   Ready    master   3d1h   v1.19.1\n```\n实际上，kind内部创建集群过程中，也是使用kubeadm，从上述创建过程中的打印也似乎能猜到这一点\n\n后面，就可以使用搭建好的集群环境，开始你的开发、测试工作了~~~\n","source":"_posts/kind快速部署Kubernetes环境.md","raw":"---\ntitle: kind快速部署Kubernetes环境\ndate: 2020-11-26 16:56:12\ntags:\n- kubernetes\n- 云原生\ncategories:\n- 云原生\n---\n\n# 什么是kind\n\nkind：Kubernetes In Docker，顾名思义，就是将kubernetes所需要的所有组件，全部部署在一个docker容器中，是一套开箱即用的kubernetes环境搭建方案。使用kind搭建的集群无法在生产中使用，但是如果你只是想在本地测试或者开发使用，不想占用太多的资源，那么使用kind是不错的选择。同样，kind还可以很方便的帮你本地的kubernetes源代码打成对应的镜像，方便测试。\n\nGitHub: https://github.com/kubernetes-sigs/kind\n\nDocumentation: https://kind.sigs.k8s.io/\n\n# 安装kind\n\n以Linux下安装为例：\n\n```\ncurl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.9.0/kind-linux-amd64\nchmod +x ./kind\nmv ./kind /usr/local/bin/kind\n```\n\n# 创建、查询集群\n\n```\nkind create cluster\n```\n该命令将默认创建名为kind的集群\n\n```\nroot@ubuntu:~# kind create cluster\nCreating cluster \"kind\" ...\n ✓ Ensuring node image (kindest/node:v1.19.1) 🖼\n ✓ Preparing nodes 📦\n ✓ Writing configuration 📜\n ✓ Starting control-plane 🕹️\n ✓ Installing CNI 🔌\n ✓ Installing StorageClass 💾\nSet kubectl context to \"kind-kind\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-kind\n\nHave a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂\n\nroot@ubuntu:~# kind get clusters\nkind\n```\n\n```\nkind create cluster --name test\n```\n该命令将创建名为test的集群\n\n```\nroot@ubuntu:~# kind create cluster --name test\nCreating cluster \"test\" ...\n ✓ Ensuring node image (kindest/node:v1.19.1) 🖼\n ✓ Preparing nodes 📦\n ✓ Writing configuration 📜\n ✓ Starting control-plane 🕹️\n ✓ Installing CNI 🔌\n ✓ Installing StorageClass 💾\nSet kubectl context to \"kind-test\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-test\n\nThanks for using kind! 😊\n\nroot@ubuntu:~# kind get clusters\nkind\ntest\n\nroot@ubuntu:~# kubectl cluster-info --context kind-test\nKubernetes master is running at https://127.0.0.1:44543\nKubeDNS is running at https://127.0.0.1:44543/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n```\n\nkubectl安装：https://kubernetes.io/docs/tasks/tools/install-kubectl/\n\n\n查询集群节点\n```\nroot@ubuntu:~# kubectl get nodes --context kind-test\nNAME                 STATUS   ROLES    AGE     VERSION\ntest-control-plane   Ready    master   4m55s   v1.19.1\n\nroot@ubuntu:~# kubectl get nodes --context kind-kind\nNAME                 STATUS   ROLES    AGE     VERSION\nkind-control-plane   Ready    master   9m14s   v1.19.1\n```\n\n```\nroot@ubuntu:~# docker ps\nCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES\n7fa7f8313453        kindest/node:v1.19.1   \"/usr/local/bin/entr…\"   16 minutes ago      Up 16 minutes       127.0.0.1:44543->6443/tcp   test-control-plane\n6fee527273e2        kindest/node:v1.19.1   \"/usr/local/bin/entr…\"   20 minutes ago      Up 20 minutes       127.0.0.1:36585->6443/tcp   kind-control-plane\nroot@ubuntu:~# docker ps -a\nCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES\n7fa7f8313453        kindest/node:v1.19.1   \"/usr/local/bin/entr…\"   16 minutes ago      Up 16 minutes       127.0.0.1:44543->6443/tcp   test-control-plane\n6fee527273e2        kindest/node:v1.19.1   \"/usr/local/bin/entr…\"   20 minutes ago      Up 20 minutes       127.0.0.1:36585->6443/tcp   kind-control-plane\n```\ntest-control-plane、kind-control-plane是运行在容器内的kubernetes节点，也正是kubernetes in Docker的意思\n\n查询集群内运行的pod\n```\nroot@ubuntu:~# kubectl get pods --all-namespaces --context kind-kind\nNAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE\nkube-system          coredns-f9fd979d6-cqpss                      1/1     Running   0          22m\nkube-system          coredns-f9fd979d6-kvbzm                      1/1     Running   0          22m\nkube-system          etcd-kind-control-plane                      1/1     Running   0          22m\nkube-system          kindnet-br2qc                                1/1     Running   0          22m\nkube-system          kube-apiserver-kind-control-plane            1/1     Running   0          22m\nkube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          22m\nkube-system          kube-proxy-4chlm                             1/1     Running   0          22m\nkube-system          kube-scheduler-kind-control-plane            1/1     Running   0          22m\nlocal-path-storage   local-path-provisioner-78776bfc44-xl4ht      1/1     Running   0          22m\n\nroot@ubuntu:~# kubectl get pods --all-namespaces --context kind-test\nNAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE\nkube-system          coredns-f9fd979d6-f7wsz                      1/1     Running   0          18m\nkube-system          coredns-f9fd979d6-j9xtx                      1/1     Running   0          18m\nkube-system          etcd-test-control-plane                      1/1     Running   0          18m\nkube-system          kindnet-jq867                                1/1     Running   0          18m\nkube-system          kube-apiserver-test-control-plane            1/1     Running   0          18m\nkube-system          kube-controller-manager-test-control-plane   1/1     Running   0          18m\nkube-system          kube-proxy-swn5j                             1/1     Running   0          18m\nkube-system          kube-scheduler-test-control-plane            1/1     Running   0          18m\nlocal-path-storage   local-path-provisioner-78776bfc44-nwqjq      1/1     Running   0          18m\n```\n\n查询pod使用的镜像\n```\nroot@ubuntu:~# docker exec -it kind-control-plane crictl images\nIMAGE                                      TAG                  IMAGE ID            SIZE\ndocker.io/kindest/kindnetd                 v20200725-4d6bea59   b77790820d015       119MB\ndocker.io/rancher/local-path-provisioner   v0.0.14              e422121c9c5f9       42MB\nk8s.gcr.io/build-image/debian-base         v2.1.0               c7c6c86897b63       53.9MB\nk8s.gcr.io/coredns                         1.7.0                bfe3a36ebd252       45.4MB\nk8s.gcr.io/etcd                            3.4.13-0             0369cf4303ffd       255MB\nk8s.gcr.io/kube-apiserver                  v1.19.1              8cba89a89aaa8       95MB\nk8s.gcr.io/kube-controller-manager         v1.19.1              7dafbafe72c90       84.1MB\nk8s.gcr.io/kube-proxy                      v1.19.1              47e289e332426       136MB\nk8s.gcr.io/kube-scheduler                  v1.19.1              4d648fc900179       65.1MB\nk8s.gcr.io/pause                           3.3                  0184c1613d929       686kB\nroot@ubuntu:~# docker exec -it kind-control-plane crictl ps\nCONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID\n1c881f7f0d306       bfe3a36ebd252       25 minutes ago      Running             coredns                   0                   75e161b37ab2d\nc64dd6bb666f3       bfe3a36ebd252       25 minutes ago      Running             coredns                   0                   a8305dc572af5\nfea2b69f5472d       e422121c9c5f9       26 minutes ago      Running             local-path-provisioner    0                   fb704b6340b63\n52f0995ba00f8       47e289e332426       26 minutes ago      Running             kube-proxy                0                   4c787e616d5a7\nb87cdcc514f59       b77790820d015       26 minutes ago      Running             kindnet-cni               0                   14eb70f9ca549\nce2c4e5b2b57f       0369cf4303ffd       27 minutes ago      Running             etcd                      0                   744a99a558714\n93b5084a29992       8cba89a89aaa8       27 minutes ago      Running             kube-apiserver            0                   91f88afc5a39b\n8b9579313058f       7dafbafe72c90       27 minutes ago      Running             kube-controller-manager   0                   8d54fdffef86e\n10fbb8244ad3b       4d648fc900179       27 minutes ago      Running             kube-scheduler            0                   a985ae4a105bc\n```\n其中，crictl命令可以理解为docker命令\n\n\n# 删除集群\n\n```\nkind delete cluster --name test\n```\n删除名为test的集群，--name未指定的话，将默认删除kind集群\n\n\n# 创建高可用kubernetes集群\n```\nroot@ubuntu:~# cat kind-config.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n- role: control-plane\n- role: control-plane\n- role: worker\n- role: worker\n- role: worker\n\nroot@ubuntu:~# kind create cluster --config kind-config.yaml --name test2\nCreating cluster \"test2\" ...\n ✓ Ensuring node image (kindest/node:v1.19.1) 🖼\n ✓ Preparing nodes 📦 📦 📦 📦 📦 📦\n ✓ Configuring the external load balancer ⚖️\n ✓ Writing configuration 📜\n ✓ Starting control-plane 🕹️\n ✓ Installing CNI 🔌\n ✓ Installing StorageClass 💾\n ✓ Joining more control-plane nodes 🎮\n ✓ Joining worker nodes 🚜\nSet kubectl context to \"kind-test2\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-test2\n\nHave a nice day! 👋\n\nroot@ubuntu:~# kubectl get nodes --context kind-test2\nNAME                   STATUS   ROLES    AGE     VERSION\ntest2-control-plane    Ready    master   5m12s   v1.19.1\ntest2-control-plane2   Ready    master   4m38s   v1.19.1\ntest2-control-plane3   Ready    master   3m22s   v1.19.1\ntest2-worker           Ready    <none>   2m5s    v1.19.1\ntest2-worker2          Ready    <none>   2m5s    v1.19.1\ntest2-worker3          Ready    <none>   2m5s    v1.19.1\n\nroot@ubuntu:~# kubectl get pods --all-namespaces --context kind-test2\nNAMESPACE            NAME                                           READY   STATUS    RESTARTS   AGE\nkube-system          coredns-f9fd979d6-jbpcz                        1/1     Running   0          5m16s\nkube-system          coredns-f9fd979d6-ng4qp                        1/1     Running   0          5m16s\nkube-system          etcd-test2-control-plane                       1/1     Running   0          5m15s\nkube-system          etcd-test2-control-plane2                      1/1     Running   0          4m54s\nkube-system          etcd-test2-control-plane3                      1/1     Running   0          2m59s\nkube-system          kindnet-gxpjn                                  1/1     Running   0          4m55s\nkube-system          kindnet-jqnx5                                  1/1     Running   0          2m20s\nkube-system          kindnet-lczmx                                  1/1     Running   0          2m18s\nkube-system          kindnet-q8bcn                                  1/1     Running   0          2m19s\nkube-system          kindnet-q9ng2                                  1/1     Running   0          3m37s\nkube-system          kindnet-s7kfb                                  1/1     Running   0          5m14s\nkube-system          kube-apiserver-test2-control-plane             1/1     Running   0          5m15s\nkube-system          kube-apiserver-test2-control-plane2            1/1     Running   0          4m54s\nkube-system          kube-apiserver-test2-control-plane3            1/1     Running   1          3m9s\nkube-system          kube-controller-manager-test2-control-plane    1/1     Running   2          5m14s\nkube-system          kube-controller-manager-test2-control-plane2   1/1     Running   0          4m54s\nkube-system          kube-controller-manager-test2-control-plane3   1/1     Running   0          2m8s\nkube-system          kube-proxy-47nc7                               1/1     Running   0          5m16s\nkube-system          kube-proxy-5799m                               1/1     Running   0          4m55s\nkube-system          kube-proxy-cvm49                               1/1     Running   0          2m18s\nkube-system          kube-proxy-s7rsp                               1/1     Running   0          2m18s\nkube-system          kube-proxy-sxwgl                               1/1     Running   0          3m37s\nkube-system          kube-proxy-wvskh                               1/1     Running   0          2m20s\nkube-system          kube-scheduler-test2-control-plane             0/1     Running   2          5m15s\nkube-system          kube-scheduler-test2-control-plane2            1/1     Running   0          4m54s\nkube-system          kube-scheduler-test2-control-plane3            1/1     Running   0          2m31s\nlocal-path-storage   local-path-provisioner-78776bfc44-fkdwq        1/1     Running   1          5m12s\n```\n\n上述过程，我们创建了两个kubernetes集群，kind和test2；可以看到我们在使用kubectl访问集群时，增加了参数：--context，这在本地的配置文件里指定了\n```\nroot@ubuntu:~# cat .kube/config\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01URXlOekF3TkRJeU9Wb1hEVE13TVRFeU5UQXdOREl5T1Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTERTCm5TU1NHS05PUUlCVWpQeXpYOFRDZm5IamExV2JxeXZJeHV3Y1Aybmh6Zi9EdG9wVDRnSTVjMlBMV3Qrd05BUFUKUHA2dGV3ZkhNQ3N6MnJLbnhaRmtWS2c5NXVFdW53V1ZuZnlmeGV0TjlOU1JTZ2s2dkJuVUt6SFliRXIybEY0LwpicFVxT2IzWnkxQXdYNlpyRTN3Y1I1RjdLV2trT0FZbHdobUtiLzIwOVZJRG4yMW9CMHMzNXgrM3Z2L2gzQ3VaCkJCQjJnNVBKMm4xc1pwd05scnZDMmh0RmJDSjQwQVNXZmNsUksyejBYUEIvdzdNQlBXMHp1cnpEMUVBcGdZVUcKUGUwOEx3dW1zMllZR3Y5TDJXMERhWW90c2JoVXlWZWRDNnpjeWtUZ0hOb1B6LytvZlBHQmxYTko3S2lwd2Z6ZQo2dzdHZGJhbjlpRms4cjAyaVQ4Q0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZEY2liT2RWZTN4U0w0RmMxOWVJdmZnSTBHcjZNQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFCS1lKSVFaenhSblFWWWp4TnlTaXJualFvZUM3OGtDMERNYjZpRFBvMFdEbmdTUjhRYgpqRjZxR2ZPMTFTcDNjeVl3V1IrM3UzU2pzQUJUUG5jcWZpWnEyN3VDMlRYNjdMQzRPNVFoVkdlRlBDdXJNNHluCi8weDZuOUZrMko5YmpTT0o1aDB2NmQ1eXBibk5sNVgvN1czWFVyK2tjOSswWG1sMFN0dmJVZ0hCaWVmWGxtZ3AKUXl5TlFtNU1yWlRFcWJOT0JubW1RWUJYWDdydWVLZXhVYUJ4QXQrRVJVWHBVOWNhbkNWWWhuZFBuMVNBYVladApsQkZyamRSNzg1SE1EV21qTW5UalJXSUhOSWd2NUgwKyt2MmN5cjRSK1lUWGo3S0JrdEZTRDA2U0I0RDZVeFk2CmRUZ25UMngzRXJvSERPZURjWWRrVmt2TkF5aC9JUGFTd2R6cwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    server: https://127.0.0.1:36585\n  name: kind-kind\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01URXlOekF6TWpJeE9Gb1hEVE13TVRFeU5UQXpNakl4T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBSi85CjlZQ0VseTNRLzRuc2t5dGZZY2Zpby9jcDJoaSsxRWpPOGMrVmF4YTkrbTIrdldBT1VhU0xQZnQ0VmRSL1hIWjYKT3FQSEY5K3ozNEZIb1p4RTJIY3kxd3R0Y1hOTXk1Qy9VMUdnakgramZLaWNmbVJmS3luS1M4SU80T3pLRHBKUQpodHQzb0JxeDVHdU0wSUpkVmsydVg5RjhmVHEyTllaN2lzK0NOVWdXM2dxMXA4SzNkZWxjaDYyM2NBSHhSS0JLCmZEZC9iZnZiZitvR0ZQS29BNWhLcXVKb3BDVFcrN1VZdnA4ZCs0QTgwYkZ2cG5CSmlUK1pGU0sxRExKZHBuRlgKV0pDOHdwNzNBYU9KSHAydnNTZ0p6ajFvUHUvL1lnSWNPNStoSGl6bThVcnVGQWxkWmE2ZzN4VnFCazNDZnducApsaU50MzdiblJrZ3VUNUU5cFFNQ0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZNdnpFOXJORVFUWGNyUmJHcllmQ0J6VEpZby9NQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFBMjJZS1htS29kTkVmUklGS1ZOMXk1alRjQ2FIVnAyd3QvR1RNT3dHU1pYQXhlN2xBOQpIZDVCWHJoaXB6bkNPR1hxakRoZkVkaWVIa3VlcDNQWGxVTWxxa20yUGZkdUp0cTJ3T0piR0ZTVWZRR2xpS09MCkJ0eDRwVmd1dC9EQW11ZHNNNFlSeGRTS1R3bkppcjBBbkNnSWprd0gvZzdzekFYTVppMmZkYk9oL3NzcVFlZU4KREYrc01ld0czK2pSaVVqTEM2ck9sb0UySzArVjNhMDlMbmNiYlRCNDBVM0pZR0VvallzVExEdXZPakhuZElkKwpyM0FHMlNXMDRYek8wcHF4VDhlRjlkUE5qVG83SlpIeDc3RUtuNVNYU1YweGRuTTR1eHVBWDBoVExLenFyMlRNCmVJTzlZNGZWeHdCQk9BaFBQVmFTMW5SZy9GMXFIWWNKK20wUgotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    server: https://127.0.0.1:34927\n  name: kind-test2\ncontexts:\n- context:\n    cluster: kind-kind\n    user: kind-kind\n  name: kind-kind\n- context:\n    cluster: kind-test2\n    user: kind-test2\n  name: kind-test2\ncurrent-context: kind-test2\nkind: Config\npreferences: {}\nusers:\n- name: kind-kind\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lJTHRQZkozeVliVHN3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURFeE1qY3dNRFF5TWpsYUZ3MHlNVEV4TWpjd01EUXlNekZhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXJEaURMOWhSUGduVzNwdlcKQ1pNekVlTG0vRTJuVmlXdG9icTVoZUdrdG1Udi9aWEUydG9uKy96ZWROOThvM3J4ZEdneDNTZDRndjZtSnpQbgpFZ3hTRDcrQnErSmt5WG5oQThPM1RQakN0aHdES1JIZjEzbkI4NDNlbjZ3S3E5K3A1RHB2UFNNSkgyQkJLckkrCjlHWTFvTWp2SnRWSjMyZ1dhTnlJV0hzTkE0QmdPM0RRT2Y2cGN6bXZhbllKZFliYTFpQmpKUEVaRURPNEpFdHIKZWYrTUFHb1diSFlaeDdySWo5eTJoNzdOQi9DV0k1alVSUXp6MWQ0ZlFnV05WR1cyblVXbGlGZjlEWlRVR25CMwpHMHBUTjc5N1U0bUNYdWVBUjFxY25idS9YNjBMb2l6bEpKVWJzcjZYUWFaRmtKS2FzSGx2Tmdydm11cWhnSjZTCmxCWWNIUUlEQVFBQm8wZ3dSakFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0h3WURWUjBqQkJnd0ZvQVVOeUpzNTFWN2ZGSXZnVnpYMTRpOStBalFhdm93RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFBay8xbjJqLzhGdlhISm94V0Q3dUl4WUxTUmlrTjcxWWdOOW1yckVYRjVFUkxBMjI5eEtyT1c1ClV2Tm9nZGlqdWpEbDhoVjRoU1hkY3M0dE9ZNmZYbExkN3JhN25vL054UUtHM1lPdktWM2g0eS9wUEYxMENQL0sKTTFhSnNkY1U2aG8wbnZrL1dQSDB2ckxtNE1jUHpBbFUvazdvd3FiemcybHZQdDBCMTJjZHh4bk44UHp5VU4zZwpQQVBzT3hab1hwQnVpNjkxcEt2a1VDUm1MY0dUTHowT0Y5YXVOaUhRRG1qMG1hSEg2ckI2c0kvQzBuZ08vaCtSCmNsUnBGYk9uQnZRbW1nRjZER0E4cGxUSUM2ZE1JOGtXRzVaQWFSbzMrblFLME5sMERaUDVBTjM1cE1yS0M1R3cKeTdHaVlRQkFCVlJOZ2FJemg1bktHUXFJVVFXRUU5TT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\n    client-key-data: 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\n- name: kind-test2\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lJR2toZno1Qy9Yc2d3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURFeE1qY3dNekl5TVRoYUZ3MHlNVEV4TWpjd016SXlNakJhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXJ6azZ2RFJsMjI4V1RndUEKYnNNN0tLVUVaaWRmbVBKVW1kaitmdCs1UTZFSHFvUitzOHVycDVVc0tOY0krZzdoYkNJa2VzdzE4OGZ0NDVlSwp4eGpmV1NiUXNiSjYyb3RQRUVoSGpPZElRTHVxQlBqR1J1N3NwUE8yRzFnMFZTMm9UY0VUVlYzQ2RCUFFPRjNOCm9WblhPdzQwSWttWXVURDZHUEdNT2VwN05Rak4vZERybVphMy94WWxJK2loVHZJbnZXNjVYYmd0NTNwS203YXgKOUNSVGhjNUtONjg2TzVLekR6ZnhPZGtpUUhJdzNXL3BpTXRvOVV5QUF3V2RoUmc0K0VacW5OTjZXREl4RlNPNQpJN0Z6c3dtT2s0L29wcW55ZHhmNnFYamF6MGlvTTNyM0I4bUY0c09VakhtaDJyUnB3a3ZpQUxkV3AvbVo0ek5uClJYYVp3UUlEQVFBQm8wZ3dSakFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0h3WURWUjBqQkJnd0ZvQVV5L01UMnMwUkJOZHl0RnNhdGg4SUhOTWxpajh3RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFIMHg2am5uajNSQWxBY0dOZmxyY1Zob01XVUpOZCtVak5OSXNSTHRaSzJTYTh6SThCK0VIeUxFCndhRjJGMzZ0VTV6L1JiSFluK3d3Q3ByQVJjLzhYTUx2OEpnMVU2aDg2SkxpNm9qc29Vb0dhUFNoWmI3S1YyOUQKSE5JQ2p5M2QrenhjdEV4OWFTRDB3WkR0cFpVaS9tZlQ3MklRekVUazQ2QTQ4bldYdkx0MWJ6TEZ4T1hQZVB1WgpiZG1lcWR5QmN1TXI0MUppcEJVUlpOWDgxQ0xIQ1ZQU2tsRHkySVl0OUgxeVNmb3RHMUV4ZHlDZE1vRjZTVUdhCkpLY0psNGFSQ3JNLzNqSGx3YVpGcWR0WkFFZ2pzM3lOYXllTW9SYi93bEdpWkdaQTFhQ3JNZlU5bXRnTlMrMWIKbmE1M0RxVmRKZHBTSnhWSjNPQXpUY2s0OVV1Z2c4ND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\n    client-key-data: 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\n```\n可以看到两个cluster，两个context。context指定了cluster及user，users字段列出了两个user\n\ncontext名为kind-kind，cluser为kind-kind，user为kind-kind，意思就是当指定--context为kind-kind时，将使用kind-kind的user去访问cluster为kind-kind的集群。\n\ncurrent-context: kind-test2说明当前的context使用的是kind-test2，如果不指定--context，将默认使用kind-test2\n\n当然，用户可以修改当然默认的current-context\n```\nroot@ubuntu:~# kubectl get node\nNAME                   STATUS   ROLES    AGE     VERSION\ntest2-control-plane    Ready    master   2d23h   v1.19.1\ntest2-control-plane2   Ready    master   2d23h   v1.19.1\ntest2-control-plane3   Ready    master   2d23h   v1.19.1\ntest2-worker           Ready    <none>   2d23h   v1.19.1\ntest2-worker2          Ready    <none>   2d23h   v1.19.1\ntest2-worker3          Ready    <none>   2d23h   v1.19.1\n\nroot@ubuntu:~# kubectl config\nModify kubeconfig files using subcommands like \"kubectl config set current-context my-context\"\n\n The loading order follows these rules:\n\n  1.  If the --kubeconfig flag is set, then only that file is loaded. The flag may only be set once and no merging takes\nplace.\n  2.  If $KUBECONFIG environment variable is set, then it is used as a list of paths (normal path delimiting rules for\nyour system). These paths are merged. When a value is modified, it is modified in the file that defines the stanza. When\na value is created, it is created in the first file that exists. If no files in the chain exist, then it creates the\nlast file in the list.\n  3.  Otherwise, ${HOME}/.kube/config is used and no merging takes place.\n\nAvailable Commands:\n  current-context Displays the current-context\n  delete-cluster  Delete the specified cluster from the kubeconfig\n  delete-context  Delete the specified context from the kubeconfig\n  get-clusters    Display clusters defined in the kubeconfig\n  get-contexts    Describe one or many contexts\n  rename-context  Renames a context from the kubeconfig file.\n  set             Sets an individual value in a kubeconfig file\n  set-cluster     Sets a cluster entry in kubeconfig\n  set-context     Sets a context entry in kubeconfig\n  set-credentials Sets a user entry in kubeconfig\n  unset           Unsets an individual value in a kubeconfig file\n  use-context     Sets the current-context in a kubeconfig file\n  view            Display merged kubeconfig settings or a specified kubeconfig file\n\nUsage:\n  kubectl config SUBCOMMAND [options]\n\nUse \"kubectl <command> --help\" for more information about a given command.\nUse \"kubectl options\" for a list of global command-line options (applies to all commands).\n\nroot@ubuntu:~# kubectl config use-context\nSets the current-context in a kubeconfig file\n\nAliases:\nuse-context, use\n\nExamples:\n  # Use the context for the minikube cluster\n  kubectl config use-context minikube\n\nUsage:\n  kubectl config use-context CONTEXT_NAME [options]\n\nUse \"kubectl options\" for a list of global command-line options (applies to all commands).\nerror: Unexpected args: []\n\nroot@ubuntu:~# kubectl config use-context kind-kind\nSwitched to context \"kind-kind\".\n\nroot@ubuntu:~# kubectl get node\nNAME                 STATUS   ROLES    AGE    VERSION\nkind-control-plane   Ready    master   3d1h   v1.19.1\n```\n实际上，kind内部创建集群过程中，也是使用kubeadm，从上述创建过程中的打印也似乎能猜到这一点\n\n后面，就可以使用搭建好的集群环境，开始你的开发、测试工作了~~~\n","slug":"kind快速部署Kubernetes环境","published":1,"updated":"2020-11-30T02:42:25.604Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cki73ih1j001ih0l70wzr37c4","content":"<h1 id=\"什么是kind\"><a href=\"#什么是kind\" class=\"headerlink\" title=\"什么是kind\"></a>什么是kind</h1><p>kind：Kubernetes In Docker，顾名思义，就是将kubernetes所需要的所有组件，全部部署在一个docker容器中，是一套开箱即用的kubernetes环境搭建方案。使用kind搭建的集群无法在生产中使用，但是如果你只是想在本地测试或者开发使用，不想占用太多的资源，那么使用kind是不错的选择。同样，kind还可以很方便的帮你本地的kubernetes源代码打成对应的镜像，方便测试。</p>\n<p>GitHub: <a href=\"https://github.com/kubernetes-sigs/kind\">https://github.com/kubernetes-sigs/kind</a></p>\n<p>Documentation: <a href=\"https://kind.sigs.k8s.io/\">https://kind.sigs.k8s.io/</a></p>\n<h1 id=\"安装kind\"><a href=\"#安装kind\" class=\"headerlink\" title=\"安装kind\"></a>安装kind</h1><p>以Linux下安装为例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -Lo .&#x2F;kind https:&#x2F;&#x2F;kind.sigs.k8s.io&#x2F;dl&#x2F;v0.9.0&#x2F;kind-linux-amd64</span><br><span class=\"line\">chmod +x .&#x2F;kind</span><br><span class=\"line\">mv .&#x2F;kind &#x2F;usr&#x2F;local&#x2F;bin&#x2F;kind</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"创建、查询集群\"><a href=\"#创建、查询集群\" class=\"headerlink\" title=\"创建、查询集群\"></a>创建、查询集群</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind create cluster</span><br></pre></td></tr></table></figure>\n<p>该命令将默认创建名为kind的集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kind create cluster</span><br><span class=\"line\">Creating cluster &quot;kind&quot; ...</span><br><span class=\"line\"> ✓ Ensuring node image (kindest&#x2F;node:v1.19.1) 🖼</span><br><span class=\"line\"> ✓ Preparing nodes 📦</span><br><span class=\"line\"> ✓ Writing configuration 📜</span><br><span class=\"line\"> ✓ Starting control-plane 🕹️</span><br><span class=\"line\"> ✓ Installing CNI 🔌</span><br><span class=\"line\"> ✓ Installing StorageClass 💾</span><br><span class=\"line\">Set kubectl context to &quot;kind-kind&quot;</span><br><span class=\"line\">You can now use your cluster with:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl cluster-info --context kind-kind</span><br><span class=\"line\"></span><br><span class=\"line\">Have a question, bug, or feature request? Let us know! https:&#x2F;&#x2F;kind.sigs.k8s.io&#x2F;#community 🙂</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kind get clusters</span><br><span class=\"line\">kind</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind create cluster --name test</span><br></pre></td></tr></table></figure>\n<p>该命令将创建名为test的集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kind create cluster --name test</span><br><span class=\"line\">Creating cluster &quot;test&quot; ...</span><br><span class=\"line\"> ✓ Ensuring node image (kindest&#x2F;node:v1.19.1) 🖼</span><br><span class=\"line\"> ✓ Preparing nodes 📦</span><br><span class=\"line\"> ✓ Writing configuration 📜</span><br><span class=\"line\"> ✓ Starting control-plane 🕹️</span><br><span class=\"line\"> ✓ Installing CNI 🔌</span><br><span class=\"line\"> ✓ Installing StorageClass 💾</span><br><span class=\"line\">Set kubectl context to &quot;kind-test&quot;</span><br><span class=\"line\">You can now use your cluster with:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl cluster-info --context kind-test</span><br><span class=\"line\"></span><br><span class=\"line\">Thanks for using kind! 😊</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kind get clusters</span><br><span class=\"line\">kind</span><br><span class=\"line\">test</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl cluster-info --context kind-test</span><br><span class=\"line\">Kubernetes master is running at https:&#x2F;&#x2F;127.0.0.1:44543</span><br><span class=\"line\">KubeDNS is running at https:&#x2F;&#x2F;127.0.0.1:44543&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-system&#x2F;services&#x2F;kube-dns:dns&#x2F;proxy</span><br><span class=\"line\"></span><br><span class=\"line\">To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.</span><br></pre></td></tr></table></figure>\n\n<p>kubectl安装：<a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>\n<p>查询集群节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl get nodes --context kind-test</span><br><span class=\"line\">NAME                 STATUS   ROLES    AGE     VERSION</span><br><span class=\"line\">test-control-plane   Ready    master   4m55s   v1.19.1</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get nodes --context kind-kind</span><br><span class=\"line\">NAME                 STATUS   ROLES    AGE     VERSION</span><br><span class=\"line\">kind-control-plane   Ready    master   9m14s   v1.19.1</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES</span><br><span class=\"line\">7fa7f8313453        kindest&#x2F;node:v1.19.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;entr…&quot;   16 minutes ago      Up 16 minutes       127.0.0.1:44543-&gt;6443&#x2F;tcp   test-control-plane</span><br><span class=\"line\">6fee527273e2        kindest&#x2F;node:v1.19.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;entr…&quot;   20 minutes ago      Up 20 minutes       127.0.0.1:36585-&gt;6443&#x2F;tcp   kind-control-plane</span><br><span class=\"line\">root@ubuntu:~# docker ps -a</span><br><span class=\"line\">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES</span><br><span class=\"line\">7fa7f8313453        kindest&#x2F;node:v1.19.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;entr…&quot;   16 minutes ago      Up 16 minutes       127.0.0.1:44543-&gt;6443&#x2F;tcp   test-control-plane</span><br><span class=\"line\">6fee527273e2        kindest&#x2F;node:v1.19.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;entr…&quot;   20 minutes ago      Up 20 minutes       127.0.0.1:36585-&gt;6443&#x2F;tcp   kind-control-plane</span><br></pre></td></tr></table></figure>\n<p>test-control-plane、kind-control-plane是运行在容器内的kubernetes节点，也正是kubernetes in Docker的意思</p>\n<p>查询集群内运行的pod</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl get pods --all-namespaces --context kind-kind</span><br><span class=\"line\">NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-cqpss                      1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-kvbzm                      1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          etcd-kind-control-plane                      1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kindnet-br2qc                                1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kube-apiserver-kind-control-plane            1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kube-controller-manager-kind-control-plane   1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kube-proxy-4chlm                             1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kube-scheduler-kind-control-plane            1&#x2F;1     Running   0          22m</span><br><span class=\"line\">local-path-storage   local-path-provisioner-78776bfc44-xl4ht      1&#x2F;1     Running   0          22m</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get pods --all-namespaces --context kind-test</span><br><span class=\"line\">NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-f7wsz                      1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-j9xtx                      1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          etcd-test-control-plane                      1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kindnet-jq867                                1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kube-apiserver-test-control-plane            1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kube-controller-manager-test-control-plane   1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kube-proxy-swn5j                             1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kube-scheduler-test-control-plane            1&#x2F;1     Running   0          18m</span><br><span class=\"line\">local-path-storage   local-path-provisioner-78776bfc44-nwqjq      1&#x2F;1     Running   0          18m</span><br></pre></td></tr></table></figure>\n\n<p>查询pod使用的镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# docker exec -it kind-control-plane crictl images</span><br><span class=\"line\">IMAGE                                      TAG                  IMAGE ID            SIZE</span><br><span class=\"line\">docker.io&#x2F;kindest&#x2F;kindnetd                 v20200725-4d6bea59   b77790820d015       119MB</span><br><span class=\"line\">docker.io&#x2F;rancher&#x2F;local-path-provisioner   v0.0.14              e422121c9c5f9       42MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;build-image&#x2F;debian-base         v2.1.0               c7c6c86897b63       53.9MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;coredns                         1.7.0                bfe3a36ebd252       45.4MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;etcd                            3.4.13-0             0369cf4303ffd       255MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;kube-apiserver                  v1.19.1              8cba89a89aaa8       95MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;kube-controller-manager         v1.19.1              7dafbafe72c90       84.1MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;kube-proxy                      v1.19.1              47e289e332426       136MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;kube-scheduler                  v1.19.1              4d648fc900179       65.1MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;pause                           3.3                  0184c1613d929       686kB</span><br><span class=\"line\">root@ubuntu:~# docker exec -it kind-control-plane crictl ps</span><br><span class=\"line\">CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID</span><br><span class=\"line\">1c881f7f0d306       bfe3a36ebd252       25 minutes ago      Running             coredns                   0                   75e161b37ab2d</span><br><span class=\"line\">c64dd6bb666f3       bfe3a36ebd252       25 minutes ago      Running             coredns                   0                   a8305dc572af5</span><br><span class=\"line\">fea2b69f5472d       e422121c9c5f9       26 minutes ago      Running             local-path-provisioner    0                   fb704b6340b63</span><br><span class=\"line\">52f0995ba00f8       47e289e332426       26 minutes ago      Running             kube-proxy                0                   4c787e616d5a7</span><br><span class=\"line\">b87cdcc514f59       b77790820d015       26 minutes ago      Running             kindnet-cni               0                   14eb70f9ca549</span><br><span class=\"line\">ce2c4e5b2b57f       0369cf4303ffd       27 minutes ago      Running             etcd                      0                   744a99a558714</span><br><span class=\"line\">93b5084a29992       8cba89a89aaa8       27 minutes ago      Running             kube-apiserver            0                   91f88afc5a39b</span><br><span class=\"line\">8b9579313058f       7dafbafe72c90       27 minutes ago      Running             kube-controller-manager   0                   8d54fdffef86e</span><br><span class=\"line\">10fbb8244ad3b       4d648fc900179       27 minutes ago      Running             kube-scheduler            0                   a985ae4a105bc</span><br></pre></td></tr></table></figure>\n<p>其中，crictl命令可以理解为docker命令</p>\n<h1 id=\"删除集群\"><a href=\"#删除集群\" class=\"headerlink\" title=\"删除集群\"></a>删除集群</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind delete cluster --name test</span><br></pre></td></tr></table></figure>\n<p>删除名为test的集群，–name未指定的话，将默认删除kind集群</p>\n<h1 id=\"创建高可用kubernetes集群\"><a href=\"#创建高可用kubernetes集群\" class=\"headerlink\" title=\"创建高可用kubernetes集群\"></a>创建高可用kubernetes集群</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# cat kind-config.yaml</span><br><span class=\"line\">kind: Cluster</span><br><span class=\"line\">apiVersion: kind.x-k8s.io&#x2F;v1alpha4</span><br><span class=\"line\">nodes:</span><br><span class=\"line\">- role: control-plane</span><br><span class=\"line\">- role: control-plane</span><br><span class=\"line\">- role: control-plane</span><br><span class=\"line\">- role: worker</span><br><span class=\"line\">- role: worker</span><br><span class=\"line\">- role: worker</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kind create cluster --config kind-config.yaml --name test2</span><br><span class=\"line\">Creating cluster &quot;test2&quot; ...</span><br><span class=\"line\"> ✓ Ensuring node image (kindest&#x2F;node:v1.19.1) 🖼</span><br><span class=\"line\"> ✓ Preparing nodes 📦 📦 📦 📦 📦 📦</span><br><span class=\"line\"> ✓ Configuring the external load balancer ⚖️</span><br><span class=\"line\"> ✓ Writing configuration 📜</span><br><span class=\"line\"> ✓ Starting control-plane 🕹️</span><br><span class=\"line\"> ✓ Installing CNI 🔌</span><br><span class=\"line\"> ✓ Installing StorageClass 💾</span><br><span class=\"line\"> ✓ Joining more control-plane nodes 🎮</span><br><span class=\"line\"> ✓ Joining worker nodes 🚜</span><br><span class=\"line\">Set kubectl context to &quot;kind-test2&quot;</span><br><span class=\"line\">You can now use your cluster with:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl cluster-info --context kind-test2</span><br><span class=\"line\"></span><br><span class=\"line\">Have a nice day! 👋</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get nodes --context kind-test2</span><br><span class=\"line\">NAME                   STATUS   ROLES    AGE     VERSION</span><br><span class=\"line\">test2-control-plane    Ready    master   5m12s   v1.19.1</span><br><span class=\"line\">test2-control-plane2   Ready    master   4m38s   v1.19.1</span><br><span class=\"line\">test2-control-plane3   Ready    master   3m22s   v1.19.1</span><br><span class=\"line\">test2-worker           Ready    &lt;none&gt;   2m5s    v1.19.1</span><br><span class=\"line\">test2-worker2          Ready    &lt;none&gt;   2m5s    v1.19.1</span><br><span class=\"line\">test2-worker3          Ready    &lt;none&gt;   2m5s    v1.19.1</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get pods --all-namespaces --context kind-test2</span><br><span class=\"line\">NAMESPACE            NAME                                           READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-jbpcz                        1&#x2F;1     Running   0          5m16s</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-ng4qp                        1&#x2F;1     Running   0          5m16s</span><br><span class=\"line\">kube-system          etcd-test2-control-plane                       1&#x2F;1     Running   0          5m15s</span><br><span class=\"line\">kube-system          etcd-test2-control-plane2                      1&#x2F;1     Running   0          4m54s</span><br><span class=\"line\">kube-system          etcd-test2-control-plane3                      1&#x2F;1     Running   0          2m59s</span><br><span class=\"line\">kube-system          kindnet-gxpjn                                  1&#x2F;1     Running   0          4m55s</span><br><span class=\"line\">kube-system          kindnet-jqnx5                                  1&#x2F;1     Running   0          2m20s</span><br><span class=\"line\">kube-system          kindnet-lczmx                                  1&#x2F;1     Running   0          2m18s</span><br><span class=\"line\">kube-system          kindnet-q8bcn                                  1&#x2F;1     Running   0          2m19s</span><br><span class=\"line\">kube-system          kindnet-q9ng2                                  1&#x2F;1     Running   0          3m37s</span><br><span class=\"line\">kube-system          kindnet-s7kfb                                  1&#x2F;1     Running   0          5m14s</span><br><span class=\"line\">kube-system          kube-apiserver-test2-control-plane             1&#x2F;1     Running   0          5m15s</span><br><span class=\"line\">kube-system          kube-apiserver-test2-control-plane2            1&#x2F;1     Running   0          4m54s</span><br><span class=\"line\">kube-system          kube-apiserver-test2-control-plane3            1&#x2F;1     Running   1          3m9s</span><br><span class=\"line\">kube-system          kube-controller-manager-test2-control-plane    1&#x2F;1     Running   2          5m14s</span><br><span class=\"line\">kube-system          kube-controller-manager-test2-control-plane2   1&#x2F;1     Running   0          4m54s</span><br><span class=\"line\">kube-system          kube-controller-manager-test2-control-plane3   1&#x2F;1     Running   0          2m8s</span><br><span class=\"line\">kube-system          kube-proxy-47nc7                               1&#x2F;1     Running   0          5m16s</span><br><span class=\"line\">kube-system          kube-proxy-5799m                               1&#x2F;1     Running   0          4m55s</span><br><span class=\"line\">kube-system          kube-proxy-cvm49                               1&#x2F;1     Running   0          2m18s</span><br><span class=\"line\">kube-system          kube-proxy-s7rsp                               1&#x2F;1     Running   0          2m18s</span><br><span class=\"line\">kube-system          kube-proxy-sxwgl                               1&#x2F;1     Running   0          3m37s</span><br><span class=\"line\">kube-system          kube-proxy-wvskh                               1&#x2F;1     Running   0          2m20s</span><br><span class=\"line\">kube-system          kube-scheduler-test2-control-plane             0&#x2F;1     Running   2          5m15s</span><br><span class=\"line\">kube-system          kube-scheduler-test2-control-plane2            1&#x2F;1     Running   0          4m54s</span><br><span class=\"line\">kube-system          kube-scheduler-test2-control-plane3            1&#x2F;1     Running   0          2m31s</span><br><span class=\"line\">local-path-storage   local-path-provisioner-78776bfc44-fkdwq        1&#x2F;1     Running   1          5m12s</span><br></pre></td></tr></table></figure>\n\n<p>上述过程，我们创建了两个kubernetes集群，kind和test2；可以看到我们在使用kubectl访问集群时，增加了参数：–context，这在本地的配置文件里指定了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# cat .kube&#x2F;config</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01URXlOekF3TkRJeU9Wb1hEVE13TVRFeU5UQXdOREl5T1Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTERTCm5TU1NHS05PUUlCVWpQeXpYOFRDZm5IamExV2JxeXZJeHV3Y1Aybmh6Zi9EdG9wVDRnSTVjMlBMV3Qrd05BUFUKUHA2dGV3ZkhNQ3N6MnJLbnhaRmtWS2c5NXVFdW53V1ZuZnlmeGV0TjlOU1JTZ2s2dkJuVUt6SFliRXIybEY0LwpicFVxT2IzWnkxQXdYNlpyRTN3Y1I1RjdLV2trT0FZbHdobUtiLzIwOVZJRG4yMW9CMHMzNXgrM3Z2L2gzQ3VaCkJCQjJnNVBKMm4xc1pwd05scnZDMmh0RmJDSjQwQVNXZmNsUksyejBYUEIvdzdNQlBXMHp1cnpEMUVBcGdZVUcKUGUwOEx3dW1zMllZR3Y5TDJXMERhWW90c2JoVXlWZWRDNnpjeWtUZ0hOb1B6LytvZlBHQmxYTko3S2lwd2Z6ZQo2dzdHZGJhbjlpRms4cjAyaVQ4Q0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZEY2liT2RWZTN4U0w0RmMxOWVJdmZnSTBHcjZNQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFCS1lKSVFaenhSblFWWWp4TnlTaXJualFvZUM3OGtDMERNYjZpRFBvMFdEbmdTUjhRYgpqRjZxR2ZPMTFTcDNjeVl3V1IrM3UzU2pzQUJUUG5jcWZpWnEyN3VDMlRYNjdMQzRPNVFoVkdlRlBDdXJNNHluCi8weDZuOUZrMko5YmpTT0o1aDB2NmQ1eXBibk5sNVgvN1czWFVyK2tjOSswWG1sMFN0dmJVZ0hCaWVmWGxtZ3AKUXl5TlFtNU1yWlRFcWJOT0JubW1RWUJYWDdydWVLZXhVYUJ4QXQrRVJVWHBVOWNhbkNWWWhuZFBuMVNBYVladApsQkZyamRSNzg1SE1EV21qTW5UalJXSUhOSWd2NUgwKyt2MmN5cjRSK1lUWGo3S0JrdEZTRDA2U0I0RDZVeFk2CmRUZ25UMngzRXJvSERPZURjWWRrVmt2TkF5aC9JUGFTd2R6cwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg&#x3D;&#x3D;</span><br><span class=\"line\">    server: https:&#x2F;&#x2F;127.0.0.1:36585</span><br><span class=\"line\">  name: kind-kind</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01URXlOekF6TWpJeE9Gb1hEVE13TVRFeU5UQXpNakl4T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBSi85CjlZQ0VseTNRLzRuc2t5dGZZY2Zpby9jcDJoaSsxRWpPOGMrVmF4YTkrbTIrdldBT1VhU0xQZnQ0VmRSL1hIWjYKT3FQSEY5K3ozNEZIb1p4RTJIY3kxd3R0Y1hOTXk1Qy9VMUdnakgramZLaWNmbVJmS3luS1M4SU80T3pLRHBKUQpodHQzb0JxeDVHdU0wSUpkVmsydVg5RjhmVHEyTllaN2lzK0NOVWdXM2dxMXA4SzNkZWxjaDYyM2NBSHhSS0JLCmZEZC9iZnZiZitvR0ZQS29BNWhLcXVKb3BDVFcrN1VZdnA4ZCs0QTgwYkZ2cG5CSmlUK1pGU0sxRExKZHBuRlgKV0pDOHdwNzNBYU9KSHAydnNTZ0p6ajFvUHUvL1lnSWNPNStoSGl6bThVcnVGQWxkWmE2ZzN4VnFCazNDZnducApsaU50MzdiblJrZ3VUNUU5cFFNQ0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZNdnpFOXJORVFUWGNyUmJHcllmQ0J6VEpZby9NQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFBMjJZS1htS29kTkVmUklGS1ZOMXk1alRjQ2FIVnAyd3QvR1RNT3dHU1pYQXhlN2xBOQpIZDVCWHJoaXB6bkNPR1hxakRoZkVkaWVIa3VlcDNQWGxVTWxxa20yUGZkdUp0cTJ3T0piR0ZTVWZRR2xpS09MCkJ0eDRwVmd1dC9EQW11ZHNNNFlSeGRTS1R3bkppcjBBbkNnSWprd0gvZzdzekFYTVppMmZkYk9oL3NzcVFlZU4KREYrc01ld0czK2pSaVVqTEM2ck9sb0UySzArVjNhMDlMbmNiYlRCNDBVM0pZR0VvallzVExEdXZPakhuZElkKwpyM0FHMlNXMDRYek8wcHF4VDhlRjlkUE5qVG83SlpIeDc3RUtuNVNYU1YweGRuTTR1eHVBWDBoVExLenFyMlRNCmVJTzlZNGZWeHdCQk9BaFBQVmFTMW5SZy9GMXFIWWNKK20wUgotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg&#x3D;&#x3D;</span><br><span class=\"line\">    server: https:&#x2F;&#x2F;127.0.0.1:34927</span><br><span class=\"line\">  name: kind-test2</span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: kind-kind</span><br><span class=\"line\">    user: kind-kind</span><br><span class=\"line\">  name: kind-kind</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: kind-test2</span><br><span class=\"line\">    user: kind-test2</span><br><span class=\"line\">  name: kind-test2</span><br><span class=\"line\">current-context: kind-test2</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\">users:</span><br><span class=\"line\">- name: kind-kind</span><br><span class=\"line\">  user:</span><br><span class=\"line\">    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lJTHRQZkozeVliVHN3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURFeE1qY3dNRFF5TWpsYUZ3MHlNVEV4TWpjd01EUXlNekZhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXJEaURMOWhSUGduVzNwdlcKQ1pNekVlTG0vRTJuVmlXdG9icTVoZUdrdG1Udi9aWEUydG9uKy96ZWROOThvM3J4ZEdneDNTZDRndjZtSnpQbgpFZ3hTRDcrQnErSmt5WG5oQThPM1RQakN0aHdES1JIZjEzbkI4NDNlbjZ3S3E5K3A1RHB2UFNNSkgyQkJLckkrCjlHWTFvTWp2SnRWSjMyZ1dhTnlJV0hzTkE0QmdPM0RRT2Y2cGN6bXZhbllKZFliYTFpQmpKUEVaRURPNEpFdHIKZWYrTUFHb1diSFlaeDdySWo5eTJoNzdOQi9DV0k1alVSUXp6MWQ0ZlFnV05WR1cyblVXbGlGZjlEWlRVR25CMwpHMHBUTjc5N1U0bUNYdWVBUjFxY25idS9YNjBMb2l6bEpKVWJzcjZYUWFaRmtKS2FzSGx2Tmdydm11cWhnSjZTCmxCWWNIUUlEQVFBQm8wZ3dSakFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0h3WURWUjBqQkJnd0ZvQVVOeUpzNTFWN2ZGSXZnVnpYMTRpOStBalFhdm93RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFBay8xbjJqLzhGdlhISm94V0Q3dUl4WUxTUmlrTjcxWWdOOW1yckVYRjVFUkxBMjI5eEtyT1c1ClV2Tm9nZGlqdWpEbDhoVjRoU1hkY3M0dE9ZNmZYbExkN3JhN25vL054UUtHM1lPdktWM2g0eS9wUEYxMENQL0sKTTFhSnNkY1U2aG8wbnZrL1dQSDB2ckxtNE1jUHpBbFUvazdvd3FiemcybHZQdDBCMTJjZHh4bk44UHp5VU4zZwpQQVBzT3hab1hwQnVpNjkxcEt2a1VDUm1MY0dUTHowT0Y5YXVOaUhRRG1qMG1hSEg2ckI2c0kvQzBuZ08vaCtSCmNsUnBGYk9uQnZRbW1nRjZER0E4cGxUSUM2ZE1JOGtXRzVaQWFSbzMrblFLME5sMERaUDVBTjM1cE1yS0M1R3cKeTdHaVlRQkFCVlJOZ2FJemg1bktHUXFJVVFXRUU5TT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo&#x3D;</span><br><span class=\"line\">    client-key-data: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFb3dJQkFBS0NBUUVBckRpREw5aFJQZ25XM3B2V0NaTXpFZUxtL0UyblZpV3RvYnE1aGVHa3RtVHYvWlhFCjJ0b24rL3plZE45OG8zcnhkR2d4M1NkNGd2Nm1KelBuRWd4U0Q3K0JxK0preVhuaEE4TzNUUGpDdGh3REtSSGYKMTNuQjg0M2VuNndLcTkrcDVEcHZQU01KSDJCQktySSs5R1kxb01qdkp0VkozMmdXYU55SVdIc05BNEJnTzNEUQpPZjZwY3ptdmFuWUpkWWJhMWlCakpQRVpFRE80SkV0cmVmK01BR29XYkhZWng3cklqOXkyaDc3TkIvQ1dJNWpVClJRenoxZDRmUWdXTlZHVzJuVVdsaUZmOURaVFVHbkIzRzBwVE43OTdVNG1DWHVlQVIxcWNuYnUvWDYwTG9pemwKSkpVYnNyNlhRYVpGa0pLYXNIbHZOZ3J2bXVxaGdKNlNsQlljSFFJREFRQUJBb0lCQVFDYlJzUzVVYTlHWVRhegpOUXhSUzcvREE3TEJqdjR1QlFDOURnOFJyL1dEWWhTanJmSjBaRGVpMGtaOFY3Z1g2ZFJqNFVIOEpRZGFER0VnCmZZSjhXbEZ1MDNzRno3U1JsMnNTcXRiTTlva1FDc2Vxc3V3QWFrNDkydzc3SmZIbEwxOE5ZTVpFK0I3VWhFT2QKVEdMSWxwTUpxY0UrWVJZZThNa3J1SkxTTy9mcXk4eW1zWnk5ZHlyOWIvTjJnZm1iYW1kWVpVa3hneFVaVVB6RQpqdDBFZEZ5YThHK29YcUlMakZoR3oyQnBHSFJIVnNJYjlGdEhEbktzTVV5YzNGQXZyTmVjTHYyYmw1a0tjb1pBClY3ay9pMHhiVGpWK0tVSXQ2STlPb09aNkIzNjZkbDJjUHNQQmJtK3pRN3A4a0l0SXdoanpOUVN3QytjVFhVYnIKQ2Yxb3BpYjlBb0dCQU11RlNJVlpjaVk1akNSWlRnd0dEczlybGdsWW9hNFA4TkUyMng5RFdoMVNyS2k2and0VgorcGphM1V3ZTBYRHBWTFIrZXNKZ1NYZlBqSk5WVW5KS0RKeElBTGNHM01qek9RcUlwYjMxMXBoenJsdWo4WGllCi8wQ0ZMU0YyR2N0b1B2cUxPUWFvQjNFcy96UmxzUmVOSlMvUEp0NG9pS29ERmI3d05zbFRYVWRqQW9HQkFOaWgKRXhadG5qd1RRZzBpUHU0SERYUlU0M0hzQ2pWMFh0MENGclY0Q2Qzcjc3ZUsxd2RtSkhVUWczV0VKeUxBREhyVQpIa0EzKzRJdXdmcVE0d0FwZHF6SFF4UUtJbXA2dEpVTElYL2xhNk1RbFltSTREcHFVUWRETi8yN0V4bXAwRkZVCkc1b2FNb1BoOVNLMk0wZ2RkWjJpS3llZ2I5dkJLNWJORzVTdUhTWi9Bb0dCQUsyaVM4b0JFdU5MeTZXalQzUHcKb3lnUmlOTDJmQklONVk0SStBK0hIZFhRbUIvbjhteGdjVW1CeUxYTndUQk0wWWlnTThtcjdtSTZmNXVmZXBTcApXbkxtOXowdnJLUUE1bFIzV3JoamlpOU0ycCt5a2l3dnNtUHdleDJHTGVHZFVjWGRpOHlEQkw1by9sNU11RGI0Cm81WlRiTHl5NWszdURkcDJCTGZrMkxzekFvR0JBTEp6aGdqTXhqUFEzWEY2UzRMRFZvY0ZRdFBlME00V0RldGIKeEI4N1FrMkpCVkVhVTJacDh4Qm9TUkt1aVpxcnY5d1REdFJ5Q1lMRlI5QkVPR3N5dk9zNXZuMHNtQXRGQjZ0YgpudjMvbkxxWWQ4YnpkVnRKcDNRbklHR3BFT1BzS29wRWtmUlJMbG5MOHFia2xyd0tZSkE1UGZtSHhYMnUxRnlHCm0valBzWDI3QW44cStrMXBqRFlMakMzSjlXWkE2a3Blc05yMENaU0RaTjNhZy9LNUxzQTVaekhaclhMQm9EaEYKekJ5ankvVVpUM1RlOXVxM2dTb1pNdnp1TVRRYWVLclFmOFBHQi9sNUVvdDJxSkMza1piR1F5cXNQVG8yT0JSdApnNytzdjE2azRieEZlMkVRVmU4M0NXR0pneEZkKzc1c1NxZGxON1RKZXJVOUdxbnM1dmk1Ci0tLS0tRU5EIFJTQSBQUklWQVRFIEtFWS0tLS0tCg&#x3D;&#x3D;</span><br><span class=\"line\">- name: kind-test2</span><br><span class=\"line\">  user:</span><br><span class=\"line\">    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lJR2toZno1Qy9Yc2d3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURFeE1qY3dNekl5TVRoYUZ3MHlNVEV4TWpjd016SXlNakJhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXJ6azZ2RFJsMjI4V1RndUEKYnNNN0tLVUVaaWRmbVBKVW1kaitmdCs1UTZFSHFvUitzOHVycDVVc0tOY0krZzdoYkNJa2VzdzE4OGZ0NDVlSwp4eGpmV1NiUXNiSjYyb3RQRUVoSGpPZElRTHVxQlBqR1J1N3NwUE8yRzFnMFZTMm9UY0VUVlYzQ2RCUFFPRjNOCm9WblhPdzQwSWttWXVURDZHUEdNT2VwN05Rak4vZERybVphMy94WWxJK2loVHZJbnZXNjVYYmd0NTNwS203YXgKOUNSVGhjNUtONjg2TzVLekR6ZnhPZGtpUUhJdzNXL3BpTXRvOVV5QUF3V2RoUmc0K0VacW5OTjZXREl4RlNPNQpJN0Z6c3dtT2s0L29wcW55ZHhmNnFYamF6MGlvTTNyM0I4bUY0c09VakhtaDJyUnB3a3ZpQUxkV3AvbVo0ek5uClJYYVp3UUlEQVFBQm8wZ3dSakFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0h3WURWUjBqQkJnd0ZvQVV5L01UMnMwUkJOZHl0RnNhdGg4SUhOTWxpajh3RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFIMHg2am5uajNSQWxBY0dOZmxyY1Zob01XVUpOZCtVak5OSXNSTHRaSzJTYTh6SThCK0VIeUxFCndhRjJGMzZ0VTV6L1JiSFluK3d3Q3ByQVJjLzhYTUx2OEpnMVU2aDg2SkxpNm9qc29Vb0dhUFNoWmI3S1YyOUQKSE5JQ2p5M2QrenhjdEV4OWFTRDB3WkR0cFpVaS9tZlQ3MklRekVUazQ2QTQ4bldYdkx0MWJ6TEZ4T1hQZVB1WgpiZG1lcWR5QmN1TXI0MUppcEJVUlpOWDgxQ0xIQ1ZQU2tsRHkySVl0OUgxeVNmb3RHMUV4ZHlDZE1vRjZTVUdhCkpLY0psNGFSQ3JNLzNqSGx3YVpGcWR0WkFFZ2pzM3lOYXllTW9SYi93bEdpWkdaQTFhQ3JNZlU5bXRnTlMrMWIKbmE1M0RxVmRKZHBTSnhWSjNPQXpUY2s0OVV1Z2c4ND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo&#x3D;</span><br><span class=\"line\">    client-key-data: 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&#x3D;&#x3D;</span><br></pre></td></tr></table></figure>\n<p>可以看到两个cluster，两个context。context指定了cluster及user，users字段列出了两个user</p>\n<p>context名为kind-kind，cluser为kind-kind，user为kind-kind，意思就是当指定–context为kind-kind时，将使用kind-kind的user去访问cluster为kind-kind的集群。</p>\n<p>current-context: kind-test2说明当前的context使用的是kind-test2，如果不指定–context，将默认使用kind-test2</p>\n<p>当然，用户可以修改当然默认的current-context</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl get node</span><br><span class=\"line\">NAME                   STATUS   ROLES    AGE     VERSION</span><br><span class=\"line\">test2-control-plane    Ready    master   2d23h   v1.19.1</span><br><span class=\"line\">test2-control-plane2   Ready    master   2d23h   v1.19.1</span><br><span class=\"line\">test2-control-plane3   Ready    master   2d23h   v1.19.1</span><br><span class=\"line\">test2-worker           Ready    &lt;none&gt;   2d23h   v1.19.1</span><br><span class=\"line\">test2-worker2          Ready    &lt;none&gt;   2d23h   v1.19.1</span><br><span class=\"line\">test2-worker3          Ready    &lt;none&gt;   2d23h   v1.19.1</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl config</span><br><span class=\"line\">Modify kubeconfig files using subcommands like &quot;kubectl config set current-context my-context&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"> The loading order follows these rules:</span><br><span class=\"line\"></span><br><span class=\"line\">  1.  If the --kubeconfig flag is set, then only that file is loaded. The flag may only be set once and no merging takes</span><br><span class=\"line\">place.</span><br><span class=\"line\">  2.  If $KUBECONFIG environment variable is set, then it is used as a list of paths (normal path delimiting rules for</span><br><span class=\"line\">your system). These paths are merged. When a value is modified, it is modified in the file that defines the stanza. When</span><br><span class=\"line\">a value is created, it is created in the first file that exists. If no files in the chain exist, then it creates the</span><br><span class=\"line\">last file in the list.</span><br><span class=\"line\">  3.  Otherwise, $&#123;HOME&#125;&#x2F;.kube&#x2F;config is used and no merging takes place.</span><br><span class=\"line\"></span><br><span class=\"line\">Available Commands:</span><br><span class=\"line\">  current-context Displays the current-context</span><br><span class=\"line\">  delete-cluster  Delete the specified cluster from the kubeconfig</span><br><span class=\"line\">  delete-context  Delete the specified context from the kubeconfig</span><br><span class=\"line\">  get-clusters    Display clusters defined in the kubeconfig</span><br><span class=\"line\">  get-contexts    Describe one or many contexts</span><br><span class=\"line\">  rename-context  Renames a context from the kubeconfig file.</span><br><span class=\"line\">  set             Sets an individual value in a kubeconfig file</span><br><span class=\"line\">  set-cluster     Sets a cluster entry in kubeconfig</span><br><span class=\"line\">  set-context     Sets a context entry in kubeconfig</span><br><span class=\"line\">  set-credentials Sets a user entry in kubeconfig</span><br><span class=\"line\">  unset           Unsets an individual value in a kubeconfig file</span><br><span class=\"line\">  use-context     Sets the current-context in a kubeconfig file</span><br><span class=\"line\">  view            Display merged kubeconfig settings or a specified kubeconfig file</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">  kubectl config SUBCOMMAND [options]</span><br><span class=\"line\"></span><br><span class=\"line\">Use &quot;kubectl &lt;command&gt; --help&quot; for more information about a given command.</span><br><span class=\"line\">Use &quot;kubectl options&quot; for a list of global command-line options (applies to all commands).</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl config use-context</span><br><span class=\"line\">Sets the current-context in a kubeconfig file</span><br><span class=\"line\"></span><br><span class=\"line\">Aliases:</span><br><span class=\"line\">use-context, use</span><br><span class=\"line\"></span><br><span class=\"line\">Examples:</span><br><span class=\"line\">  # Use the context for the minikube cluster</span><br><span class=\"line\">  kubectl config use-context minikube</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">  kubectl config use-context CONTEXT_NAME [options]</span><br><span class=\"line\"></span><br><span class=\"line\">Use &quot;kubectl options&quot; for a list of global command-line options (applies to all commands).</span><br><span class=\"line\">error: Unexpected args: []</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl config use-context kind-kind</span><br><span class=\"line\">Switched to context &quot;kind-kind&quot;.</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get node</span><br><span class=\"line\">NAME                 STATUS   ROLES    AGE    VERSION</span><br><span class=\"line\">kind-control-plane   Ready    master   3d1h   v1.19.1</span><br></pre></td></tr></table></figure>\n<p>实际上，kind内部创建集群过程中，也是使用kubeadm，从上述创建过程中的打印也似乎能猜到这一点</p>\n<p>后面，就可以使用搭建好的集群环境，开始你的开发、测试工作了~~~</p>\n","site":{"data":{}},"excerpt":"什么是kind\nkind：Kubernetes In Docker，顾名思义，就是将kubernetes所需要的所有组件，全部部署在一个docker容器中，是一套开箱即用的kubernetes环境搭建方案。使用kind搭建的集群无法在生产中使用，但是如果你只是想在本地测试或者开发使用，不想占用太多的资源，那么使用kind是不错的选择。同样，kind还可以很方便的帮你本地的kubernetes源代码打成对应的镜像，方便测试。\n\nGitHub: https://github.com/kubernetes-sigs/kind\n\nDocumentation: https://kind.sigs.k8s","more":"<h1 id=\"什么是kind\"><a href=\"#什么是kind\" class=\"headerlink\" title=\"什么是kind\"></a>什么是kind</h1><p>kind：Kubernetes In Docker，顾名思义，就是将kubernetes所需要的所有组件，全部部署在一个docker容器中，是一套开箱即用的kubernetes环境搭建方案。使用kind搭建的集群无法在生产中使用，但是如果你只是想在本地测试或者开发使用，不想占用太多的资源，那么使用kind是不错的选择。同样，kind还可以很方便的帮你本地的kubernetes源代码打成对应的镜像，方便测试。</p>\n<p>GitHub: <a href=\"https://github.com/kubernetes-sigs/kind\">https://github.com/kubernetes-sigs/kind</a></p>\n<p>Documentation: <a href=\"https://kind.sigs.k8s.io/\">https://kind.sigs.k8s.io/</a></p>\n<h1 id=\"安装kind\"><a href=\"#安装kind\" class=\"headerlink\" title=\"安装kind\"></a>安装kind</h1><p>以Linux下安装为例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -Lo .&#x2F;kind https:&#x2F;&#x2F;kind.sigs.k8s.io&#x2F;dl&#x2F;v0.9.0&#x2F;kind-linux-amd64</span><br><span class=\"line\">chmod +x .&#x2F;kind</span><br><span class=\"line\">mv .&#x2F;kind &#x2F;usr&#x2F;local&#x2F;bin&#x2F;kind</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"创建、查询集群\"><a href=\"#创建、查询集群\" class=\"headerlink\" title=\"创建、查询集群\"></a>创建、查询集群</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind create cluster</span><br></pre></td></tr></table></figure>\n<p>该命令将默认创建名为kind的集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kind create cluster</span><br><span class=\"line\">Creating cluster &quot;kind&quot; ...</span><br><span class=\"line\"> ✓ Ensuring node image (kindest&#x2F;node:v1.19.1) 🖼</span><br><span class=\"line\"> ✓ Preparing nodes 📦</span><br><span class=\"line\"> ✓ Writing configuration 📜</span><br><span class=\"line\"> ✓ Starting control-plane 🕹️</span><br><span class=\"line\"> ✓ Installing CNI 🔌</span><br><span class=\"line\"> ✓ Installing StorageClass 💾</span><br><span class=\"line\">Set kubectl context to &quot;kind-kind&quot;</span><br><span class=\"line\">You can now use your cluster with:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl cluster-info --context kind-kind</span><br><span class=\"line\"></span><br><span class=\"line\">Have a question, bug, or feature request? Let us know! https:&#x2F;&#x2F;kind.sigs.k8s.io&#x2F;#community 🙂</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kind get clusters</span><br><span class=\"line\">kind</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind create cluster --name test</span><br></pre></td></tr></table></figure>\n<p>该命令将创建名为test的集群</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kind create cluster --name test</span><br><span class=\"line\">Creating cluster &quot;test&quot; ...</span><br><span class=\"line\"> ✓ Ensuring node image (kindest&#x2F;node:v1.19.1) 🖼</span><br><span class=\"line\"> ✓ Preparing nodes 📦</span><br><span class=\"line\"> ✓ Writing configuration 📜</span><br><span class=\"line\"> ✓ Starting control-plane 🕹️</span><br><span class=\"line\"> ✓ Installing CNI 🔌</span><br><span class=\"line\"> ✓ Installing StorageClass 💾</span><br><span class=\"line\">Set kubectl context to &quot;kind-test&quot;</span><br><span class=\"line\">You can now use your cluster with:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl cluster-info --context kind-test</span><br><span class=\"line\"></span><br><span class=\"line\">Thanks for using kind! 😊</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kind get clusters</span><br><span class=\"line\">kind</span><br><span class=\"line\">test</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl cluster-info --context kind-test</span><br><span class=\"line\">Kubernetes master is running at https:&#x2F;&#x2F;127.0.0.1:44543</span><br><span class=\"line\">KubeDNS is running at https:&#x2F;&#x2F;127.0.0.1:44543&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-system&#x2F;services&#x2F;kube-dns:dns&#x2F;proxy</span><br><span class=\"line\"></span><br><span class=\"line\">To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.</span><br></pre></td></tr></table></figure>\n\n<p>kubectl安装：<a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>\n<p>查询集群节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl get nodes --context kind-test</span><br><span class=\"line\">NAME                 STATUS   ROLES    AGE     VERSION</span><br><span class=\"line\">test-control-plane   Ready    master   4m55s   v1.19.1</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get nodes --context kind-kind</span><br><span class=\"line\">NAME                 STATUS   ROLES    AGE     VERSION</span><br><span class=\"line\">kind-control-plane   Ready    master   9m14s   v1.19.1</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES</span><br><span class=\"line\">7fa7f8313453        kindest&#x2F;node:v1.19.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;entr…&quot;   16 minutes ago      Up 16 minutes       127.0.0.1:44543-&gt;6443&#x2F;tcp   test-control-plane</span><br><span class=\"line\">6fee527273e2        kindest&#x2F;node:v1.19.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;entr…&quot;   20 minutes ago      Up 20 minutes       127.0.0.1:36585-&gt;6443&#x2F;tcp   kind-control-plane</span><br><span class=\"line\">root@ubuntu:~# docker ps -a</span><br><span class=\"line\">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES</span><br><span class=\"line\">7fa7f8313453        kindest&#x2F;node:v1.19.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;entr…&quot;   16 minutes ago      Up 16 minutes       127.0.0.1:44543-&gt;6443&#x2F;tcp   test-control-plane</span><br><span class=\"line\">6fee527273e2        kindest&#x2F;node:v1.19.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;entr…&quot;   20 minutes ago      Up 20 minutes       127.0.0.1:36585-&gt;6443&#x2F;tcp   kind-control-plane</span><br></pre></td></tr></table></figure>\n<p>test-control-plane、kind-control-plane是运行在容器内的kubernetes节点，也正是kubernetes in Docker的意思</p>\n<p>查询集群内运行的pod</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl get pods --all-namespaces --context kind-kind</span><br><span class=\"line\">NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-cqpss                      1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-kvbzm                      1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          etcd-kind-control-plane                      1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kindnet-br2qc                                1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kube-apiserver-kind-control-plane            1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kube-controller-manager-kind-control-plane   1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kube-proxy-4chlm                             1&#x2F;1     Running   0          22m</span><br><span class=\"line\">kube-system          kube-scheduler-kind-control-plane            1&#x2F;1     Running   0          22m</span><br><span class=\"line\">local-path-storage   local-path-provisioner-78776bfc44-xl4ht      1&#x2F;1     Running   0          22m</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get pods --all-namespaces --context kind-test</span><br><span class=\"line\">NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-f7wsz                      1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-j9xtx                      1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          etcd-test-control-plane                      1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kindnet-jq867                                1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kube-apiserver-test-control-plane            1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kube-controller-manager-test-control-plane   1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kube-proxy-swn5j                             1&#x2F;1     Running   0          18m</span><br><span class=\"line\">kube-system          kube-scheduler-test-control-plane            1&#x2F;1     Running   0          18m</span><br><span class=\"line\">local-path-storage   local-path-provisioner-78776bfc44-nwqjq      1&#x2F;1     Running   0          18m</span><br></pre></td></tr></table></figure>\n\n<p>查询pod使用的镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# docker exec -it kind-control-plane crictl images</span><br><span class=\"line\">IMAGE                                      TAG                  IMAGE ID            SIZE</span><br><span class=\"line\">docker.io&#x2F;kindest&#x2F;kindnetd                 v20200725-4d6bea59   b77790820d015       119MB</span><br><span class=\"line\">docker.io&#x2F;rancher&#x2F;local-path-provisioner   v0.0.14              e422121c9c5f9       42MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;build-image&#x2F;debian-base         v2.1.0               c7c6c86897b63       53.9MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;coredns                         1.7.0                bfe3a36ebd252       45.4MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;etcd                            3.4.13-0             0369cf4303ffd       255MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;kube-apiserver                  v1.19.1              8cba89a89aaa8       95MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;kube-controller-manager         v1.19.1              7dafbafe72c90       84.1MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;kube-proxy                      v1.19.1              47e289e332426       136MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;kube-scheduler                  v1.19.1              4d648fc900179       65.1MB</span><br><span class=\"line\">k8s.gcr.io&#x2F;pause                           3.3                  0184c1613d929       686kB</span><br><span class=\"line\">root@ubuntu:~# docker exec -it kind-control-plane crictl ps</span><br><span class=\"line\">CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID</span><br><span class=\"line\">1c881f7f0d306       bfe3a36ebd252       25 minutes ago      Running             coredns                   0                   75e161b37ab2d</span><br><span class=\"line\">c64dd6bb666f3       bfe3a36ebd252       25 minutes ago      Running             coredns                   0                   a8305dc572af5</span><br><span class=\"line\">fea2b69f5472d       e422121c9c5f9       26 minutes ago      Running             local-path-provisioner    0                   fb704b6340b63</span><br><span class=\"line\">52f0995ba00f8       47e289e332426       26 minutes ago      Running             kube-proxy                0                   4c787e616d5a7</span><br><span class=\"line\">b87cdcc514f59       b77790820d015       26 minutes ago      Running             kindnet-cni               0                   14eb70f9ca549</span><br><span class=\"line\">ce2c4e5b2b57f       0369cf4303ffd       27 minutes ago      Running             etcd                      0                   744a99a558714</span><br><span class=\"line\">93b5084a29992       8cba89a89aaa8       27 minutes ago      Running             kube-apiserver            0                   91f88afc5a39b</span><br><span class=\"line\">8b9579313058f       7dafbafe72c90       27 minutes ago      Running             kube-controller-manager   0                   8d54fdffef86e</span><br><span class=\"line\">10fbb8244ad3b       4d648fc900179       27 minutes ago      Running             kube-scheduler            0                   a985ae4a105bc</span><br></pre></td></tr></table></figure>\n<p>其中，crictl命令可以理解为docker命令</p>\n<h1 id=\"删除集群\"><a href=\"#删除集群\" class=\"headerlink\" title=\"删除集群\"></a>删除集群</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kind delete cluster --name test</span><br></pre></td></tr></table></figure>\n<p>删除名为test的集群，–name未指定的话，将默认删除kind集群</p>\n<h1 id=\"创建高可用kubernetes集群\"><a href=\"#创建高可用kubernetes集群\" class=\"headerlink\" title=\"创建高可用kubernetes集群\"></a>创建高可用kubernetes集群</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# cat kind-config.yaml</span><br><span class=\"line\">kind: Cluster</span><br><span class=\"line\">apiVersion: kind.x-k8s.io&#x2F;v1alpha4</span><br><span class=\"line\">nodes:</span><br><span class=\"line\">- role: control-plane</span><br><span class=\"line\">- role: control-plane</span><br><span class=\"line\">- role: control-plane</span><br><span class=\"line\">- role: worker</span><br><span class=\"line\">- role: worker</span><br><span class=\"line\">- role: worker</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kind create cluster --config kind-config.yaml --name test2</span><br><span class=\"line\">Creating cluster &quot;test2&quot; ...</span><br><span class=\"line\"> ✓ Ensuring node image (kindest&#x2F;node:v1.19.1) 🖼</span><br><span class=\"line\"> ✓ Preparing nodes 📦 📦 📦 📦 📦 📦</span><br><span class=\"line\"> ✓ Configuring the external load balancer ⚖️</span><br><span class=\"line\"> ✓ Writing configuration 📜</span><br><span class=\"line\"> ✓ Starting control-plane 🕹️</span><br><span class=\"line\"> ✓ Installing CNI 🔌</span><br><span class=\"line\"> ✓ Installing StorageClass 💾</span><br><span class=\"line\"> ✓ Joining more control-plane nodes 🎮</span><br><span class=\"line\"> ✓ Joining worker nodes 🚜</span><br><span class=\"line\">Set kubectl context to &quot;kind-test2&quot;</span><br><span class=\"line\">You can now use your cluster with:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl cluster-info --context kind-test2</span><br><span class=\"line\"></span><br><span class=\"line\">Have a nice day! 👋</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get nodes --context kind-test2</span><br><span class=\"line\">NAME                   STATUS   ROLES    AGE     VERSION</span><br><span class=\"line\">test2-control-plane    Ready    master   5m12s   v1.19.1</span><br><span class=\"line\">test2-control-plane2   Ready    master   4m38s   v1.19.1</span><br><span class=\"line\">test2-control-plane3   Ready    master   3m22s   v1.19.1</span><br><span class=\"line\">test2-worker           Ready    &lt;none&gt;   2m5s    v1.19.1</span><br><span class=\"line\">test2-worker2          Ready    &lt;none&gt;   2m5s    v1.19.1</span><br><span class=\"line\">test2-worker3          Ready    &lt;none&gt;   2m5s    v1.19.1</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get pods --all-namespaces --context kind-test2</span><br><span class=\"line\">NAMESPACE            NAME                                           READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-jbpcz                        1&#x2F;1     Running   0          5m16s</span><br><span class=\"line\">kube-system          coredns-f9fd979d6-ng4qp                        1&#x2F;1     Running   0          5m16s</span><br><span class=\"line\">kube-system          etcd-test2-control-plane                       1&#x2F;1     Running   0          5m15s</span><br><span class=\"line\">kube-system          etcd-test2-control-plane2                      1&#x2F;1     Running   0          4m54s</span><br><span class=\"line\">kube-system          etcd-test2-control-plane3                      1&#x2F;1     Running   0          2m59s</span><br><span class=\"line\">kube-system          kindnet-gxpjn                                  1&#x2F;1     Running   0          4m55s</span><br><span class=\"line\">kube-system          kindnet-jqnx5                                  1&#x2F;1     Running   0          2m20s</span><br><span class=\"line\">kube-system          kindnet-lczmx                                  1&#x2F;1     Running   0          2m18s</span><br><span class=\"line\">kube-system          kindnet-q8bcn                                  1&#x2F;1     Running   0          2m19s</span><br><span class=\"line\">kube-system          kindnet-q9ng2                                  1&#x2F;1     Running   0          3m37s</span><br><span class=\"line\">kube-system          kindnet-s7kfb                                  1&#x2F;1     Running   0          5m14s</span><br><span class=\"line\">kube-system          kube-apiserver-test2-control-plane             1&#x2F;1     Running   0          5m15s</span><br><span class=\"line\">kube-system          kube-apiserver-test2-control-plane2            1&#x2F;1     Running   0          4m54s</span><br><span class=\"line\">kube-system          kube-apiserver-test2-control-plane3            1&#x2F;1     Running   1          3m9s</span><br><span class=\"line\">kube-system          kube-controller-manager-test2-control-plane    1&#x2F;1     Running   2          5m14s</span><br><span class=\"line\">kube-system          kube-controller-manager-test2-control-plane2   1&#x2F;1     Running   0          4m54s</span><br><span class=\"line\">kube-system          kube-controller-manager-test2-control-plane3   1&#x2F;1     Running   0          2m8s</span><br><span class=\"line\">kube-system          kube-proxy-47nc7                               1&#x2F;1     Running   0          5m16s</span><br><span class=\"line\">kube-system          kube-proxy-5799m                               1&#x2F;1     Running   0          4m55s</span><br><span class=\"line\">kube-system          kube-proxy-cvm49                               1&#x2F;1     Running   0          2m18s</span><br><span class=\"line\">kube-system          kube-proxy-s7rsp                               1&#x2F;1     Running   0          2m18s</span><br><span class=\"line\">kube-system          kube-proxy-sxwgl                               1&#x2F;1     Running   0          3m37s</span><br><span class=\"line\">kube-system          kube-proxy-wvskh                               1&#x2F;1     Running   0          2m20s</span><br><span class=\"line\">kube-system          kube-scheduler-test2-control-plane             0&#x2F;1     Running   2          5m15s</span><br><span class=\"line\">kube-system          kube-scheduler-test2-control-plane2            1&#x2F;1     Running   0          4m54s</span><br><span class=\"line\">kube-system          kube-scheduler-test2-control-plane3            1&#x2F;1     Running   0          2m31s</span><br><span class=\"line\">local-path-storage   local-path-provisioner-78776bfc44-fkdwq        1&#x2F;1     Running   1          5m12s</span><br></pre></td></tr></table></figure>\n\n<p>上述过程，我们创建了两个kubernetes集群，kind和test2；可以看到我们在使用kubectl访问集群时，增加了参数：–context，这在本地的配置文件里指定了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# cat .kube&#x2F;config</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01URXlOekF3TkRJeU9Wb1hEVE13TVRFeU5UQXdOREl5T1Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTERTCm5TU1NHS05PUUlCVWpQeXpYOFRDZm5IamExV2JxeXZJeHV3Y1Aybmh6Zi9EdG9wVDRnSTVjMlBMV3Qrd05BUFUKUHA2dGV3ZkhNQ3N6MnJLbnhaRmtWS2c5NXVFdW53V1ZuZnlmeGV0TjlOU1JTZ2s2dkJuVUt6SFliRXIybEY0LwpicFVxT2IzWnkxQXdYNlpyRTN3Y1I1RjdLV2trT0FZbHdobUtiLzIwOVZJRG4yMW9CMHMzNXgrM3Z2L2gzQ3VaCkJCQjJnNVBKMm4xc1pwd05scnZDMmh0RmJDSjQwQVNXZmNsUksyejBYUEIvdzdNQlBXMHp1cnpEMUVBcGdZVUcKUGUwOEx3dW1zMllZR3Y5TDJXMERhWW90c2JoVXlWZWRDNnpjeWtUZ0hOb1B6LytvZlBHQmxYTko3S2lwd2Z6ZQo2dzdHZGJhbjlpRms4cjAyaVQ4Q0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZEY2liT2RWZTN4U0w0RmMxOWVJdmZnSTBHcjZNQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFCS1lKSVFaenhSblFWWWp4TnlTaXJualFvZUM3OGtDMERNYjZpRFBvMFdEbmdTUjhRYgpqRjZxR2ZPMTFTcDNjeVl3V1IrM3UzU2pzQUJUUG5jcWZpWnEyN3VDMlRYNjdMQzRPNVFoVkdlRlBDdXJNNHluCi8weDZuOUZrMko5YmpTT0o1aDB2NmQ1eXBibk5sNVgvN1czWFVyK2tjOSswWG1sMFN0dmJVZ0hCaWVmWGxtZ3AKUXl5TlFtNU1yWlRFcWJOT0JubW1RWUJYWDdydWVLZXhVYUJ4QXQrRVJVWHBVOWNhbkNWWWhuZFBuMVNBYVladApsQkZyamRSNzg1SE1EV21qTW5UalJXSUhOSWd2NUgwKyt2MmN5cjRSK1lUWGo3S0JrdEZTRDA2U0I0RDZVeFk2CmRUZ25UMngzRXJvSERPZURjWWRrVmt2TkF5aC9JUGFTd2R6cwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg&#x3D;&#x3D;</span><br><span class=\"line\">    server: https:&#x2F;&#x2F;127.0.0.1:36585</span><br><span class=\"line\">  name: kind-kind</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01URXlOekF6TWpJeE9Gb1hEVE13TVRFeU5UQXpNakl4T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBSi85CjlZQ0VseTNRLzRuc2t5dGZZY2Zpby9jcDJoaSsxRWpPOGMrVmF4YTkrbTIrdldBT1VhU0xQZnQ0VmRSL1hIWjYKT3FQSEY5K3ozNEZIb1p4RTJIY3kxd3R0Y1hOTXk1Qy9VMUdnakgramZLaWNmbVJmS3luS1M4SU80T3pLRHBKUQpodHQzb0JxeDVHdU0wSUpkVmsydVg5RjhmVHEyTllaN2lzK0NOVWdXM2dxMXA4SzNkZWxjaDYyM2NBSHhSS0JLCmZEZC9iZnZiZitvR0ZQS29BNWhLcXVKb3BDVFcrN1VZdnA4ZCs0QTgwYkZ2cG5CSmlUK1pGU0sxRExKZHBuRlgKV0pDOHdwNzNBYU9KSHAydnNTZ0p6ajFvUHUvL1lnSWNPNStoSGl6bThVcnVGQWxkWmE2ZzN4VnFCazNDZnducApsaU50MzdiblJrZ3VUNUU5cFFNQ0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZNdnpFOXJORVFUWGNyUmJHcllmQ0J6VEpZby9NQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFBMjJZS1htS29kTkVmUklGS1ZOMXk1alRjQ2FIVnAyd3QvR1RNT3dHU1pYQXhlN2xBOQpIZDVCWHJoaXB6bkNPR1hxakRoZkVkaWVIa3VlcDNQWGxVTWxxa20yUGZkdUp0cTJ3T0piR0ZTVWZRR2xpS09MCkJ0eDRwVmd1dC9EQW11ZHNNNFlSeGRTS1R3bkppcjBBbkNnSWprd0gvZzdzekFYTVppMmZkYk9oL3NzcVFlZU4KREYrc01ld0czK2pSaVVqTEM2ck9sb0UySzArVjNhMDlMbmNiYlRCNDBVM0pZR0VvallzVExEdXZPakhuZElkKwpyM0FHMlNXMDRYek8wcHF4VDhlRjlkUE5qVG83SlpIeDc3RUtuNVNYU1YweGRuTTR1eHVBWDBoVExLenFyMlRNCmVJTzlZNGZWeHdCQk9BaFBQVmFTMW5SZy9GMXFIWWNKK20wUgotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg&#x3D;&#x3D;</span><br><span class=\"line\">    server: https:&#x2F;&#x2F;127.0.0.1:34927</span><br><span class=\"line\">  name: kind-test2</span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: kind-kind</span><br><span class=\"line\">    user: kind-kind</span><br><span class=\"line\">  name: kind-kind</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: kind-test2</span><br><span class=\"line\">    user: kind-test2</span><br><span class=\"line\">  name: kind-test2</span><br><span class=\"line\">current-context: kind-test2</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\">users:</span><br><span class=\"line\">- name: kind-kind</span><br><span class=\"line\">  user:</span><br><span class=\"line\">    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lJTHRQZkozeVliVHN3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURFeE1qY3dNRFF5TWpsYUZ3MHlNVEV4TWpjd01EUXlNekZhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXJEaURMOWhSUGduVzNwdlcKQ1pNekVlTG0vRTJuVmlXdG9icTVoZUdrdG1Udi9aWEUydG9uKy96ZWROOThvM3J4ZEdneDNTZDRndjZtSnpQbgpFZ3hTRDcrQnErSmt5WG5oQThPM1RQakN0aHdES1JIZjEzbkI4NDNlbjZ3S3E5K3A1RHB2UFNNSkgyQkJLckkrCjlHWTFvTWp2SnRWSjMyZ1dhTnlJV0hzTkE0QmdPM0RRT2Y2cGN6bXZhbllKZFliYTFpQmpKUEVaRURPNEpFdHIKZWYrTUFHb1diSFlaeDdySWo5eTJoNzdOQi9DV0k1alVSUXp6MWQ0ZlFnV05WR1cyblVXbGlGZjlEWlRVR25CMwpHMHBUTjc5N1U0bUNYdWVBUjFxY25idS9YNjBMb2l6bEpKVWJzcjZYUWFaRmtKS2FzSGx2Tmdydm11cWhnSjZTCmxCWWNIUUlEQVFBQm8wZ3dSakFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0h3WURWUjBqQkJnd0ZvQVVOeUpzNTFWN2ZGSXZnVnpYMTRpOStBalFhdm93RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFBay8xbjJqLzhGdlhISm94V0Q3dUl4WUxTUmlrTjcxWWdOOW1yckVYRjVFUkxBMjI5eEtyT1c1ClV2Tm9nZGlqdWpEbDhoVjRoU1hkY3M0dE9ZNmZYbExkN3JhN25vL054UUtHM1lPdktWM2g0eS9wUEYxMENQL0sKTTFhSnNkY1U2aG8wbnZrL1dQSDB2ckxtNE1jUHpBbFUvazdvd3FiemcybHZQdDBCMTJjZHh4bk44UHp5VU4zZwpQQVBzT3hab1hwQnVpNjkxcEt2a1VDUm1MY0dUTHowT0Y5YXVOaUhRRG1qMG1hSEg2ckI2c0kvQzBuZ08vaCtSCmNsUnBGYk9uQnZRbW1nRjZER0E4cGxUSUM2ZE1JOGtXRzVaQWFSbzMrblFLME5sMERaUDVBTjM1cE1yS0M1R3cKeTdHaVlRQkFCVlJOZ2FJemg1bktHUXFJVVFXRUU5TT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo&#x3D;</span><br><span class=\"line\">    client-key-data: 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&#x3D;&#x3D;</span><br><span class=\"line\">- name: kind-test2</span><br><span class=\"line\">  user:</span><br><span class=\"line\">    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lJR2toZno1Qy9Yc2d3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURFeE1qY3dNekl5TVRoYUZ3MHlNVEV4TWpjd016SXlNakJhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXJ6azZ2RFJsMjI4V1RndUEKYnNNN0tLVUVaaWRmbVBKVW1kaitmdCs1UTZFSHFvUitzOHVycDVVc0tOY0krZzdoYkNJa2VzdzE4OGZ0NDVlSwp4eGpmV1NiUXNiSjYyb3RQRUVoSGpPZElRTHVxQlBqR1J1N3NwUE8yRzFnMFZTMm9UY0VUVlYzQ2RCUFFPRjNOCm9WblhPdzQwSWttWXVURDZHUEdNT2VwN05Rak4vZERybVphMy94WWxJK2loVHZJbnZXNjVYYmd0NTNwS203YXgKOUNSVGhjNUtONjg2TzVLekR6ZnhPZGtpUUhJdzNXL3BpTXRvOVV5QUF3V2RoUmc0K0VacW5OTjZXREl4RlNPNQpJN0Z6c3dtT2s0L29wcW55ZHhmNnFYamF6MGlvTTNyM0I4bUY0c09VakhtaDJyUnB3a3ZpQUxkV3AvbVo0ek5uClJYYVp3UUlEQVFBQm8wZ3dSakFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0h3WURWUjBqQkJnd0ZvQVV5L01UMnMwUkJOZHl0RnNhdGg4SUhOTWxpajh3RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFIMHg2am5uajNSQWxBY0dOZmxyY1Zob01XVUpOZCtVak5OSXNSTHRaSzJTYTh6SThCK0VIeUxFCndhRjJGMzZ0VTV6L1JiSFluK3d3Q3ByQVJjLzhYTUx2OEpnMVU2aDg2SkxpNm9qc29Vb0dhUFNoWmI3S1YyOUQKSE5JQ2p5M2QrenhjdEV4OWFTRDB3WkR0cFpVaS9tZlQ3MklRekVUazQ2QTQ4bldYdkx0MWJ6TEZ4T1hQZVB1WgpiZG1lcWR5QmN1TXI0MUppcEJVUlpOWDgxQ0xIQ1ZQU2tsRHkySVl0OUgxeVNmb3RHMUV4ZHlDZE1vRjZTVUdhCkpLY0psNGFSQ3JNLzNqSGx3YVpGcWR0WkFFZ2pzM3lOYXllTW9SYi93bEdpWkdaQTFhQ3JNZlU5bXRnTlMrMWIKbmE1M0RxVmRKZHBTSnhWSjNPQXpUY2s0OVV1Z2c4ND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo&#x3D;</span><br><span class=\"line\">    client-key-data: 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&#x3D;&#x3D;</span><br></pre></td></tr></table></figure>\n<p>可以看到两个cluster，两个context。context指定了cluster及user，users字段列出了两个user</p>\n<p>context名为kind-kind，cluser为kind-kind，user为kind-kind，意思就是当指定–context为kind-kind时，将使用kind-kind的user去访问cluster为kind-kind的集群。</p>\n<p>current-context: kind-test2说明当前的context使用的是kind-test2，如果不指定–context，将默认使用kind-test2</p>\n<p>当然，用户可以修改当然默认的current-context</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@ubuntu:~# kubectl get node</span><br><span class=\"line\">NAME                   STATUS   ROLES    AGE     VERSION</span><br><span class=\"line\">test2-control-plane    Ready    master   2d23h   v1.19.1</span><br><span class=\"line\">test2-control-plane2   Ready    master   2d23h   v1.19.1</span><br><span class=\"line\">test2-control-plane3   Ready    master   2d23h   v1.19.1</span><br><span class=\"line\">test2-worker           Ready    &lt;none&gt;   2d23h   v1.19.1</span><br><span class=\"line\">test2-worker2          Ready    &lt;none&gt;   2d23h   v1.19.1</span><br><span class=\"line\">test2-worker3          Ready    &lt;none&gt;   2d23h   v1.19.1</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl config</span><br><span class=\"line\">Modify kubeconfig files using subcommands like &quot;kubectl config set current-context my-context&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"> The loading order follows these rules:</span><br><span class=\"line\"></span><br><span class=\"line\">  1.  If the --kubeconfig flag is set, then only that file is loaded. The flag may only be set once and no merging takes</span><br><span class=\"line\">place.</span><br><span class=\"line\">  2.  If $KUBECONFIG environment variable is set, then it is used as a list of paths (normal path delimiting rules for</span><br><span class=\"line\">your system). These paths are merged. When a value is modified, it is modified in the file that defines the stanza. When</span><br><span class=\"line\">a value is created, it is created in the first file that exists. If no files in the chain exist, then it creates the</span><br><span class=\"line\">last file in the list.</span><br><span class=\"line\">  3.  Otherwise, $&#123;HOME&#125;&#x2F;.kube&#x2F;config is used and no merging takes place.</span><br><span class=\"line\"></span><br><span class=\"line\">Available Commands:</span><br><span class=\"line\">  current-context Displays the current-context</span><br><span class=\"line\">  delete-cluster  Delete the specified cluster from the kubeconfig</span><br><span class=\"line\">  delete-context  Delete the specified context from the kubeconfig</span><br><span class=\"line\">  get-clusters    Display clusters defined in the kubeconfig</span><br><span class=\"line\">  get-contexts    Describe one or many contexts</span><br><span class=\"line\">  rename-context  Renames a context from the kubeconfig file.</span><br><span class=\"line\">  set             Sets an individual value in a kubeconfig file</span><br><span class=\"line\">  set-cluster     Sets a cluster entry in kubeconfig</span><br><span class=\"line\">  set-context     Sets a context entry in kubeconfig</span><br><span class=\"line\">  set-credentials Sets a user entry in kubeconfig</span><br><span class=\"line\">  unset           Unsets an individual value in a kubeconfig file</span><br><span class=\"line\">  use-context     Sets the current-context in a kubeconfig file</span><br><span class=\"line\">  view            Display merged kubeconfig settings or a specified kubeconfig file</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">  kubectl config SUBCOMMAND [options]</span><br><span class=\"line\"></span><br><span class=\"line\">Use &quot;kubectl &lt;command&gt; --help&quot; for more information about a given command.</span><br><span class=\"line\">Use &quot;kubectl options&quot; for a list of global command-line options (applies to all commands).</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl config use-context</span><br><span class=\"line\">Sets the current-context in a kubeconfig file</span><br><span class=\"line\"></span><br><span class=\"line\">Aliases:</span><br><span class=\"line\">use-context, use</span><br><span class=\"line\"></span><br><span class=\"line\">Examples:</span><br><span class=\"line\">  # Use the context for the minikube cluster</span><br><span class=\"line\">  kubectl config use-context minikube</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">  kubectl config use-context CONTEXT_NAME [options]</span><br><span class=\"line\"></span><br><span class=\"line\">Use &quot;kubectl options&quot; for a list of global command-line options (applies to all commands).</span><br><span class=\"line\">error: Unexpected args: []</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl config use-context kind-kind</span><br><span class=\"line\">Switched to context &quot;kind-kind&quot;.</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubuntu:~# kubectl get node</span><br><span class=\"line\">NAME                 STATUS   ROLES    AGE    VERSION</span><br><span class=\"line\">kind-control-plane   Ready    master   3d1h   v1.19.1</span><br></pre></td></tr></table></figure>\n<p>实际上，kind内部创建集群过程中，也是使用kubeadm，从上述创建过程中的打印也似乎能猜到这一点</p>\n<p>后面，就可以使用搭建好的集群环境，开始你的开发、测试工作了~~~</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cki73ih160003h0l70l0v4m1y","category_id":"cki73ih1a000bh0l7gruyeb9u","_id":"cki73ih1c000ih0l767sdgl2n"},{"post_id":"cki73ih190009h0l7hxnacgw6","category_id":"cki73ih1a000bh0l7gruyeb9u","_id":"cki73ih1e000nh0l7grzf4ixj"},{"post_id":"cki73ih130001h0l70tl2f2pn","category_id":"cki73ih170004h0l7hvq65ktb","_id":"cki73ih1f000rh0l7121wdr6r"},{"post_id":"cki73ih130001h0l70tl2f2pn","category_id":"cki73ih1e000lh0l77mu9gmy0","_id":"cki73ih1f000vh0l7hje28t45"},{"post_id":"cki73ih1a000ah0l7ek6e38vx","category_id":"cki73ih1e000oh0l73lja1egf","_id":"cki73ih1g000xh0l7bxzpbd2t"},{"post_id":"cki73ih180007h0l79chxdzbu","category_id":"cki73ih1c000eh0l7g55h81tq","_id":"cki73ih1h0015h0l76oxa0xwj"},{"post_id":"cki73ih180007h0l79chxdzbu","category_id":"cki73ih1g000yh0l71rgb0mqm","_id":"cki73ih1h0017h0l71oq07s90"},{"post_id":"cki73ih1b000dh0l77vh59mmk","category_id":"cki73ih1f000th0l70w86gx76","_id":"cki73ih1i001dh0l70omkeuy8"},{"post_id":"cki73ih1b000dh0l77vh59mmk","category_id":"cki73ih1h0013h0l7f9fk76uu","_id":"cki73ih1j001eh0l74bna77yl"},{"post_id":"cki73ih1b000dh0l77vh59mmk","category_id":"cki73ih1h0018h0l75h6i4mdp","_id":"cki73ih1j001gh0l75djvfrdv"},{"post_id":"cki73ih1j001ih0l70wzr37c4","category_id":"cki73ih1k001jh0l71oza1pu1","_id":"cki73ih1k001nh0l71lmm9ggc"}],"PostTag":[{"post_id":"cki73ih130001h0l70tl2f2pn","tag_id":"cki73ih180005h0l7ar0z39k8","_id":"cki73ih1c000gh0l7elk0g1o2"},{"post_id":"cki73ih130001h0l70tl2f2pn","tag_id":"cki73ih1b000ch0l7b3wc40rr","_id":"cki73ih1c000hh0l7391pgyuh"},{"post_id":"cki73ih160003h0l70l0v4m1y","tag_id":"cki73ih1c000fh0l7h3rx9ttf","_id":"cki73ih1f000qh0l75xbo68rt"},{"post_id":"cki73ih160003h0l70l0v4m1y","tag_id":"cki73ih1d000kh0l77uqs496h","_id":"cki73ih1f000sh0l7b1e55za1"},{"post_id":"cki73ih160003h0l70l0v4m1y","tag_id":"cki73ih1e000mh0l7dhtzh34u","_id":"cki73ih1f000wh0l7a1wy6lnl"},{"post_id":"cki73ih180007h0l79chxdzbu","tag_id":"cki73ih1e000mh0l7dhtzh34u","_id":"cki73ih1g0010h0l7cvoa0zpx"},{"post_id":"cki73ih180007h0l79chxdzbu","tag_id":"cki73ih1f000uh0l7am7b0oy5","_id":"cki73ih1g0011h0l7f13yexs4"},{"post_id":"cki73ih190009h0l7hxnacgw6","tag_id":"cki73ih1e000mh0l7dhtzh34u","_id":"cki73ih1h0014h0l7hj7847of"},{"post_id":"cki73ih1a000ah0l7ek6e38vx","tag_id":"cki73ih1g0012h0l7crtodg0e","_id":"cki73ih1i001ah0l7dqvuftaf"},{"post_id":"cki73ih1a000ah0l7ek6e38vx","tag_id":"cki73ih1h0016h0l72mkh7dau","_id":"cki73ih1i001bh0l7fwog6uvw"},{"post_id":"cki73ih1b000dh0l77vh59mmk","tag_id":"cki73ih1i0019h0l7947b65zy","_id":"cki73ih1j001fh0l7hge4hivc"},{"post_id":"cki73ih1b000dh0l77vh59mmk","tag_id":"cki73ih1e000mh0l7dhtzh34u","_id":"cki73ih1j001hh0l71k7f6mhp"},{"post_id":"cki73ih1j001ih0l70wzr37c4","tag_id":"cki73ih1e000mh0l7dhtzh34u","_id":"cki73ih1k001lh0l71ka7c5pf"},{"post_id":"cki73ih1j001ih0l70wzr37c4","tag_id":"cki73ih1k001kh0l7fksjhyi6","_id":"cki73ih1k001mh0l7hxdr4gi0"}],"Tag":[{"name":"kuiper","_id":"cki73ih180005h0l7ar0z39k8"},{"name":"edgex","_id":"cki73ih1b000ch0l7b3wc40rr"},{"name":"云计算","_id":"cki73ih1c000fh0l7h3rx9ttf"},{"name":"边缘计算","_id":"cki73ih1d000kh0l77uqs496h"},{"name":"kubernetes","_id":"cki73ih1e000mh0l7dhtzh34u"},{"name":"python","_id":"cki73ih1f000uh0l7am7b0oy5"},{"name":"GitHub","_id":"cki73ih1g0012h0l7crtodg0e"},{"name":"helm","_id":"cki73ih1h0016h0l72mkh7dau"},{"name":"docker","_id":"cki73ih1i0019h0l7947b65zy"},{"name":"云原生","_id":"cki73ih1k001kh0l7fksjhyi6"}]}}